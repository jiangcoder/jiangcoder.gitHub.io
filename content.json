{"pages":[],"posts":[{"title":"ElasticSearch之索引模板","text":"一，模板简述template大致分成setting和mappings两部分：索引可使用预定义的模板进行创建,这个模板称作Index templates。模板设置包括settings和mappings，通过模式匹配的方式使得多个索引重用一个模板。 settings主要作用于index的一些相关配置信息，如分片数、副本数，tranlog同步条件、refresh等。 mappings主要是一些说明信息，大致又分为_all、_source、prpperties这三部分： (1) _all：主要指的是AllField字段，我们可以将一个或多个都包含进来，在进行检索时无需指定字段的情况下检索多个字段。设置“_all” : {“enabled” : true} (2) _source：主要指的是SourceField字段，Source可以理解为ES除了将数据保存在索引文件中，另外还有一份源数据。_source字段在我们进行检索时相当重要，如果在{“enabled” : false}情况下默认检索只会返回ID， 你需要通过Fields字段去到索引中去取数据，效率不是很高。但是enabled设置为true时，索引会比较大，这时可以通过Compress进行压缩和inclueds、excludes来在字段级别上进行一些限制，自定义哪些字段允许存储。 (3) properties：这是最重要的步骤，主要针对索引结构和字段级别上的一些设置。 咱们通常在elasticsearch中 post mapping信息，每重新创建索引便到设置mapping，分片，副本信息。非常繁琐。强烈建议大家通过设置template方式设置索引信息。设置索引名，通过正则匹配的方式匹配到相应的模板。ps:直接修改mapping的优先级>索引template。索引匹配了多个template，当属性等配置出现不一致的，以order的最大值为准，order默认值为0 二，创建模板例如： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455{ \"template\": \"pmall*\", \"settings\": { \"index.number_of_shards\": 1, \"number_of_replicas\": 4, \"similarity\": { \"IgnoreTFSimilarity\": { \"type\": \"IgoreTFSimilarity\" } } }, \"mappings\": { \"_default_\": { \"_source\": { \"enabled\": false } }, \"commodity\": { \"properties\": { \"sold\": { \"type\": \"long\" }, \"online_time\": { \"type\": \"long\" }, \"price\": { \"type\": \"long\" }, \"publish_time\": { \"type\": \"long\" }, \"id\": { \"type\": \"long\" }, \"catecode\": { \"type\": \"integer\" }, \"title\": { \"search_analyzer\": \"ikSmart\", \"similarity\": \"IgnoreTFSimilarity\", \"analyzer\": \"ik\", \"type\": \"text\" }, \"content\": { \"index\": false, \"store\": true, \"type\": \"keyword\" }, \"status\": { \"type\": \"integer\" } } } }} 三，删除模板12DELETE /_template/template_1 四，查看模板：1GET /_template/template_1 也可以通过模糊匹配得到多个模板信息 1GET /_template/temp* 可以批量查看模板 1GET /_template/template_1,template_2 验证模板是否存在： 1HEAD _template/template_1 五：多个模板同时匹配，以order顺序倒排，order越大，优先级越高1234567891011121314151617181920212223242526272829 PUT /_template/template_1{ \"template\" : \"*\", \"order\" : 0, \"settings\" : { \"number_of_shards\" : 1 }, \"mappings\" : { \"type1\" : { \"_source\" : { \"enabled\" : false } } }}PUT /_template/template_2{ \"template\" : \"te*\", \"order\" : 1, \"settings\" : { \"number_of_shards\" : 1 }, \"mappings\" : { \"type1\" : { \"_source\" : { \"enabled\" : true } } }} 六，模板版本号模板可以选择添加版本号，这可以是任何整数值，以便简化外部系统的模板管理。版本字段是完全可选的，它仅用于模板的外部管理。要取消设置版本，只需替换模板即可 创建模板： 123456789PUT /_template/template_1{ \"template\" : \"*\", \"order\" : 0, \"settings\" : { \"number_of_shards\" : 1 }, \"version\": 123} 查看模板版本号： 1GET /_template/template_1?filter_path=*.version 响应如下： 12345{ \"template_1\" : { \"version\" : 123 }} 七，参考：[url=https://www.elastic.co/guide/en/elasticsearch/reference/5.4/indices-templates.html]indices-templates[/url]","link":"/2020/03/06/ElasticSearch%E4%B9%8B%E7%B4%A2%E5%BC%95%E6%A8%A1%E6%9D%BF/"},{"title":"Elasticsearch 搜索模块之preference参数","text":"##一，preference简述 elasticsearch可以使用preference参数来指定分片查询的优先级，即我们可以通过该参数来控制搜索时的索引数据分片。 如不设置该参数：在所有有效的主分片以及副本间轮询。 具体可看下：OperationRouting.java类 123public ShardIterator activeInitializingShardsRandomIt() { return activeInitializingShardsIt(shuffler.nextSeed());} 自增，以实现shard间轮询操作 123public int nextSeed() { return seed.getAndIncrement(); } 123456789public ShardIterator activeInitializingShardsIt(int seed) { if (allInitializingShards.isEmpty()) { return new PlainShardIterator(shardId, shuffler.shuffle(activeShards, seed)); } ArrayList ordered = new ArrayList(activeShards.size() + allInitializingShards.size()); ordered.addAll(shuffler.shuffle(activeShards, seed)); ordered.addAll(allInitializingShards); return new PlainShardIterator(shardId, ordered);} 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576private ShardIterator preferenceActiveShardIterator(IndexShardRoutingTable indexShard, String localNodeId, DiscoveryNodes nodes, @Nullable String preference) { if (preference == null || preference.isEmpty()) { if (awarenessAttributes.length == 0) { return indexShard.activeInitializingShardsRandomIt(); } else { return indexShard.preferAttributesActiveInitializingShardsIt(awarenessAttributes, nodes); } } if (preference.charAt(0) == '_') { Preference preferenceType = Preference.parse(preference); if (preferenceType == Preference.SHARDS) { // starts with _shards, so execute on specific ones int index = preference.indexOf('|'); String shards; if (index == -1) { shards = preference.substring(Preference.SHARDS.type().length() + 1); } else { shards = preference.substring(Preference.SHARDS.type().length() + 1, index); } String ids = Strings.splitStringByCommaToArray(shards); boolean found = false; for (String id : ids) { if (Integer.parseInt(id) == indexShard.shardId().id()) { found = true; break; } } if (!found) { return null; } // no more preference if (index == -1 || index == preference.length() - 1) { if (awarenessAttributes.length == 0) { return indexShard.activeInitializingShardsRandomIt(); } else { return indexShard.preferAttributesActiveInitializingShardsIt(awarenessAttributes, nodes); } } else { // update the preference and continue preference = preference.substring(index + 1); } } preferenceType = Preference.parse(preference); switch (preferenceType) { case PREFER_NODES: final Set nodesIds = Arrays.stream( preference.substring(Preference.PREFER_NODES.type().length() + 1).split(\",\") ).collect(Collectors.toSet()); return indexShard.preferNodeActiveInitializingShardsIt(nodesIds); case LOCAL: return indexShard.preferNodeActiveInitializingShardsIt(Collections.singleton(localNodeId)); case PRIMARY: return indexShard.primaryActiveInitializingShardIt(); case REPLICA: return indexShard.replicaActiveInitializingShardIt(); case PRIMARY_FIRST: return indexShard.primaryFirstActiveInitializingShardsIt(); case REPLICA_FIRST: return indexShard.replicaFirstActiveInitializingShardsIt(); case ONLY_LOCAL: return indexShard.onlyNodeActiveInitializingShardsIt(localNodeId); case ONLY_NODES: String nodeAttributes = preference.substring(Preference.ONLY_NODES.type().length() + 1); return indexShard.onlyNodeSelectorActiveInitializingShardsIt(nodeAttributes.split(\",\"), nodes); default: throw new IllegalArgumentException(\"unknown preference [\" + preferenceType + \"]\"); } } // if not, then use it as the index if (awarenessAttributes.length == 0) { return indexShard.activeInitializingShardsIt(Murmur3HashFunction.hash(preference)); } else { return indexShard.preferAttributesActiveInitializingShardsIt(awarenessAttributes, nodes, Murmur3HashFunction.hash(preference)); } } ##二，结果震荡问题（Bouncing Results） 搜索同一query，结果ES返回的顺序却不尽相同，这就是请求轮询到不同分片，而未设置排序条件，相同相关性评分情况下，是按照所在segment中​lucene id来排序的，相同数据的不同备份之间该id是不能保证一致的，故造成结果震荡问题。如设置该参数，则有一下9种情况 _primary:发送到集群的相关操作请求只会在主分片上执行。_primary_first:指查询会先在主分片中查询，如果主分片找不到（挂了），就会在副本中查询。_replica:发送到集群的相关操作请求只会在副本上执行。_replica_first：指查询会先在副本中查询，如果副本找不到（挂了），就会在主分片中查询。_local: 指查询操作会优先在本地节点有的分片中查询，没有的话再在其它节点查询。_prefer_nodes:abc,xyz:在提供的节点上优先执行（在这种情况下为’abc’或’xyz’）_shards:2,3：限制操作到指定的分片。 （2和“3”）。这个偏好可以与其他偏好组合，但必须首先出现：_shards：2,3 | _primary_only_nodes:node1,node2:指在指定id的节点里面进行查询，如果该节点只有要查询索引的部分分片，就只在这部分分片中查找，不同节点之间用“，”分隔。 custom(自定义)：注意自定义的preference参数不能以下划线”_”开头。当preference为自定义时，即该参数不为空，且开头不以“下划线”开头时，特别注意：如果以用户query作为自定义preference时，一定要处理以下划线开头的情况，这种情况下如果不属于以上8种情况，则会抛出异常。 三，参考： https://www.elastic.co/guide/en/elasticsearch/reference/current/search-request-preference.html","link":"/2020/03/06/Elasticsearch%20%E6%90%9C%E7%B4%A2%E6%A8%A1%E5%9D%97%E4%B9%8Bpreference%E5%8F%82%E6%95%B0/"},{"title":"Elasticsearch源码编译by Intellij Idea","text":"##一、软件环境Intellij Idea:2017.1版本Elasticsearch源码版本:5.3.1JDK:1.8.0_111Gradle :建议3.3及以上版本。官网：https://gradle.org/##二、下载Elasticsearch源码到github clone源码，https://github.com/elastic/elasticsearch.git，建议选择稳定版本分支。 ##三、导入idea1，##编译执行gradle build.gradle，报错：you must run gradle idea from the root of elasticsearch before importing into intellij解决办法：运行命令：gradle idea。同理如使用eclipse编译器，运行gradle eclipse。该过程会向mvn仓库下载响应的jar包，视网络情况，大概会持续20分钟。 ##2，运行org.elasticsearch.bootstrap.Elasticsearch 方法，报错：“path.home is not configured” when starting ES in transport and client mode“，解决办法：在VM options中加入配置：-Des.path.home=/home/jiangtao/code/elasticsearch/core，即指向相应的core模块的路径。 ##3，报错：org.elasticsearch.bootstrap.BootstrapException: java.nio.file.NoSuchFileException 123456789101112Exception in thread \"main\" org.elasticsearch.bootstrap.BootstrapException: java.nio.file.NoSuchFileException: /home/jiangtao/code/elasticsearch/core/config Likely root cause: java.nio.file.NoSuchFileException: /home/jiangtao/code/elasticsearch/core/config at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86) at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) at sun.nio.fs.UnixFileAttributeViews$Basic.readAttributes(UnixFileAttributeViews.java:55) at sun.nio.fs.UnixFileSystemProvider.readAttributes(UnixFileSystemProvider.java:144) at sun.nio.fs.LinuxFileSystemProvider.readAttributes(LinuxFileSystemProvider.java:99) at java.nio.file.Files.readAttributes(Files.java:1737) at java.nio.file.FileTreeWalker.getAttributes(FileTreeWalker.java:225) at java.nio.file.FileTreeWalker.visit(FileTreeWalker.java:276) at java.nio.file.FileTreeWalker.walk(FileTreeWalker.java:322) at java.nio.file.Files.walkFileTree(Files.java:2662) 解决办法：将distribution模块src路径下的config整个文件copy到core模块中 ##4，报错： ERROR Could not register mbeans java.security.AccessControlException 1234567892017-06-06 09:52:08,007 main ERROR Could not register mbeans java.security.AccessControlException: access denied (\"javax.management.MBeanTrustPermission\" \"register\") at java.security.AccessControlContext.checkPermission(AccessControlContext.java:472) at java.lang.SecurityManager.checkPermission(SecurityManager.java:585) at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.checkMBeanTrustPermission(DefaultMBeanServerInterceptor.java:1848) at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:322) at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522) at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:91) at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:84) 解决办法：禁用jmx,在VM options中继续添加配置： -Dlog4j2.disable.jmx=true。注意：在VM options中多个配置中间用空格分隔。123456789101112131415161718192021##5，报错： java.lang.IllegalStateException: Unsupported transport.type 错误栈如下：```java[2017-06-06T10:04:21,327][WARN ][o.e.b.ElasticsearchUncaughtExceptionHandler] uncaught exception in thread [main]org.elasticsearch.bootstrap.StartupException: java.lang.IllegalStateException: Unsupported transport.type at org.elasticsearch.bootstrap.Elasticsearch.init(Elasticsearch.java:127) ~[main/:?]at org.elasticsearch.bootstrap.Elasticsearch.execute(Elasticsearch.java:114) ~[main/:?]at org.elasticsearch.cli.EnvironmentAwareCommand.execute(EnvironmentAwareCommand.java:58) ~[main/:?]at org.elasticsearch.cli.Command.mainWithoutErrorHandling(Command.java:122) ~[main/:?]at org.elasticsearch.cli.Command.main(Command.java:88) ~[main/:?]at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:91) ~[main/:?]at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:84) ~[main/:?]Caused by: java.lang.IllegalStateException: Unsupported transport.type at org.elasticsearch.common.network.NetworkModule.getTransportSupplier(NetworkModule.java:213) ~[main/:?]at org.elasticsearch.node.Node.(Node.java:421) ~[main/:?]at org.elasticsearch.node.Node.(Node.java:242) ~[main/:?]at org.elasticsearch.bootstrap.Bootstrap$6.(Bootstrap.java:242) ~[main/:?]at org.elasticsearch.bootstrap.Bootstrap.setup(Bootstrap.java:242) ~[main/:?]at org.elasticsearch.bootstrap.Bootstrap.init(Bootstrap.java:360) ~[main/:?]at org.elasticsearch.bootstrap.Elasticsearch.init(Elasticsearch.java:123) ~[main/:?]... 6 more 这个是由于依赖的transport等jar并没有找到，可以在项目根目录找到models模块，然后将下面目录打包，然后copy到distribution/src/main/models目录下，也可以直接去官网（https://www.elastic.co/downloads/elasticsearch）下载zip包，解压后直接copy。我直接去官网下载的zip包：从官网下载完毕zip包后，具体解决办法请看：错误 6。 ##6，copy module版本冲突错误栈如下： 123456789org.elasticsearch.bootstrap.StartupException: java.lang.IllegalArgumentException: Plugin [lang-expression] is incompatible with Elasticsearch [5.3.4]. Was designed for version [5.3.1] at org.elasticsearch.bootstrap.Elasticsearch.init(Elasticsearch.java:127) ~[main/:?] at org.elasticsearch.bootstrap.Elasticsearch.execute(Elasticsearch.java:114) ~[main/:?] at org.elasticsearch.cli.EnvironmentAwareCommand.execute(EnvironmentAwareCommand.java:58) ~[main/:?] at org.elasticsearch.cli.Command.mainWithoutErrorHandling(Command.java:122) ~[main/:?] at org.elasticsearch.cli.Command.main(Command.java:88) ~[main/:?]at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:91) ~[main/:?]at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:84) ~[main/:?]Caused by: java.lang.IllegalArgumentException: Plugin [lang-expression] is incompatible with Elasticsearch [5.3.4]. Was designed for version [5.3.1] 解决办法：修改es当前版本将core模块中的Version.java类由public static final Version CURRENT = V_5_3_4_UNRELEASED;修改为：public static final Version CURRENT = V_5_3_1;","link":"/2020/03/06/Elasticsearch%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91by%20Intellij%20Idea/"},{"title":"Elasticsearch定制化插件开发","text":"一，一般的插件开发方式： 按照官网教程，每次都得打包、替换、重启，这是一个很不方便的过程，固然可以通过testCase来做debug，但是所见即所得的编码习惯，直接上手debug，才是最高效的方式。 介绍插件开发的博客何其多，个人私以为都没有get到G点，其实深入研究下elasticsearch源码，fix 这个问题并不难，下面希望通过这篇文章帮助到大家。二，elasticsearch插件的加载机制①：Node节点启动过程，Elasticsearch.java会调用Bootstrap.java中的init函数。 1234567static void init(...) { ... INSTANCE = new Bootstrap(); INSTANCE.setup(true, environment); ... INSTANCE.start();} ②：Node节点通过setup方法进行实例化。 123456private void setup(boolean addShutdownHook, Environment environment) throws BootstrapException { node = new Node(environment) { ...} ③：Node.java类中会包含各类的service服务，其中包括PluginsService服务。在实例化PluginsService服务时会传参 123456789environment.pluginsFile(),classpathPlugins等参数。而pluginsFile()即是elasticsearch所指定的plugin目录，elasticsearch会扫描该路径下所有的插件，并加载进来。 public Node(Environment environment) { this(environment, Collections.emptyList());} protected Node(final Environment environment, Collection classpathPlugins) { ... this.pluginsService = new PluginsService(tmpSettings, environment.modulesFile(), environment.pluginsFile(), classpathPlugins);} ④：classpathPlugins参数介绍： 123public Node(Environment environment) { this(environment, Collections.emptyList()); } 在elasticsearch源码中，这个参数Collection classpathPlugins一直都是空集合。没有任何地方注入修改该参数。elasticsearch不但会扫描插件所在路径中的插件，同样也会加载classpathPlugins中所指定的插件，只不过问题是elasticsearch没有给我们提供相应的参数！！！！三，如何更优雅的开发开发插件 接上一段小节④，我们只要利用classpathPlugins该参数，就可以在elasticsearch源码环境中进行debug了！！！ 我的实现思路如下，通过继承Node.java，并重写Node类的构造方法，然后在bootstrap中直接实例化该子类，便可以通过elasticsearch直接bug 插件源码了。 下面贴出我的实现代码，供大家参考： 1234567891011121314151617181920212223242526import org.elasticsearch.Version;import org.elasticsearch.env.Environment;import org.elasticsearch.node.Node;import org.elasticsearch.plugins.Plugin;import java.util.Collection;public class EmbeddedNode extends Node { private Version version; private Collection plugins; public EmbeddedNode(Environment environment, Version version, Collection classpathPlugins) { super(environment, classpathPlugins); this.version = version; this.plugins = classpathPlugins; } public Collection getPlugins() { return plugins; } public Version getVersion() { return version; }} 123456789101112131415161718192021private void setup(boolean addShutdownHook, Environment environment) throws BootstrapException { ..... //注释Node初始化源码 /* node = new Node(environment) { @Override protected void validateNodeBeforeAcceptingRequests( final Settings settings, final BoundTransportAddress boundTransportAddress, List checks) throws NodeValidationException { BootstrapChecks.check(settings, boundTransportAddress, checks); } };*/ Collection plugins = new ArrayList(); Collections.addAll(plugins, AnalysisIkPlugin.class, HelloPlugin.class, AnalysisMMsegPlugin.class);//, ,AnalysisMMsegPlugin.class node = new EmbeddedNode(environment, Version.CURRENT, plugins) { @Override protected void validateNodeBeforeAcceptingRequests(final Settings settings, final BoundTransportAddress boundTransportAddress, List checks) throws NodeValidationException { BootstrapChecks.check(settings, boundTransportAddress, checks); } }; } 四，部署插件相关的注意事项： 有关插件开发的详细配置，es插件的种类，在此不再赘述，具体可参考官方文档，更权威，更直接。下面贴个图，本人在elasticsearch中同时整合了多个插件，以供学习研究时用，直接debug，个人感觉十分不错。","link":"/2020/03/27/Elasticsearch%E5%AE%9A%E5%88%B6%E5%8C%96%E6%8F%92%E4%BB%B6%E5%BC%80%E5%8F%91/"},{"title":"Linux系统之用户态、内核态","text":"#什么是内核态、用户态？内核态：cpu可以访问内存的所有数据，包括外围设备，例如硬盘，网卡，cpu也可以将自己从一个程序切换到另一个程序。用户态：只能受限的访问内存，且不允许访问外围设备，占用cpu的能力被剥夺，cpu资源可以被其他程序获取。 #为什么要有用户态和内核态？由于需要限制不同的程序之间的访问能力, 防止他们获取别的程序的内存数据, 或者获取外围设备的数据, 并发送到网络,CPU划分出两个权限等级 – 用户态和内核态。 #用户态与内核态的切换 所有用户程序都是运行在用户态的, 但是有时候程序确实需要做一些内核态的事情, 例如从硬盘读取数据, 或者从键盘获取输入等. 而唯一可以做这些事情的就是操作系统, 所以此时程序就需要先操作系统请求以程序的名义来执行这些操作.这时需要一个这样的机制: 用户态程序切换到内核态, 但是不能控制在内核态中执行的指令这种机制叫系统调用, 在CPU中的实现称之为陷阱指令(Trap Instruction)他们的工作流程如下:用户态程序将一些数据值放在寄存器中, 或者使用参数创建一个堆栈(stack frame), 以此表明需要操作系统提供的服务.用户态程序执行陷阱指令CPU切换到内核态, 并跳到位于内存指定位置的指令, 这些指令是操作系统的一部分, 他们具有内存保护, 不可被用户态程序访问这些指令称之为陷阱(trap)或者系统调用处理器(system call handler). 他们会读取程序放入内存的数据参数, 并执行程序请求的服务系统调用完成后, 操作系统会重置CPU为用户态并返回系统调用的结果当一个任务（进程）执行系统调用而陷入内核代码中执行时，我们就称进程处于内核运行态（或简称为内核态）。此时处理器处于特权级最高的（0级）内核代码中执行。当进程处于内核态时，执行的内核代码会使用当前进程的内核栈。每个进程都有自己的内核栈。当进程在执行用户自己的代码时，则称其处于用户运行态（用户态）。即此时处理器在特权级最低的（3级）用户代码中运行。当正在执行用户程序而突然被中断程序中断时，此时用户程序也可以象征性地称为处于进程的内核态。因为中断处理程序将使用当前进程的内核栈。这与处于内核态的进程的状态有些类似。 内核态与用户态是操作系统的两种运行级别,跟intel cpu没有必然的联系, intel cpu提供Ring0-Ring3三种级别的运行模式，Ring0级别最高，Ring3最低。Linux使用了Ring3级别运行用户态，Ring0作为 内核态，没有使用Ring1和Ring2。Ring3状态不能访问Ring0的地址空间，包括代码和数据。Linux进程的4GB地址空间，3G-4G部 分大家是共享的，是内核态的地址空间，这里存放在整个内核的代码和所有的内核模块，以及内核所维护的数据。用户运行一个程序，该程序所创建的进程开始是运 行在用户态的，如果要执行文件操作，网络数据发送等操作，必须通过write，send等系统调用，这些系统调用会调用内核中的代码来完成操作，这时，必 须切换到Ring0，然后进入3GB-4GB中的内核地址空间去执行这些代码完成操作，完成后，切换回Ring3，回到用户态。这样，用户态的程序就不能 随意操作内核地址空间，具有一定的安全保护作用。至于说保护模式，是说通过内存页表操作等机制，保证进程间的地址空间不会互相冲突，一个进程的操作不会修改另一个进程的地址空间中的数据。","link":"/2020/03/28/Linux%E7%B3%BB%E7%BB%9F%E4%B9%8B%E7%94%A8%E6%88%B7%E6%80%81%E3%80%81%E5%86%85%E6%A0%B8%E6%80%81/"},{"title":"Elasticsearch负载高问题排查","text":"我们Elasticsearch集群近几日负载飙高，排查思路记录如下； 查看日志信息，确定是否存在异常情况 12cd ${ES_HOME}/logstail -100f ES.log 频繁Full GC往往会引起负载飙高，故查看ES集群GC 情况， 使用命令： 1jstat -gcutil 近一个多月，服务共Full GC700余次，平均每次Full GC耗时90ms，符合预期，排除Full GC问题导致负载飙高；4. 找到ES中占用CPU的线程ID 1top -Hp PID 如找到ES进程中2291线程较费CPU 将得到的线程id，转化为16进制 12printf %x 2291输出结果：8f3 使用jstack分析线程状态jstack命令主要用于调试java程序运行过程中的线程堆栈信息 1jstack PID >> pid.txt 8.查看pid.txt文件，分析线程对应的堆栈信息由步骤6得到 16进制线程“8f3” 12vim pid.txt//查找线程“8f3”对应信息 内容如下 123456789101112131415\"elasticsearch[data-es12][write][T#3]\" #94 daemon prio=5 os_prio=0 tid=0x00007f3254017800 nid=0x8f3 waiting for monitor entry [0x00007f2d37a7a000] java.lang.Thread.State: BLOCKED (on object monitor) at org.elasticsearch.index.translog.TranslogWriter.syncUpTo(TranslogWriter.java:342) - waiting to lock (a java.lang.Object) at org.elasticsearch.index.translog.Translog.ensureSynced(Translog.java:797) at org.elasticsearch.index.translog.Translog.ensureSynced(Translog.java:818) at org.elasticsearch.index.engine.InternalEngine.ensureTranslogSynced(InternalEngine.java:489) at org.elasticsearch.index.shard.IndexShard$5.write(IndexShard.java:2782) at org.elasticsearch.common.util.concurrent.AsyncIOProcessor.processList(AsyncIOProcessor.java:107) at org.elasticsearch.common.util.concurrent.AsyncIOProcessor.drainAndProcess(AsyncIOProcessor.java:99) at org.elasticsearch.common.util.concurrent.AsyncIOProcessor.put(AsyncIOProcessor.java:82) at org.elasticsearch.index.shard.IndexShard.sync(IndexShard.java:2804) at org.elasticsearch.action.support.replication.TransportWriteAction$AsyncAfterWriteAction.run(TransportWriteAction.java:355) at org.elasticsearch.action.support.replication.TransportWriteAction$WritePrimaryResult.(TransportWriteAction.java:151) at 该线程正处于堵塞状态。 9，原因分析从ES索引数据创建机制说起写请求首先先写到内存一份数据，然后写translog，默认每1秒进行refresh，将索引写入到文件系统；该ES集群是ELK日志查询服务，特点读多写少，我们TB级数据，上千个索引，refresh_interval参数1s，在日志服务中显然不太合适，是时候调整下该参数配置了。 10，参数调整 123456http://ip:port/logstash*/_settings PUT{ \"settings\": { \"refresh_interval\": \"5m\" }} 11，问题解决","link":"/2020/03/20/Elasticsearch%E8%B4%9F%E8%BD%BD%E9%AB%98%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5/"},{"title":"Git如何回退版本","text":"首先使用git log查看最近几次提交的版本号，如版本号”0250cd”; 在命令行输入 git reset –hard 0250cd，成功后会提示”head is now at 0250cd”； git push -f -u origin you_branch,you_branch需要回退的分支名","link":"/2020/03/20/Git%E5%A6%82%E4%BD%95%E5%9B%9E%E9%80%80%E7%89%88%E6%9C%AC/"},{"title":"Java之Buffer","text":"一，Buffer概念Buffer 类是 java.nio 的构造基础。一个 Buffer 对象是固定数量的数据的容器，其作用是一个存储器，或者分段运输区.每个非布尔原始数据类型都有一个缓冲区类.子类有 1234567ByteBufferCharBufferIntBufferLongBufferDoubleBufferFloatBufferShortBuffer 二，缓存区的四个属性1234private int mark = -1;//一个备忘位置。标记在设定前是未定义的(undefined)。使用场景是，假设缓冲区中有 10 个元素，position 目前的位置为 2(也就是如果get的话是第三个元素)，现在只想发送 6 - 10 之间的缓冲数据，此时我们可以 buffer.mark(buffer.position())，即把当前的 position 记入 mark 中，然后 buffer.postion(6)，此时发送给 channel 的数据就是 6 - 10 的数据。发送完后，我们可以调用 buffer.reset() 使得 position = mark，因此这里的 mark 只是用于临时记录一下位置用的private int position = 0;//下一个要被读或写的元素的索引。位置会自动由相应的 get() 和 put() 函数更新。 这里需要注意的是positon的位置是从0开始的private int limit;//缓冲区的第一个不能被读或写的元素。缓冲创建时，limit 的值等于 capacity 的值。假设 capacity = 1024，我们在程序中设置了 limit = 512，说明，Buffer 的容量为 1024，但是从 512 之后既不能读也不能写，因此可以理解成，Buffer 的实际可用大小为 512private int capacity;//缓冲区能够容纳的数据元素的最大数量。这一容量在缓冲区创建时被设定，并且永远不能被改变。 三，flipflip() :写模式转到读模式clear()或者compact():重新从Buffer中读取数据such as : 123456789101112131415161718192021import java.nio.ByteBuffer;public class CreateBuffer { public static void main(String args[]) { ByteBuffer buffer = ByteBuffer.allocate(1024); buffer.put((byte) 'a'); buffer.put((byte) 'b'); buffer.put((byte) 'c'); //调用flip之后，读写指针指到缓存头部，并且设置了最多只能读出之前写入的数据长度(而不是整个缓存的容量大小) buffer.flip(); System.out.println((char) buffer.get());//a System.out.println((char) buffer.get());//b System.out.println((char) buffer.get());//c //重新从Buffer中读取数据 buffer.compact(); System.out.println((char) buffer.get());//a System.out.println((char) buffer.get());//b System.out.println((char) buffer.get());//c }}","link":"/2020/03/27/Java%E4%B9%8BBuffer/"},{"title":"lambda表达式","text":"一，排序对数组从小到大排序 123public void sortUsingLambda(List indexs) { Collections.sort(indexs, (s1, s2) -> s1.compareTo(s2));} 更简洁的实现方式 123public void sortUsingLambda(List indexs) { Collections.sort(indexs, Integer::compareTo);} 对数组从小到大排序 123public void sortUsingLambda(List indexs) { Collections.sort(indexs, (s1, s2) -> s2.compareTo(s1));} 从小到大简洁实现 123public void sortUsingLambda(List indexs) { Collections.sort(indexs, Comparator.reverseOrder());} 二，list转map①：取list中某2个字段作为Map的K,V 123public Map getIdNameMap(List accounts) { return accounts.stream().collect(Collectors.toMap(Account::getId, Account::getUsername));} ②：将id和实体Bean做为K,V 123public Map getIdAccountMap(List accounts) { return accounts.stream().collect(Collectors.toMap(Account::getId, account -> account));} 或者这样写 123public Map getIdAccountMap(List accounts) { return accounts.stream().collect(Collectors.toMap(Account::getId, Function.identity()));} account -> account是一个返回本身的lambda表达式，后面的使用Function接口中的一个默认方法代替，使整个方法更简洁优雅。③：key存在重复记录时处理 123public Map getNameAccountMap(List accounts) { return accounts.stream().collect(Collectors.toMap(Account::getUsername, Function.identity(), (key1, key2) -> key2));} ④：使用某个具体的Map类来保存，如保存时使用LinkedHashMap 123public Map getNameAccountMap(List accounts) { return accounts.stream().collect(Collectors.toMap(Account::getUsername, Function.identity(), (key1, key2) -> key2, LinkedHashMap::new));} ⑤：List转List 123456789101112public Map getCodeListMap(){ if(CollectionUtils.isEmpty(codeListMap)){ List codeList = this.getCodeList(); Set keySet = codeList.stream().map(code -> code.getCodeKbn()).collect(Collectors.toSet()); Iterator it = keySet.iterator(); while(it.hasNext()) { String key = it.next(); codeListMap.put(key, codeList.stream().filter(code -> code.getCodeKbn().equals(key)).collect(Collectors.toList())); } } return codeListMap;} 三，Map转List 1234567891011121314151617Map map = new HashMap();// Convert all Map keys to a ListList result = new ArrayList(map.keySet());// Convert all Map values to a ListList result2 = new ArrayList(map.values());// Java 8, Convert all Map keys to a ListList result3 = map.keySet().stream() .collect(Collectors.toList());// Java 8, Convert all Map values to a ListList result4 = map.values().stream() .collect(Collectors.toList());// Java 8, seem a bit long, but you can enjoy the Stream features like filter and etc.List result5 = map.values().stream() .filter(x -> !\"apple\".equalsIgnoreCase(x)) .collect(Collectors.toList());// Java 8, split a map into 2 List, it works!// refer example 3 below","link":"/2020/03/06/lambda%E8%A1%A8%E8%BE%BE%E5%BC%8F/"},{"title":"Git如何回退版本","text":"目录 1、什么是垃圾 2、如何定位垃圾 reference count Root Searching 3、常见的垃圾回收算法 Mark-Sweep(标记清除) Copying(拷贝算法） Mark-Compact（标记压缩)​ 4、JVM内存分代模型(用于分代垃圾回收算法） 堆内存逻辑分区 5、垃圾回收器 Serial Parallel Scavenge ParNew SerialOld Parallel Old CMS 6、JVM参数 7、思维导图 1、什么是垃圾 内存分配与回收方式： C语言：malloc、free C++：new、delete Java：new 自动回收内存 自动回收内存系统不容易出错，手动回收内存，容易出现以下的错误： 忘记回收 多次回收 垃圾的定义：没有任何引用指向的一个对象或者多个对象(循环引用）。 当把成员变量设置为空(null)之后，不再指向任何引用对象，那么该对象就被称作垃圾： 还有一种情况，多个对象之间互相引用，但是没有其他的引用指向这个循环的对象。 2、如何定位垃圾 reference count 当引用计数变为0的时候，这个对象就成为垃圾了。但是引用计数不能解决对象循环引用 如下： 每个引用计数都是1，但是它们全部是垃圾，所以用引用计数的方式的话，这些垃圾就找不到了，会发生内存泄漏。 Root Searching 根可达或者根搜索算法。 通过程序找到一些根对象，通过根对象找到它所连接的那些对象不是垃圾，其他的都是垃圾。 Roots：线程栈变量、静态变量、常量池、JNI指针 3、常见的垃圾回收算法 Mark-Sweep(标记清除) 将可回收的对象标记为非垃圾。 缺点：位置不连续，产生内存碎片。 Copying(拷贝算法） 内存一分为二，将存活对象复制到未使用的内存中，原内存全部标记为可使用；新分配内存时先分配存活对象所在的那段内存，垃圾回收时，重复上述操作。 特点：没有碎片，但是内浪费空间。最大的问题：内存浪费。 Mark-Compact（标记压缩) 将存活对象依次复制到垃圾对象和未使用的区域中，结合了标记清除和拷贝的做法，但是效率比copy略低。 三种方法找垃圾的效率是一致的，区别在于找到垃圾后对其进行整理的方式。拷贝算法是内存拷贝，是线性地址的拷贝，速度很快的，效率很高。但是压缩算法却不这么简单，因为任意一个内存进行移动时，如果是多线程， 都要进行线程同步；如果是单线程，那单线程的效率本来就低。 所以任何一块内存挪动都要进行线程同步，所以效率肯定是很低的。 4、JVM内存分代模型(用于分代垃圾回收算法） 目前，生产环境中普遍使用的是JDK1.7或JDK1.8，根据JDK版本不同，分代也不同。 JVM中分代：新生代+老年代+永久代(JDK1.7)/元数据区(JDK1.8)Metaspace。 永久代和元数据区是装载Class的，将硬盘上的Class对象load到内存的时候，装载了永久代或者元数据区域，具体放在哪里区别于使用的JDK版本 永久代必须指定大小限制，而元数据可以设置，也可不设置，无上限(受限于物理内存） 字符串常量在JDK1.7中，是放在永久代区域；而JDK1.8中，是放在堆里 MethodArea是一个逻辑概念，并不是指的一个区域，在JDK1.7中对应的就是永久代，JDK1.8中对应的是元数据 堆内存逻辑分区 新生代中分了两类区域，eden和survivor，而survivor有两块。默认的比例，新生代：老年代=1：3，新生代中eden: survivor：survivor = 8:1:1。 之所以新生代中按照这个比例分配，是因为eden区在GC的时候，90%的对象都会被回收，剩下的存活对象在survivor区是可以放下的。 当创建一个对象时，默认会去找eden区， 如果对象特别大，eden区装不下则直接进入老年代。 新生代 = Eden + 2个survivor区(survivor0、survivor1）： YGC(Young GC)回收后，大多数的对象会被回收，活着的对象进入survivor0 再次YGC，活着的对象eden+s0拷贝到s1，将eden和s0清空 再次YGC，活着的对象eden+s1拷贝到s0，将eden和s1清空 年龄足够->老年代(年龄足够：15，CMS 6) survivor区装不下的时候，装不下的部分直接进入老年代 老年代： 顽固份子 老年代区域满了，就进行Full GC(简称FGC, FGC包括新生代和老年代同时GC) GC Tuning：尽量减少FGC。 5、垃圾回收器 Serial、ParNew、Parallel Scavenge是用于回收Young Generation CMS、Serial Old、Parallel Old是用于回收Old Generation G1、ZGC、Shenandoah不区分老年代和新生代。 Epsilon是一个空的GC，仅仅用于调试JDK。 图中的红色虚线表示可以配合使用。 Serial 垃圾回收的时候，程序是无法执行的。stop-the-world(STW)是停止程序运行，回收线程开始运行，回收结束后程序再接着运行。 Parallel Scavenge 并行回收，多个线程同时进行垃圾回收。 ParNew 配合CMS的年轻代并行回收。 SerialOld 单线程回收算法用于old区域 Parallel Old 多线程回收算法用于old区域 CMS ConcurrentMarkSweep，用于回收老年代，在垃圾回收的同时程序也能运行。(黄色的表示垃圾回收线程，蓝色表示程序执行线程） 调优针对的是Serial、Parallel Scavenge和Serial Old、Parallel New，因为JDK1.8默认的垃圾回收：Parallel Scavenge + Parallel Old。 6、JVM参数 JVM的命令行参数参考：https://docs.oracle.com/javase/8/docs/technotes/tools/unix/java.html JVM参数分类： 标准：-开头，所有的HotSpot都支持。 如：java -version 非标准：-X开头，特定版本HotSpot支持特定命令 不稳定：-XX开头，下个版本可能取消 -XX: +PrintFlagsFinal --- 设置值（最终生效值) -XX:+PrintFlagsInitial --- 默认值 -XX:+PrintCommandLineFlags ---命令行参数 7、思维导图 参考文档： https://blogs.oracle.com/jonthecollector/our-collectors https://blogs.oracle.com/jonthecollector/why-not-a-grand-unified-garbage-collector","link":"/2020/02/26/jvm-GC-and-GC-Tuning/"},{"title":"《可复制的领导力》读后有感","text":"前言 2020年以来，一直想读一本关于管理类的书籍，前中央电视台主持人樊登创办了《樊登读书会》，仅用4年时间，付费会员人数便突破300万，发展势头非常良好。 樊登老师的《可复制的领导力》在京东商城管理类书籍排名第一，抱着高山仰止的心态，选择了这本书，进行拜读学习。 《樊登读书会》火爆带来的思考 在我高中的时候，学校来了一位中国最年轻的演讲家，在学校的大操场慷慨激昂，励志事迹娓娓道来，音响里重复播放着《感恩的心》，最后领着我们宣誓，让我们很多同学，尤其是女同学哭的稀里哗啦，最后很多人买了演讲家100多元的书。 《樊登读书会》能够为那些没有时间阅读、不知道阅读哪些书和阅读效率低下的人，每年吸收50本书的精华。旨在让更多的中国人爱上阅读，通过传播知识不断提升自己，造福社会。我恰好同学在参加了《樊登读书会》，故有了解一些，其大概每年收取365元会费，加入会属于班级以及小组，营造一种共同学习的氛围。读书的重要性不必自说，樊登老师是成功者，也毋庸讳言，不过加入这种每年付费的读书会，我个人感觉是非常不必要的，通过阅读其作品，领悟到其思想中精华就好了。 《可复制的领导力》读后有感一 樊登老师在该书中总结了一些关于管理的观点 1、领导力就是一个工具包，可习得、可复制、可传递。 感悟：大概类似两千多年前秦朝的陈胜吧，在地头里喊出”王侯将相，宁有种乎”。这本书也想向我们说明，管理能力不是某些人具备的一种天赋，也不是不可意会的艺术，而是人人都可以掌握的一种能力，跟学习语文、数学没什么区别。 2、团队是一只球队，而不是家，需要明确彼此的目标，才能更有效的合作； 感悟：建立一个团队目标，大家一起朝着目标努力。 3、管理者的几个关键步骤。 先建立感情，信任；再激发源动力，培养责任感；努力营造好的团队氛围；以身作则，知行合一； 良好的沟通，客观的反馈。 感悟：总结的很好； 《可复制的领导力》读后有感二 管理是一门科学，更是一门艺术。犹如看大豆结出果实。需要有种豆、浇水，施肥，开花，结果等等一系列的过程。管理能力虽说不是天生的，我们需要不断练习即可获得，但是也不要看完樊登老师举的”海底捞、麦当劳”成功小事例，就盲目自信，给自己一种很容易学习到的感觉。 《可复制的执行力》在京东商城管理类书籍排名第一，但在我看来，的确不能算一本好书。跟我看高中时买的演讲家自编的励志故事书味道差不多；一本书，一篇文章到底好不好，大概需要经历岁月的洗涤，历久弥新，给人以启发吧。买书学管理，我个人感觉还是不要看京东上热销的管理学的书了，别抱着太强的功利心了，或许读书更有启发吧；正如：孙子兵法第一句：”兵者，国之大事，死生之地，存亡之道，不可不察也”。孙子兵法流传千年，靠的不是打仗的小诀窍，而是站在民族、国家、军队的一个领导者一个应有的战略高度！","link":"/2020/03/22/%E3%80%8A%E5%8F%AF%E5%A4%8D%E5%88%B6%E7%9A%84%E9%A2%86%E5%AF%BC%E5%8A%9B%E3%80%8B%E8%AF%BB%E5%90%8E%E6%9C%89%E6%84%9F/"},{"title":"Kafka节点平滑迁移","text":"一，查看所有的topic1bin/kafka-topics.sh --zookeeper ip:port --list 二，将topic组装为JSON格式kafka后台脚本只支持如下JSON格式节点迁移 1234567{ \"topics\": [ { \"topic\": \"plat_order_core_dubbo_access_topic\" } ], \"version\": 1} 生成该格式代码，可参考使用如下Java代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849import com.alibaba.fastjson.JSONObject;import com.google.common.collect.Lists;import org.apache.commons.lang3.StringUtils; import java.io.BufferedReader;import java.io.InputStream;import java.io.InputStreamReader;import java.nio.charset.StandardCharsets;import java.util.ArrayList;import java.util.List; public class Topic2JsonUtil { public static void main(String[] args) { List topicList = readFileAsListFromJarPath(\"topic.txt\"); List topicJsonList = Lists.newArrayList(); topicList.forEach(topic -> { JSONObject topicJson = new JSONObject(); topicJson.put(\"topic\", topic); topicJsonList.add(topicJson); }); JSONObject resultJson = new JSONObject(); resultJson.put(\"topics\", topicJsonList); System.out.println(resultJson); } public static List readFileAsListFromJarPath(String fileName) { List result = new ArrayList(); try { InputStream inputStream = Topic2JsonUtil.class.getClassLoader().getResourceAsStream(fileName); BufferedReader reader = new BufferedReader(new InputStreamReader(inputStream, StandardCharsets.UTF_8)); String line; while ((line = reader.readLine()) != null) { if (StringUtils.isNotBlank(line)) { result.add(line); } } reader.close(); } catch (Exception e) { LogUtil.ROOT.error(\"\", e); } StringBuilder builder = new StringBuilder(); if (result.size() != 0) { result.forEach(builder::append); } return result; } } 三，生成迁移计划使用如下命令生成迁移计划如下示例代表将topic所有的节点数据重新路由到4、5、6节点上，并将迁移计划输出到plan-move.json文件中 1./bin/kafka-reassign-partitions.sh --zookeeper ip:port --topics-to-move-json-file topics-to-move.json --broker-list \"4,5,6\" --generate > plan-move.json 生成的计划格式化后如下： 1234567891011121314151617181920Current partition replica assignment{ \"version\": 1, \"partitions\": [{ \"topic\": \"erp_java_topic\", \"partition\": 9, \"replicas\": [12, 11, 13, 1], \"log_dirs\": [\"any\", \"any\", \"any\", \"any\"] }]}Proposed partition reassignment configuration{ \"version\": 1, \"partitions\": [{ \"topic\": \"erp_java_topic\", \"partition\": 9, \"replicas\": [4, 5, 6, 7], \"log_dirs\": [\"any\", \"any\", \"any\", \"any\"] }]} 保留迁移计划JSON，即下面的JSON内容； 四，执行迁移计划执行迁移计划 1./bin/kafka-reassign-partitions.sh --zookeeper ip:port --reassignment-json-file plan-move.json --execute 查看迁移进度 1./bin/kafka-reassign-partitions.sh --zookeeper ip:port --reassignment-json-file plan-move.json --verify","link":"/2020/04/23/Kafka%E8%8A%82%E7%82%B9%E5%B9%B3%E6%BB%91%E8%BF%81%E7%A7%BB%E6%AD%A5%E9%AA%A4/"},{"title":"Elasticsearch 之Doc Values","text":"一，Elasticsearch之keyword和textElasticsearch 5.0.0 版本之后 将string拆分成两个新的类型: text和keyword. Keyword类型: 用于存储邮箱号码、手机号码、主机名、状态码、邮政编码、标签、年龄、性别等数据。用于筛选数据(例如: select * from x where status=’open’)、排序、聚合(统计)。直接将完整的文本保存到倒排索引中。Text类型: 用于存储全文搜索数据, 例如: 邮箱内容、地址、代码块、博客文章内容等。默认结合standard analyzer(标准解析器)对文本进行分词、倒排索引。默认结合标准分析器进行词命中、词频相关度打分。 二，Elasticsearch之Doc Values正排索引：是以文档的ID为关键字，表中记录文档中每个字段的值信息，主要场景是通过查询id来把整条文档拿出来； Doc Values数据结构如下： 123456Doc Terms-----------------------------------------------------------------Doc_1 | brown, dog, fox, jumped, lazy, over, quick, theDoc_2 | brown, dogs, foxes, in, lazy, leap, over, quick, summerDoc_3 | dog, dogs, fox, jumped, over, quick, the----------------------------------------------------------------- 倒排索引：以字或词为关键字进行索引，表中关键字所对应的记录项记录了出现这个字或词的所有文档； 倒排索引数据结构如下： 12345678910111213141516Term Doc_1 Doc_2 Doc_3------------------------------------brown | X | X |dog | X | | Xdogs | | X | Xfox | X | | Xfoxes | | X |in | | X |jumped | X | | Xlazy | X | X |leap | | X |over | X | X | Xquick | X | X | Xsummer | | X |the | X | | X------------------------------------ 正排索引广泛应用在聚合、排序、访问字段值的脚本，父子关系处理（参见 父-子关系文档 ）等方面； 三，Doc Values 启用Doc Values 是在索引时与 倒排索引 同时生成。也就是说 Doc Values 和 倒排索引 一样，基于 Segement 生成并且是不可变的。同时 Doc Values 和 倒排索引 一样序列化到磁盘，这样对性能和扩展性有很大帮助。 Doc Values 通过序列化把数据结构持久化到磁盘，我们可以充分利用操作系统的内存，而不是 JVM 的 Heap 。 当 working set 远小于系统的可用内存，系统会自动将 Doc Values 驻留在内存中，使得其读写十分快速；不过，当其远大于可用内存时，系统会根据需要从磁盘读取 Doc Values，然后选择性放到分页缓存中。很显然，这样性能会比在内存中差很多，但是它的大小就不再局限于服务器的内存了。如果是使用 JVM 的 Heap 来实现那么只能是因为 OutOfMemory 导致程序崩溃了。 因为 Doc Values 不是由 JVM 来管理，所以 Elasticsearch 实例可以配置一个很小的 JVM Heap，这样给系统留出来更多的内存。同时更小的 Heap 可以让 JVM 更加快速和高效的回收。 之前，我们会建议分配机器内存的 50% 来给 JVM Heap。但是对于 Doc Values，这样可能不是最合适的方案了。 以 64gb 内存的机器为例，可能给 Heap 分配 4-16gb 的内存更合适，而不是 32gb。 有关更详细的讨论，查看 堆内存:大小和交换. Doc Values 默认对所有字段启用，除了 analyzed strings。也就是说所有的数字、地理坐标、日期、IP 和不分析（ not_analyzed ）字符类型都会默认开启。 四，Doc Values 实现细节从广义来说，Doc Values 本质上是一个序列化的 列式存储 。 正如我们上一节所讨论的，列式存储 适用于聚合、排序、脚本等操作。 而且，这种存储方式也非常便于压缩，特别是数字类型。这样可以减少磁盘空间并且提高访问速度。现代 CPU 的处理速度要比磁盘快几个数量级（尽管即将到来的 NVMe 驱动器正在迅速缩小差距）。所以我们必须减少直接存磁盘读取数据的大小，尽管需要额外消耗 CPU 运算用来进行解压。 要了解它如何压缩数据的，来看一组数字类型的 Doc Values： 12345678910Doc Terms-----------------------------------------------------------------Doc_1 | 100Doc_2 | 1000Doc_3 | 1500Doc_4 | 1200Doc_5 | 300Doc_6 | 1900Doc_7 | 4200----------------------------------------------------------------- 按列布局意味着我们有一个连续的数据块： [100,1000,1500,1200,300,1900,4200] 。因为我们已经知道他们都是数字（而不是像文档或行中看到的异构集合），所以我们可以使用统一的偏移来将他们紧紧排列。 而且，针对这样的数字有很多种压缩技巧。你会注意到这里每个数字都是 100 的倍数，Doc Values 会检测一个段里面的所有数值，并使用一个 最大公约数 ，方便做进一步的数据压缩。 如果我们保存 100 作为此段的除数，我们可以对每个数字都除以 100，然后得到： [1,10,15,12,3,19,42] 。现在这些数字变小了，只需要很少的位就可以存储下，也减少了磁盘存放的大小。 Doc Values 在压缩过程中使用如下技巧。它会按依次检测以下压缩模式: 如果所有的数值各不相同（或缺失），设置一个标记并记录这些值如果这些值小于 256，将使用一个简单的编码表如果这些值大于 256，检测是否存在一个最大公约数如果没有存在最大公约数，从最小的数值开始，统一计算偏移量进行编码你会发现这些压缩模式不是传统的通用的压缩方式，比如 DEFLATE 或是 LZ4。 因为列式存储的结构是严格且良好定义的，我们可以通过使用专门的模式来达到比通用压缩算法（如 LZ4 ）更高的压缩效果。 五，Doc Values 使用注意的问题除数字外，keyword类型默认也开启了Doc Values ，此时必须注意size必须","link":"/2020/05/11/Elasticsearch%E4%B9%8BDoc%20Values/"},{"title":"raft一致性协议","text":"1.raft是一个实现了解决分布式一致性问题的协议 2.分布式环境下的每个节点有三种状态： follower（跟随者） candidate（候选人） leader（领导者） 3.所有的节点开始都是follower状态 一旦他们不能检测到leader就能成为candidate candidate会请求其他节点投票，得到大多是节点的投票就会成为leader，这个过程叫做Leader Election 4.节点的每个改变都会增加节点的日志条目，提交之后leader会复制日志条目到从节点上，在大多数从节点成功增加日志条目之后，提交成功，leader值更新，leader通知从节点已经更新成功，从节点更新数据，这个过程叫做Log Replication。 5.Leader Election Raft有两个timeout设置来控制选举第一个是election timeout election timeout指的是follower等待成为candidate的时间，在150ms到300ms之间 election timeout一个follower成为一个开始一个election term 投票给自己，请求其他节点投票，在得到大多数节点投票之后，重置election timeout，成为leader第二个是HearBeat timeout Append Entries 在HeartBeat timeout时发送6.Log Replication Log Replicaiton是通过HeartBeat timeout发送Append Entries来完成的 客户端发送更新请求 leader增加日志条目 在下个HeartBeat时，日志变化发给follower 在大多数从节点成功之后，leader提交数据并响应客户端 下次HeartBeat Timeout之后，从节点数据更新 7，如何选主过程，可以参考学习该动画https://raft.github.io/raftscope/index.html","link":"/2020/10/19/raft%E4%B8%80%E8%87%B4%E6%80%A7%E5%8D%8F%E8%AE%AE/"},{"title":"Redis面试题","text":"1、什么是Redis?Redis 是完全开源免费的，遵守BSD协议，是一个高性能的key-value数据库。 Redis 与其他 key - value 缓存产品有以下三个特点：Redis支持数据的持久化，可以将内存中的数据保存在磁盘中，重启的时候可以再次加载进行使用。Redis不仅仅支持简单的key-value类型的数据，同时还提供list，set，zset，hash等数据结构的存储。Redis支持数据的备份，即master-slave模式的数据备份。 Redis 优势性能极高 – Redis能读的速度是110000次/s,写的速度是81000次/s 。丰富的数据类型 – Redis支持二进制案例的 Strings, Lists, Hashes, Sets 及 Ordered Sets 数据类型操作。原子 – Redis的所有操作都是原子性的，意思就是要么成功执行要么失败完全不执行。单个操作是原子性的。多个操作也支持事务，即原子性，通过MULTI和EXEC指令包起来。丰富的特性 – Redis还支持 publish/subscribe, 通知, key 过期等等特性。 Redis与其他key-value存储有什么不同？Redis有着更为复杂的数据结构并且提供对他们的原子性操作，这是一个不同于其他数据库的进化路径。Redis的数据类型都是基于基本数据结构的同时对程序员透明，无需进行额外的抽象。 Redis运行在内存中但是可以持久化到磁盘，所以在对不同数据集进行高速读写时需要权衡内存，因为数据量不能大于硬件内存。在内存数据库方面的另一个优点是，相比在磁盘上相同的复杂的数据结构，在内存中操作起来非常简单，这样Redis可以做很多内部复杂性很强的事情。同时，在磁盘格式方面他们是紧凑的以追加的方式产生的，因为他们并不需要进行随机访问。 2、Redis的数据类型？答：Redis支持五种数据类型：string（字符串），hash（哈希），list（列表），set（集合）及zsetsorted set：有序集合)。 我们实际项目中比较常用的是string，hash如果你是Redis中高级用户，还需要加上下面几种数据结构HyperLogLog、Geo、Pub/Sub。 如果你说还玩过Redis Module，像BloomFilter，RedisSearch，Redis-ML，面试官得眼睛就开始发亮了。 3、使用Redis有哪些好处？1、速度快，因为数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度都是O1) 2、支持丰富数据类型，支持string，list，set，Zset，hash等 3、支持事务，操作都是原子性，所谓的原子性就是对数据的更改要么全部执行，要么全部不执行 4、丰富的特性：可用于缓存，消息，按key设置过期时间，过期后将会自动删除 4、Redis相比Memcached有哪些优势？1、Memcached所有的值均是简单的字符串，redis作为其替代者，支持更为丰富的数据类2、Redis的速度比Memcached快很3、Redis可以持久化其数据 5、Memcache与Redis的区别都有哪些？1、存储方式 Memecache把数据全部存在内存之中，断电后会挂掉，数据不能超过内存大小。Redis有部份存在硬盘上，这样能保证数据的持久性。 2、数据支持类型 Memcache对数据类型支持相对简单。Redis有复杂的数据类型。 3、使用底层模型不同 它们之间底层实现方式 以及与客户端之间通信的应用协议不一样。Redis直接自己构建了VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求。 6、Redis是单进程单线程的？答：Redis是单进程单线程的，redis利用队列技术将并发访问变为串行访问，消除了传统数据库串行控制的开销。 7、一个字符串类型的值能存储最大容量是多少？答：512M 8、Redis的持久化机制是什么？各自的优缺点？Redis提供两种持久化机制RDB和AOF机制:1、RDBRedis DataBase)持久化方式：是指用数据集快照的方式半持久化模式)记录redis数据库的所有键值对,在某个时间点将数据写入一个临时文件，持久化结束后，用这个临时文件替换上次持久化的文件，达到数据恢复。 优点：1、只有一个文件dump.rdb，方便持久化。 2、容灾性好，一个文件可以保存到安全的磁盘。 3、性能最大化，fork子进程来完成写操作，让主进程继续处理命令，所以是IO最大化。使用单独子进程来进行持久化，主进程不会进行任何IO操作，保证了redis的高性能) 4.相对于数据集大时，比AOF的启动效率更高。 缺点：1、数据安全性低。RDB是间隔一段时间进行持久化，如果持久化之间redis发生故障，会发生数据丢失。所以这种方式更适合数据要求不严谨的时候) 2、AOFAppend-only file)持久化方式：是指所有的命令行记录以redis命令请求协议的格式完全持久化存储)保存为aof文件。 优点：1、数据安全，aof持久化可以配置appendfsync属性，有always，每进行一次命令操作就记录到aof文件中一次。 2、通过append模式写文件，即使中途服务器宕机，可以通过redis-check-aof工具解决数据一致性问题。 3、AOF机制的rewrite模式。AOF文件没被rewrite之前（文件过大时会对命令进行合并重写），可以删除其中的某些命令（比如误操作的flushall）) 缺点：1、AOF文件比RDB文件大，且恢复速度慢。2、数据集大的时候，比rdb启动效率低。 9、Redis常见性能问题和解决方案：1、Master最好不要写内存快照，如果Master写内存快照，save命令调度rdbSave函数，会阻塞主线程的工作，当快照比较大时对性能影响是非常大的，会间断性暂停服务 2、如果数据比较重要，某个Slave开启AOF备份数据，策略设置为每秒同步一 3、为了主从复制的速度和连接的稳定性，Master和Slave最好在同一个局域网 4、尽量避免在压力很大的主库上增加从 5、主从复制不要用图状结构，用单向链表结构更为稳定，即：Master","link":"/2020/10/19/Redis%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"title":"Redis面试题2","text":"概述什么是RedisRedis(Remote Dictionary Server) 是一个使用 C 语言编写的，开源的（BSD许可）高性能非关系型（NoSQL）的键值对数据库。Redis 可以存储键和五种不同类型的值之间的映射。键的类型只能为字符串，值支持五种数据类型：字符串、列表、集合、散列表、有序集合。与传统数据库不同的是 Redis 的数据是存在内存中的，所以读写速度非常快，因此 redis 被广泛应用于缓存方向，每秒可以处理超过 10万次读写操作，是已知性能最快的Key-Value DB。另外，Redis 也经常用来做分布式锁。除此之外，Redis 支持事务 、持久化、LUA脚本、LRU驱动事件、多种集群方案。Redis有哪些优缺点优点读写性能优异， Redis能读的速度是110000次/s，写的速度是81000次/s。支持数据持久化，支持AOF和RDB两种持久化方式。支持事务，Redis的所有操作都是原子性的，同时Redis还支持对几个操作合并后的原子性执行。数据结构丰富，除了支持string类型的value外还支持hash、set、zset、list等数据结构。支持主从复制，主机会自动将数据同步到从机，可以进行读写分离。缺点数据库容量受到物理内存的限制，不能用作海量数据的高性能读写，因此Redis适合的场景主要局限在较小数据量的高性能操作和运算上。Redis 不具备自动容错和恢复功能，主机从机的宕机都会导致前端部分读写请求失败，需要等待机器重启或者手动切换前端的IP才能恢复。主机宕机，宕机前有部分数据未能及时同步到从机，切换IP后还会引入数据不一致的问题，降低了系统的可用性。Redis 较难支持在线扩容，在集群容量达到上限时在线扩容会变得很复杂。为避免这一问题，运维人员在系统上线时必须确保有足够的空间，这对资源造成了很大的浪费。为什么要用 Redis /为什么要用缓存主要从“高性能”和“高并发”这两点来看待这个问题。高性能：假如用户第一次访问数据库中的某些数据。这个过程会比较慢，因为是从硬盘上读取的。将该用户访问的数据存在数缓存中，这样下一次再访问这些数据的时候就可以直接从缓存中获取了。操作缓存就是直接操作内存，所以速度相当快。如果数据库中的对应数据改变的之后，同步改变缓存中相应的数据即可！ 高并发：直接操作缓存能够承受的请求是远远大于直接访问数据库的，所以我们可以考虑把数据库中的部分数据转移到缓存中去，这样用户的一部分请求会直接到缓存这里而不用经过数据库。 为什么要用 Redis 而不用 map/guava 做缓存?缓存分为本地缓存和分布式缓存。以 Java 为例，使用自带的 map 或者 guava 实现的是本地缓存，最主要的特点是轻量以及快速，生命周期随着 jvm 的销毁而结束，并且在多实例的情况下，每个实例都需要各自保存一份缓存，缓存不具有一致性。使用 redis 或 memcached 之类的称为分布式缓存，在多实例的情况下，各实例共用一份缓存数据，缓存具有一致性。缺点是需要保持 redis 或 memcached服务的高可用，整个程序架构上较为复杂。Redis为什么这么快1、完全基于内存，绝大部分请求是纯粹的内存操作，非常快速。数据存在内存中，类似于 HashMap，HashMap 的优势就是查找和操作的时间复杂度都是O(1)；2、数据结构简单，对数据操作也简单，Redis 中的数据结构是专门进行设计的；3、采用单线程，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗 CPU，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗；4、使用多路 I/O 复用模型，非阻塞 IO；5、使用底层模型不同，它们之间底层实现方式以及与客户端之间通信的应用协议不一样，Redis 直接自己构建了 VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求；数据类型Redis有哪些数据类型Redis主要有5种数据类型，包括String，List，Set，Zset，Hash，满足大部分的使用要求数据类型 可以存储的值 操作 应用场景STRING 字符串、整数或者浮点数 对整个字符串或者字符串的其中一部分执行操作对整数和浮点数执行自增或者自减操作 做简单的键值对缓存LIST 列表 从两端压入或者弹出元素对单个或者多个元素进行修剪，只保留一个范围内的元素 存储一些列表型的数据结构，类似粉丝列表、文章的评论列表之类的数据SET 无序集合 添加、获取、移除单个元素检查一个元素是否存在于集合中计算交集、并集、差集从集合里面随机获取元素 交集、并集、差集的操作，比如交集，可以把两个人的粉丝列表整一个交集HASH 包含键值对的无序散列表 添加、获取、移除单个键值对获取所有键值对检查某个键是否存在 结构化的数据，比如一个对象ZSET 有序集合 添加、获取、删除元素根据分值范围或者成员来获取元素计算一个键的排名 去重但可以排序，如获取排名前几名的用户Redis的应用场景总结一计数器可以对 String 进行自增自减运算，从而实现计数器功能。Redis 这种内存型数据库的读写性能非常高，很适合存储频繁读写的计数量。缓存将热点数据放到内存中，设置内存的最大使用量以及淘汰策略来保证缓存的命中率。会话缓存可以使用 Redis 来统一存储多台应用服务器的会话信息。当应用服务器不再存储用户的会话信息，也就不再具有状态，一个用户可以请求任意一个应用服务器，从而更容易实现高可用性以及可伸缩性。全页缓存（FPC）除基本的会话token之外，Redis还提供很简便的FPC平台。以Magento为例，Magento提供一个插件来使用Redis作为全页缓存后端。此外，对WordPress的用户来说，Pantheon有一个非常好的插件 wp-redis，这个插件能帮助你以最快速度加载你曾浏览过的页面。查找表例如 DNS 记录就很适合使用 Redis 进行存储。查找表和缓存类似，也是利用了 Redis 快速的查找特性。但是查找表的内容不能失效，而缓存的内容可以失效，因为缓存不作为可靠的数据来源。消息队列(发布/订阅功能)List 是一个双向链表，可以通过 lpush 和 rpop 写入和读取消息。不过最好使用 Kafka、RabbitMQ 等消息中间件。分布式锁实现在分布式场景下，无法使用单机环境下的锁来对多个节点上的进程进行同步。可以使用 Redis 自带的 SETNX 命令实现分布式锁，除此之外，还可以使用官方提供的 RedLock 分布式锁实现。其它Set 可以实现交集、并集等操作，从而实现共同好友等功能。ZSet 可以实现有序性操作，从而实现排行榜等功能。总结二Redis相比其他缓存，有一个非常大的优势，就是支持多种数据类型。数据类型说明string字符串，最简单的k-v存储hashhash格式，value为field和value，适合ID-Detail这样的场景。list简单的list，顺序列表，支持首位或者末尾插入数据set无序list，查找速度快，适合交集、并集、差集处理sorted set有序的set其实，通过上面的数据类型的特性，基本就能想到合适的应用场景了。string——适合最简单的k-v存储，类似于memcached的存储结构，短信验证码，配置信息等，就用这种类型来存储。hash——一般key为ID或者唯一标示，value对应的就是详情了。如商品详情，个人信息详情，新闻详情等。list——因为list是有序的，比较适合存储一些有序且数据相对固定的数据。如省市区表、字典表等。因为list是有序的，适合根据写入的时间来排序，如：最新的***，消息队列等。set——可以简单的理解为ID-List的模式，如微博中一个人有哪些好友，set最牛的地方在于，可以对两个set提供交集、并集、差集操作。例如：查找两个人共同的好友等。Sorted Set——是set的增强版本，增加了一个score参数，自动会根据score的值进行排序。比较适合类似于top 10等不根据插入的时间来排序的数据。如上所述，虽然Redis不像关系数据库那么复杂的数据结构，但是，也能适合很多场景，比一般的缓存数据结构要多。了解每种数据结构适合的业务场景，不仅有利于提升开发效率，也能有效利用Redis的性能。持久化什么是Redis持久化？持久化就是把内存的数据写到磁盘中去，防止服务宕机了内存数据丢失。Redis 的持久化机制是什么？各自的优缺点？Redis 提供两种持久化机制 RDB（默认） 和 AOF 机制:RDB：是Redis DataBase缩写快照RDB是Redis默认的持久化方式。按照一定的时间将内存的数据以快照的形式保存到硬盘中，对应产生的数据文件为dump.rdb。通过配置文件中的save参数来定义快照的周期。 优点：1、只有一个文件 dump.rdb，方便持久化。2、容灾性好，一个文件可以保存到安全的磁盘。3、性能最大化，fork 子进程来完成写操作，让主进程继续处理命令，所以是 IO 最大化。使用单独子进程来进行持久化，主进程不会进行任何 IO 操作，保证了 redis 的高性能4.相对于数据集大时，比 AOF 的启动效率更高。缺点：1、数据安全性低。RDB 是间隔一段时间进行持久化，如果持久化之间 redis 发生故障，会发生数据丢失。所以这种方式更适合数据要求不严谨的时候)2、AOF（Append-only file)持久化方式： 是指所有的命令行记录以 redis 命令请 求协议的格式完全持久化存储)保存为 aof 文件。AOF：持久化AOF持久化(即Append Only File持久化)，则是将Redis执行的每次写命令记录到单独的日志文件中，当重启Redis会重新将持久化的日志中文件恢复数据。当两种方式同时开启时，数据恢复Redis会优先选择AOF恢复。 优点：1、数据安全，aof 持久化可以配置 appendfsync 属性，有 always，每进行一次 命令操作就记录到 aof 文件中一次。2、通过 append 模式写文件，即使中途服务器宕机，可以通过 redis-check-aof 工具解决数据一致性问题。3、AOF 机制的 rewrite 模式。AOF 文件没被 rewrite 之前（文件过大时会对命令 进行合并重写），可以删除其中的某些命令（比如误操作的 flushall）)缺点：1、AOF 文件比 RDB 文件大，且恢复速度慢。2、数据集大的时候，比 rdb 启动效率低。优缺点是什么？AOF文件比RDB更新频率高，优先使用AOF还原数据。AOF比RDB更安全也更大RDB性能比AOF好如果两个都配了优先加载AOF如何选择合适的持久化方式一般来说， 如果想达到足以媲美PostgreSQL的数据安全性，你应该同时使用两种持久化功能。在这种情况下，当 Redis 重启的时候会优先载入AOF文件来恢复原始的数据，因为在通常情况下AOF文件保存的数据集要比RDB文件保存的数据集要完整。如果你非常关心你的数据， 但仍然可以承受数分钟以内的数据丢失，那么你可以只使用RDB持久化。有很多用户都只使用AOF持久化，但并不推荐这种方式，因为定时生成RDB快照（snapshot）非常便于进行数据库备份， 并且 RDB 恢复数据集的速度也要比AOF恢复的速度要快，除此之外，使用RDB还可以避免AOF程序的bug。如果你只希望你的数据在服务器运行的时候存在，你也可以不使用任何持久化方式。Redis持久化数据和缓存怎么做扩容？如果Redis被当做缓存使用，使用一致性哈希实现动态扩容缩容。如果Redis被当做一个持久化存储使用，必须使用固定的keys-to-nodes映射关系，节点的数量一旦确定不能变化。否则的话(即Redis节点需要动态变化的情况），必须使用可以在运行时进行数据再平衡的一套系统，而当前只有Redis集群可以做到这样。过期键的删除策略Redis的过期键的删除策略我们都知道，Redis是key-value数据库，我们可以设置Redis中缓存的key的过期时间。Redis的过期策略就是指当Redis中缓存的key过期了，Redis如何处理。过期策略通常有以下三种：定时过期：每个设置过期时间的key都需要创建一个定时器，到过期时间就会立即清除。该策略可以立即清除过期的数据，对内存很友好；但是会占用大量的CPU资源去处理过期的数据，从而影响缓存的响应时间和吞吐量。惰性过期：只有当访问一个key时，才会判断该key是否已过期，过期则清除。该策略可以最大化地节省CPU资源，却对内存非常不友好。极端情况可能出现大量的过期key没有再次被访问，从而不会被清除，占用大量内存。定期过期：每隔一定的时间，会扫描一定数量的数据库的expires字典中一定数量的key，并清除其中已过期的key。该策略是前两者的一个折中方案。通过调整定时扫描的时间间隔和每次扫描的限定耗时，可以在不同情况下使得CPU和内存资源达到最优的平衡效果。(expires字典会保存所有设置了过期时间的key的过期时间数据，其中，key是指向键空间中的某个键的指针，value是该键的毫秒精度的UNIX时间戳表示的过期时间。键空间是指该Redis集群中保存的所有键。)Redis中同时使用了惰性过期和定期过期两种过期策略。Redis key的过期时间和永久有效分别怎么设置？EXPIRE和PERSIST命令。我们知道通过expire来设置key 的过期时间，那么对过期的数据怎么处理呢?除了缓存服务器自带的缓存失效策略之外（Redis默认的有6中策略可供选择），我们还可以根据具体的业务需求进行自定义的缓存淘汰，常见的策略有两种：1.定时去清理过期的缓存；2.3.当有用户请求过来时，再判断这个请求所用到的缓存是否过期，过期的话就去底层系统得到新数据并更新缓存。4.两者各有优劣，第一种的缺点是维护大量缓存的key是比较麻烦的，第二种的缺点就是每次用户请求过来都要判断缓存失效，逻辑相对比较复杂！具体用哪种方案，大家可以根据自己的应用场景来权衡。内存相关MySQL里有2000w数据，redis中只存20w的数据，如何保证redis中的数据都是热点数据redis内存数据集大小上升到一定大小的时候，就会施行数据淘汰策略。Redis的内存淘汰策略有哪些Redis的内存淘汰策略是指在Redis的用于缓存的内存不足时，怎么处理需要新写入且需要申请额外空间的数据。全局的键空间选择性移除noeviction：当内存不足以容纳新写入数据时，新写入操作会报错。allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key。（这个是最常用的）allkeys-random：当内存不足以容纳新写入数据时，在键空间中，随机移除某个key。设置过期时间的键空间选择性移除volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的key。volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个key。volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的key优先移除。总结Redis的内存淘汰策略的选取并不会影响过期的key的处理。内存淘汰策略用于处理内存不足时的需要申请额外空间的数据；过期策略用于处理过期的缓存数据。Redis主要消耗什么物理资源？内存。Redis的内存用完了会发生什么？如果达到设置的上限，Redis的写命令会返回错误信息（但是读命令还可以正常返回。）或者你可以配置内存淘汰机制，当Redis达到内存上限时会冲刷掉旧的内容。Redis如何做内存优化？可以好好利用Hash,list,sorted set,set等集合类型数据，因为通常情况下很多小的Key-Value可以用更紧凑的方式存放到一起。尽可能使用散列表（hashes），散列表（是说散列表里面存储的数少）使用的内存非常小，所以你应该尽可能的将你的数据模型抽象到一个散列表里面。比如你的web系统中有一个用户对象，不要为这个用户的名称，姓氏，邮箱，密码设置单独的key，而是应该把这个用户的所有信息存储到一张散列表里面线程模型Redis线程模型Redis基于Reactor模式开发了网络事件处理器，这个处理器被称为文件事件处理器（file event handler）。它的组成结构为4部分：多个套接字、IO多路复用程序、文件事件分派器、事件处理器。因为文件事件分派器队列的消费是单线程的，所以Redis才叫单线程模型。文件事件处理器使用 I/O 多路复用（multiplexing）程序来同时监听多个套接字， 并根据套接字目前执行的任务来为套接字关联不同的事件处理器。当被监听的套接字准备好执行连接应答（accept）、读取（read）、写入（write）、关闭（close）等操作时， 与操作相对应的文件事件就会产生， 这时文件事件处理器就会调用套接字之前关联好的事件处理器来处理这些事件。虽然文件事件处理器以单线程方式运行， 但通过使用 I/O 多路复用程序来监听多个套接字， 文件事件处理器既实现了高性能的网络通信模型， 又可以很好地与 redis 服务器中其他同样以单线程方式运行的模块进行对接， 这保持了 Redis 内部单线程设计的简单性。参考：https://www.cnblogs.com/barrywxx/p/8570821.html事务什么是事务？事务是一个单独的隔离操作：事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。事务是一个原子操作：事务中的命令要么全部被执行，要么全部都不执行。Redis事务的概念Redis 事务的本质是通过MULTI、EXEC、WATCH等一组命令的集合。事务支持一次执行多个命令，一个事务中所有命令都会被序列化。在事务执行过程，会按照顺序串行化执行队列中的命令，其他客户端提交的命令请求不会插入到事务执行命令序列中。总结说：redis事务就是一次性、顺序性、排他性的执行一个队列中的一系列命令。Redis事务的三个阶段1.事务开始 MULTI2.命令入队3.事务执行 EXEC事务执行过程中，如果服务端收到有EXEC、DISCARD、WATCH、MULTI之外的请求，将会把请求放入队列中排队Redis事务相关命令Redis事务功能是通过MULTI、EXEC、DISCARD和WATCH 四个原语实现的Redis会将一个事务中的所有命令序列化，然后按顺序执行。1.redis 不支持回滚，“Redis 在事务失败时不进行回滚，而是继续执行余下的命令”， 所以 Redis 的内部可以保持简单且快速。2.如果在一个事务中的命令出现错误，那么所有的命令都不会执行；3.如果在一个事务中出现运行错误，那么正确的命令会被执行。WATCH 命令是一个乐观锁，可以为 Redis 事务提供 check-and-set （CAS）行为。 可以监控一个或多个键，一旦其中有一个键被修改（或删除），之后的事务就不会执行，监控一直持续到EXEC命令。MULTI命令用于开启一个事务，它总是返回OK。 MULTI执行之后，客户端可以继续向服务器发送任意多条命令，这些命令不会立即被执行，而是被放到一个队列中，当EXEC命令被调用时，所有队列中的命令才会被执行。EXEC：执行所有事务块内的命令。返回事务块内所有命令的返回值，按命令执行的先后顺序排列。 当操作被打断时，返回空值 nil 。通过调用DISCARD，客户端可以清空事务队列，并放弃执行事务， 并且客户端会从事务状态中退出。UNWATCH命令可以取消watch对所有key的监控。事务管理（ACID）概述原子性（Atomicity）原子性是指事务是一个不可分割的工作单位，事务中的操作要么都发生，要么都不发生。一致性（Consistency）事务前后数据的完整性必须保持一致。隔离性（Isolation）多个事务并发执行时，一个事务的执行不应影响其他事务的执行持久性（Durability）持久性是指一个事务一旦被提交，它对数据库中数据的改变就是永久性的，接下来即使数据库发生故障也不应该对其有任何影响Redis的事务总是具有ACID中的一致性和隔离性，其他特性是不支持的。当服务器运行在AOF持久化模式下，并且appendfsync选项的值为always时，事务也具有耐久性。Redis事务支持隔离性吗Redis 是单进程程序，并且它保证在执行事务时，不会对事务进行中断，事务可以运行直到执行完所有事务队列中的命令为止。因此，Redis 的事务是总是带有隔离性的。Redis事务保证原子性吗，支持回滚吗Redis中，单条命令是原子性执行的，但事务不保证原子性，且没有回滚。事务中任意命令执行失败，其余的命令仍会被执行。Redis事务其他实现基于Lua脚本，Redis可以保证脚本内的命令一次性、按顺序地执行，其同时也不提供事务运行错误的回滚，执行过程中如果部分命令运行错误，剩下的命令还是会继续运行完基于中间标记变量，通过另外的标记变量来标识事务是否执行完成，读取数据时先读取该标记变量判断是否事务执行完成。但这样会需要额外写代码实现，比较繁琐集群方案哨兵模式 哨兵的介绍sentinel，中文名是哨兵。哨兵是 redis 集群机构中非常重要的一个组件，主要有以下功能：集群监控：负责监控 redis master 和 slave 进程是否正常工作。消息通知：如果某个 redis 实例有故障，那么哨兵负责发送消息作为报警通知给管理员。故障转移：如果 master node 挂掉了，会自动转移到 slave node 上。配置中心：如果故障转移发生了，通知 client 客户端新的 master 地址。哨兵用于实现 redis 集群的高可用，本身也是分布式的，作为一个哨兵集群去运行，互相协同工作。故障转移时，判断一个 master node 是否宕机了，需要大部分的哨兵都同意才行，涉及到了分布式选举的问题。即使部分哨兵节点挂掉了，哨兵集群还是能正常工作的，因为如果一个作为高可用机制重要组成部分的故障转移系统本身是单点的，那就很坑爹了。哨兵的核心知识哨兵至少需要 3 个实例，来保证自己的健壮性。哨兵 + redis 主从的部署架构，是不保证数据零丢失的，只能保证 redis 集群的高可用性。对于哨兵 + redis 主从这种复杂的部署架构，尽量在测试环境和生产环境，都进行充足的测试和演练。官方Redis Cluster 方案(服务端路由查询) redis 集群模式的工作原理能说一下么？在集群模式下，redis 的 key 是如何寻址的？分布式寻址都有哪些算法？了解一致性 hash 算法吗？简介Redis Cluster是一种服务端Sharding技术，3.0版本开始正式提供。Redis Cluster并没有使用一致性hash，而是采用slot(槽)的概念，一共分成16384个槽。将请求发送到任意节点，接收到请求的节点会将查询请求发送到正确的节点上执行方案说明1.通过哈希的方式，将数据分片，每个节点均分存储一定哈希槽(哈希值)区间的数据，默认分配了16384 个槽位2.每份数据分片会存储在多个互为主从的多节点上3.数据写入先写主节点，再同步到从节点(支持配置为阻塞同步)4.同一分片多个节点间的数据不保持一致性5.读取数据时，当客户端操作的key没有分配在该节点上时，redis会返回转向指令，指向正确的节点6.扩容时时需要需要把旧节点的数据迁移一部分到新节点在 redis cluster 架构下，每个 redis 要放开两个端口号，比如一个是 6379，另外一个就是 加1w 的端口号，比如 16379。16379 端口号是用来进行节点间通信的，也就是 cluster bus 的东西，cluster bus 的通信，用来进行故障检测、配置更新、故障转移授权。cluster bus 用了另外一种二进制的协议，gossip 协议，用于节点间进行高效的数据交换，占用更少的网络带宽和处理时间。节点间的内部通信机制基本通信原理集群元数据的维护有两种方式：集中式、Gossip 协议。redis cluster 节点间采用 gossip 协议进行通信。分布式寻址算法hash 算法（大量缓存重建）一致性 hash 算法（自动缓存迁移）+ 虚拟节点（自动负载均衡）redis cluster 的 hash slot 算法优点无中心架构，支持动态扩容，对业务透明具备Sentinel的监控和自动Failover(故障转移)能力客户端不需要连接集群所有节点，连接集群中任何一个可用节点即可高性能，客户端直连redis服务，免去了proxy代理的损耗缺点运维也很复杂，数据迁移需要人工干预只能使用0号数据库不支持批量操作(pipeline管道操作)分布式逻辑和存储模块耦合等基于客户端分配 简介Redis Sharding是Redis Cluster出来之前，业界普遍使用的多Redis实例集群方法。其主要思想是采用哈希算法将Redis数据的key进行散列，通过hash函数，特定的key会映射到特定的Redis节点上。Java redis客户端驱动jedis，支持Redis Sharding功能，即ShardedJedis以及结合缓存池的ShardedJedisPool优点优势在于非常简单，服务端的Redis实例彼此独立，相互无关联，每个Redis实例像单服务器一样运行，非常容易线性扩展，系统的灵活性很强缺点由于sharding处理放到客户端，规模进一步扩大时给运维带来挑战。客户端sharding不支持动态增删节点。服务端Redis实例群拓扑结构有变化时，每个客户端都需要更新调整。连接不能共享，当应用规模增大时，资源浪费制约优化基于代理服务器分片 简介客户端发送请求到一个代理组件，代理解析客户端的数据，并将请求转发至正确的节点，最后将结果回复给客户端特征透明接入，业务程序不用关心后端Redis实例，切换成本低Proxy 的逻辑和存储的逻辑是隔离的代理层多了一次转发，性能有所损耗业界开源方案Twtter开源的Twemproxy豌豆荚开源的CodisRedis 主从架构单机的 redis，能够承载的 QPS 大概就在上万到几万不等。对于缓存来说，一般都是用来支撑读高并发的。因此架构做成主从(master-slave)架构，一主多从，主负责写，并且将数据复制到其它的 slave 节点，从节点负责读。所有的读请求全部走从节点。这样也可以很轻松实现水平扩容，支撑读高并发。 redis replication -> 主从架构 -> 读写分离 -> 水平扩容支撑读高并发redis replication 的核心机制redis 采用异步方式复制数据到 slave 节点，不过 redis2.8 开始，slave node 会周期性地确认自己每次复制的数据量；一个 master node 是可以配置多个 slave node 的；slave node 也可以连接其他的 slave node；slave node 做复制的时候，不会 block master node 的正常工作；slave node 在做复制的时候，也不会 block 对自己的查询操作，它会用旧的数据集来提供服务；但是复制完成的时候，需要删除旧数据集，加载新数据集，这个时候就会暂停对外服务了；slave node 主要用来进行横向扩容，做读写分离，扩容的 slave node 可以提高读的吞吐量。注意，如果采用了主从架构，那么建议必须开启 master node 的持久化，不建议用 slave node 作为 master node 的数据热备，因为那样的话，如果你关掉 master 的持久化，可能在 master 宕机重启的时候数据是空的，然后可能一经过复制， slave node 的数据也丢了。另外，master 的各种备份方案，也需要做。万一本地的所有文件丢失了，从备份中挑选一份 rdb 去恢复 master，这样才能确保启动的时候，是有数据的，即使采用了后续讲解的高可用机制，slave node 可以自动接管 master node，但也可能 sentinel 还没检测到 master failure，master node 就自动重启了，还是可能导致上面所有的 slave node 数据被清空。redis 主从复制的核心原理当启动一个 slave node 的时候，它会发送一个 PSYNC 命令给 master node。如果这是 slave node 初次连接到 master node，那么会触发一次 full resynchronization 全量复制。此时 master 会启动一个后台线程，开始生成一份 RDB 快照文件，同时还会将从客户端 client 新收到的所有写命令缓存在内存中。RDB 文件生成完毕后， master 会将这个 RDB 发送给 slave，slave 会先写入本地磁盘，然后再从本地磁盘加载到内存中，接着 master 会将内存中缓存的写命令发送到 slave，slave 也会同步这些数据。slave node 如果跟 master node 有网络故障，断开了连接，会自动重连，连接之后 master node 仅会复制给 slave 部分缺少的数据。 过程原理1.当从库和主库建立MS关系后，会向主数据库发送SYNC命令2.主库接收到SYNC命令后会开始在后台保存快照(RDB持久化过程)，并将期间接收到的写命令缓存起来3.当快照完成后，主Redis会将快照文件和所有缓存的写命令发送给从Redis4.从Redis接收到后，会载入快照文件并且执行收到的缓存的命令5.之后，主Redis每当接收到写命令时就会将命令发送从Redis，从而保证数据的一致缺点所有的slave节点数据的复制和同步都由master节点来处理，会照成master节点压力太大，使用主从从结构来解决Redis集群的主从复制模型是怎样的？为了使在部分节点失败或者大部分节点无法通信的情况下集群仍然可用，所以集群使用了主从复制模型，每个节点都会有N-1个复制品生产环境中的 redis 是怎么部署的？redis cluster，10 台机器，5 台机器部署了 redis 主实例，另外 5 台机器部署了 redis 的从实例，每个主实例挂了一个从实例，5 个节点对外提供读写服务，每个节点的读写高峰qps可能可以达到每秒 5 万，5 台机器最多是 25 万读写请求/s。机器是什么配置？32G 内存+ 8 核 CPU + 1T 磁盘，但是分配给 redis 进程的是10g内存，一般线上生产环境，redis 的内存尽量不要超过 10g，超过 10g 可能会有问题。5 台机器对外提供读写，一共有 50g 内存。因为每个主实例都挂了一个从实例，所以是高可用的，任何一个主实例宕机，都会自动故障迁移，redis 从实例会自动变成主实例继续提供读写服务。你往内存里写的是什么数据？每条数据的大小是多少？商品数据，每条数据是 10kb。100 条数据是 1mb，10 万条数据是 1g。常驻内存的是 200 万条商品数据，占用内存是 20g，仅仅不到总内存的 50%。目前高峰期每秒就是 3500 左右的请求量。其实大型的公司，会有基础架构的 team 负责缓存集群的运维。说说Redis哈希槽的概念？Redis集群没有使用一致性hash,而是引入了哈希槽的概念，Redis集群有16384个哈希槽，每个key通过CRC16校验后对16384取模来决定放置哪个槽，集群的每个节点负责一部分hash槽。Redis集群会有写操作丢失吗？为什么？Redis并不能保证数据的强一致性，这意味这在实际中集群在特定的条件下可能会丢失写操作。Redis集群之间是如何复制的？异步复制Redis集群最大节点个数是多少？16384个Redis集群如何选择数据库？Redis集群目前无法做数据库选择，默认在0数据库。分区Redis是单线程的，如何提高多核CPU的利用率？可以在同一个服务器部署多个Redis的实例，并把他们当作不同的服务器来使用，在某些时候，无论如何一个服务器是不够的， 所以，如果你想使用多个CPU，你可以考虑一下分片（shard）。为什么要做Redis分区？分区可以让Redis管理更大的内存，Redis将可以使用所有机器的内存。如果没有分区，你最多只能使用一台机器的内存。分区使Redis的计算能力通过简单地增加计算机得到成倍提升，Redis的网络带宽也会随着计算机和网卡的增加而成倍增长。你知道有哪些Redis分区实现方案？客户端分区就是在客户端就已经决定数据会被存储到哪个redis节点或者从哪个redis节点读取。大多数客户端已经实现了客户端分区。代理分区 意味着客户端将请求发送给代理，然后代理决定去哪个节点写数据或者读数据。代理根据分区规则决定请求哪些Redis实例，然后根据Redis的响应结果返回给客户端。redis和memcached的一种代理实现就是Twemproxy查询路由(Query routing) 的意思是客户端随机地请求任意一个redis实例，然后由Redis将请求转发给正确的Redis节点。Redis Cluster实现了一种混合形式的查询路由，但并不是直接将请求从一个redis节点转发到另一个redis节点，而是在客户端的帮助下直接redirected到正确的redis节点。Redis分区有什么缺点？涉及多个key的操作通常不会被支持。例如你不能对两个集合求交集，因为他们可能被存储到不同的Redis实例（实际上这种情况也有办法，但是不能直接使用交集指令）。同时操作多个key,则不能使用Redis事务.分区使用的粒度是key，不能使用一个非常长的排序key存储一个数据集（The partitioning granularity is the key, so it is not possible to shard a dataset with a single huge key like a very big sorted set）当使用分区的时候，数据处理会非常复杂，例如为了备份你必须从不同的Redis实例和主机同时收集RDB / AOF文件。分区时动态扩容或缩容可能非常复杂。Redis集群在运行时增加或者删除Redis节点，能做到最大程度对用户透明地数据再平衡，但其他一些客户端分区或者代理分区方法则不支持这种特性。然而，有一种预分片的技术也可以较好的解决这个问题。分布式问题Redis实现分布式锁Redis为单进程单线程模式，采用队列模式将并发访问变成串行访问，且多客户端对Redis的连接并不存在竞争关系Redis中可以使用SETNX命令实现分布式锁。当且仅当 key 不存在，将 key 的值设为 value。 若给定的 key 已经存在，则 SETNX 不做任何动作SETNX 是『SET if Not eXists』(如果不存在，则 SET)的简写。返回值：设置成功，返回 1 。设置失败，返回 0 。 使用SETNX完成同步锁的流程及事项如下：使用SETNX命令获取锁，若返回0（key已存在，锁已存在）则获取失败，反之获取成功为了防止获取锁后程序出现异常，导致其他线程/进程调用SETNX命令总是返回0而进入死锁状态，需要为该key设置一个“合理”的过期时间释放锁，使用DEL命令将锁数据删除如何解决 Redis 的并发竞争 Key 问题所谓 Redis 的并发竞争 Key 的问题也就是多个系统同时对一个 key 进行操作，但是最后执行的顺序和我们期望的顺序不同，这样也就导致了结果的不同！推荐一种方案：分布式锁（zookeeper 和 redis 都可以实现分布式锁）。（如果不存在 Redis 的并发竞争 Key 问题，不要使用分布式锁，这样会影响性能）基于zookeeper临时有序节点可以实现的分布式锁。大致思想为：每个客户端对某个方法加锁时，在zookeeper上的与该方法对应的指定节点的目录下，生成一个唯一的瞬时有序节点。 判断是否获取锁的方式很简单，只需要判断有序节点中序号最小的一个。 当释放锁的时候，只需将这个瞬时节点删除即可。同时，其可以避免服务宕机导致的锁无法释放，而产生的死锁问题。完成业务流程后，删除对应的子节点释放锁。在实践中，当然是从以可靠性为主。所以首推Zookeeper。参考：https://www.jianshu.com/p/8bddd381de06分布式Redis是前期做还是后期规模上来了再做好？为什么？既然Redis是如此的轻量（单实例只使用1M内存），为防止以后的扩容，最好的办法就是一开始就启动较多实例。即便你只有一台服务器，你也可以一开始就让Redis以分布式的方式运行，使用分区，在同一台服务器上启动多个实例。一开始就多设置几个Redis实例，例如32或者64个实例，对大多数用户来说这操作起来可能比较麻烦，但是从长久来看做这点牺牲是值得的。这样的话，当你的数据不断增长，需要更多的Redis服务器时，你需要做的就是仅仅将Redis实例从一台服务迁移到另外一台服务器而已（而不用考虑重新分区的问题）。一旦你添加了另一台服务器，你需要将你一半的Redis实例从第一台机器迁移到第二台机器。什么是 RedLockRedis 官方站提出了一种权威的基于 Redis 实现分布式锁的方式名叫 Redlock，此种方式比原先的单节点的方法更安全。它可以保证以下特性：1.安全特性：互斥访问，即永远只有一个 client 能拿到锁2.避免死锁：最终 client 都可能拿到锁，不会出现死锁的情况，即使原本锁住某资源的 client crash 了或者出现了网络分区3.容错性：只要大部分 Redis 节点存活就可以正常提供服务缓存异常缓存雪崩缓存雪崩是指缓存同一时间大面积的失效，所以，后面的请求都会落到数据库上，造成数据库短时间内承受大量请求而崩掉。解决方案1.缓存数据的过期时间设置随机，防止同一时间大量数据过期现象发生。2.一般并发量不是特别多的时候，使用最多的解决方案是加锁排队。3.给每一个缓存数据增加相应的缓存标记，记录缓存的是否失效，如果缓存标记失效，则更新数据缓存。缓存穿透缓存穿透是指缓存和数据库中都没有的数据，导致所有的请求都落到数据库上，造成数据库短时间内承受大量请求而崩掉。解决方案1.接口层增加校验，如用户鉴权校验，id做基础校验，id1)k(k>1)个相互独立的哈希函数，保证在给定的空间、误判率下，完成元素判重的过程。它的优点是空间效率和查询时间都远远超过一般的算法，缺点是有一定的误识别率和删除困难。Bloom-Filter算法的核心思想就是利用多个不同的Hash函数来解决“冲突”。Hash存在一个冲突（碰撞）的问题，用同一个Hash得到的两个URL的值有可能相同。为了减少冲突，我们可以多引入几个Hash，如果通过其中的一个Hash值我们得出某元素不在集合中，那么该元素肯定不在集合中。只有在所有的Hash函数告诉我们该元素在集合中时，才能确定该元素存在于集合中。这便是Bloom-Filter的基本思想。Bloom-Filter一般用于在大数据量的集合中判定某元素是否存在。缓存击穿缓存击穿是指缓存中没有但数据库中有的数据（一般是缓存时间到期），这时由于并发用户特别多，同时读缓存没读到数据，又同时去数据库去取数据，引起数据库压力瞬间增大，造成过大压力。和缓存雪崩不同的是，缓存击穿指并发查同一条数据，缓存雪崩是不同数据都过期了，很多数据都查不到从而查数据库。解决方案1.设置热点数据永远不过期。2.加互斥锁，互斥锁缓存预热缓存预热就是系统上线后，将相关的缓存数据直接加载到缓存系统。这样就可以避免在用户请求的时候，先查询数据库，然后再将数据缓存的问题！用户直接查询事先被预热的缓存数据！解决方案1.直接写个缓存刷新页面，上线时手工操作一下；2.3.数据量不大，可以在项目启动的时候自动进行加载；4.5.定时刷新缓存；6.缓存降级当访问量剧增、服务出现问题（如响应时间慢或不响应）或非核心服务影响到核心流程的性能时，仍然需要保证服务还是可用的，即使是有损服务。系统可以根据一些关键数据进行自动降级，也可以配置开关实现人工降级。缓存降级的最终目的是保证核心服务可用，即使是有损的。而且有些服务是无法降级的（如加入购物车、结算）。在进行降级之前要对系统进行梳理，看看系统是不是可以丢卒保帅；从而梳理出哪些必须誓死保护，哪些可降级；比如可以参考日志级别设置预案：1.一般：比如有些服务偶尔因为网络抖动或者服务正在上线而超时，可以自动降级；2.3.警告：有些服务在一段时间内成功率有波动（如在95~100%之间），可以自动降级或人工降级，并发送告警；4.5.错误：比如可用率低于90%，或者数据库连接池被打爆了，或者访问量突然猛增到系统能承受的最大阀值，此时可以根据情况自动降级或者人工降级；6.7.严重错误：比如因为特殊原因数据错误了，此时需要紧急人工降级。8.服务降级的目的，是为了防止Redis服务故障，导致数据库跟着一起发生雪崩问题。因此，对于不重要的缓存数据，可以采取服务降级策略，例如一个比较常见的做法就是，Redis出现问题，不去数据库查询，而是直接返回默认值给用户。热点数据和冷数据热点数据，缓存才有价值对于冷数据而言，大部分数据可能还没有再次访问到就已经被挤出内存，不仅占用内存，而且价值不大。频繁修改的数据，看情况考虑使用缓存对于热点数据，比如我们的某IM产品，生日祝福模块，当天的寿星列表，缓存以后可能读取数十万次。再举个例子，某导航产品，我们将导航信息，缓存以后可能读取数百万次。数据更新前至少读取两次，缓存才有意义。这个是最基本的策略，如果缓存还没有起作用就失效了，那就没有太大价值了。那存不存在，修改频率很高，但是又不得不考虑缓存的场景呢？有！比如，这个读取接口对数据库的压力很大，但是又是热点数据，这个时候就需要考虑通过缓存手段，减少数据库的压力，比如我们的某助手产品的，点赞数，收藏数，分享数等是非常典型的热点数据，但是又不断变化，此时就需要将数据同步保存到Redis缓存，减少数据库压力。缓存热点key缓存中的一个Key(比如一个促销商品)，在某个时间点过期的时候，恰好在这个时间点对这个Key有大量的并发请求过来，这些请求发现缓存过期一般都会从后端DB加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端DB压垮。解决方案对缓存查询加锁，如果KEY不存在，就加锁，然后查DB入缓存，然后解锁；其他进程如果发现有锁就等待，然后等解锁后返回数据或者进入DB查询常用工具Redis支持的Java客户端都有哪些？官方推荐用哪个？Redisson、Jedis、lettuce等等，官方推荐使用Redisson。Redis和Redisson有什么关系？Redisson是一个高级的分布式协调Redis客服端，能帮助用户在分布式环境中轻松实现一些Java的对象 (Bloom filter, BitSet, Set, SetMultimap, ScoredSortedSet, SortedSet, Map, ConcurrentMap, List, ListMultimap, Queue, BlockingQueue, Deque, BlockingDeque, Semaphore, Lock, ReadWriteLock, AtomicLong, CountDownLatch, Publish / Subscribe, HyperLogLog)。Jedis与Redisson对比有什么优缺点？Jedis是Redis的Java实现的客户端，其API提供了比较全面的Redis命令的支持；Redisson实现了分布式和可扩展的Java数据结构，和Jedis相比，功能较为简单，不支持字符串操作，不支持排序、事务、管道、分区等Redis特性。Redisson的宗旨是促进使用者对Redis的关注分离，从而让使用者能够将精力更集中地放在处理业务逻辑上。其他问题Redis与Memcached的区别两者都是非关系型内存键值数据库，现在公司一般都是用 Redis 来实现缓存，而且 Redis 自身也越来越强大了！Redis 与 Memcached 主要有以下不同：对比参数 Redis Memcached类型 1. 支持内存 2. 非关系型数据库 1. 支持内存 2. 键值对形式 3. 缓存形式数据存储类型 1. String 2. List 3. Set 4. Hash 5. Sort Set 【俗称ZSet】 1. 文本型 2. 二进制类型查询【操作】类型 1. 批量操作 2. 事务支持 3. 每个类型不同的CRUD 1.常用的CRUD 2. 少量的其他命令附加功能 1. 发布/订阅模式 2. 主从分区 3. 序列化支持 4. 脚本支持【Lua脚本】 1. 多线程服务支持网络IO模型 1. 单线程的多路 IO 复用模型 1. 多线程，非阻塞IO模式事件库 自封转简易事件库AeEvent 贵族血统的LibEvent事件库持久化支持 1. RDB 2. AOF 不支持集群模式 原生支持 cluster 模式，可以实现主从复制，读写分离 没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据内存管理机制 在 Redis 中，并不是所有数据都一直存储在内存中，可以将一些很久没用的 value 交换到磁盘 Memcached 的数据则会一直在内存中，Memcached 将内存分割成特定长度的块来存储数据，以完全解决内存碎片的问题。但是这种方式会使得内存的利用率不高，例如块的大小为 128 bytes，只存储 100 bytes 的数据，那么剩下的 28 bytes 就浪费掉了。适用场景 复杂数据结构，有持久化，高可用需求，value存储内容较大 纯key-value，数据量非常大，并发量非常大的业务(1) memcached所有的值均是简单的字符串，redis作为其替代者，支持更为丰富的数据类型(2) redis的速度比memcached快很多(3) redis可以持久化其数据如何保证缓存与数据库双写时的数据一致性？你只要用缓存，就可能会涉及到缓存与数据库双存储双写，你只要是双写，就一定会有数据一致性的问题，那么你如何解决一致性问题？一般来说，就是如果你的系统不是严格要求缓存+数据库必须一致性的话，缓存可以稍微的跟数据库偶尔有不一致的情况，最好不要做这个方案，读请求和写请求串行化，串到一个内存队列里去，这样就可以保证一定不会出现不一致的情况串行化之后，就会导致系统的吞吐量会大幅度的降低，用比正常情况下多几倍的机器去支撑线上的一个请求。还有一种方式就是可能会暂时产生不一致的情况，但是发生的几率特别小，就是先更新数据库，然后再删除缓存。问题场景 描述 解决先写缓存，再写数据库，缓存写成功，数据库写失败 缓存写成功，但写数据库失败或者响应延迟，则下次读取（并发读）缓存时，就出现脏读 这个写缓存的方式，本身就是错误的，需要改为先写数据库，把旧缓存置为失效；读取数据的时候，如果缓存不存在，则读取数据库再写缓存先写数据库，再写缓存，数据库写成功，缓存写失败 写数据库成功，但写缓存失败，则下次读取（并发读）缓存时，则读不到数据 缓存使用时，假如读缓存失败，先读数据库，再回写缓存的方式实现需要缓存异步刷新 指数据库操作和写缓存不在一个操作步骤中，比如在分布式场景下，无法做到同时写缓存或需要异步刷新（补救措施）时候 确定哪些数据适合此类场景，根据经验值确定合理的数据不一致时间，用户数据刷新的时间间隔Redis常见性能问题和解决方案？1.Master最好不要做任何持久化工作，包括内存快照和AOF日志文件，特别是不要启用内存快照做持久化。2.如果数据比较关键，某个Slave开启AOF备份数据，策略为每秒同步一次。3.为了主从复制的速度和连接的稳定性，Slave和Master最好在同一个局域网内。4.尽量避免在压力较大的主库上增加从库5.Master调用BGREWRITEAOF重写AOF文件，AOF在重写的时候会占大量的CPU和内存资源，导致服务load过高，出现短暂服务暂停现象。6.为了Master的稳定性，主从复制不要用图状结构，用单向链表结构更稳定，即主从关系为：Master 水平扩容支撑读高并发redis replication 的核心机制redis 采用异步方式复制数据到 slave 节点，不过 redis2.8 开始，slave node 会周期性地确认自己每次复制的数据量；一个 master node 是可以配置多个 slave node 的；slave node 也可以连接其他的 slave node；slave node 做复制的时候，不会 block master node 的正常工作；slave node 在做复制的时候，也不会 block 对自己的查询操作，它会用旧的数据集来提供服务；但是复制完成的时候，需要删除旧数据集，加载新数据集，这个时候就会暂停对外服务了；slave node 主要用来进行横向扩容，做读写分离，扩容的 slave node 可以提高读的吞吐量。注意，如果采用了主从架构，那么建议必须开启 master node 的持久化，不建议用 slave node 作为 master node 的数据热备，因为那样的话，如果你关掉 master 的持久化，可能在 master 宕机重启的时候数据是空的，然后可能一经过复制， slave node 的数据也丢了。另外，master 的各种备份方案，也需要做。万一本地的所有文件丢失了，从备份中挑选一份 rdb 去恢复 master，这样才能确保启动的时候，是有数据的，即使采用了后续讲解的高可用机制，slave node 可以自动接管 master node，但也可能 sentinel 还没检测到 master failure，master node 就自动重启了，还是可能导致上面所有的 slave node 数据被清空。redis 主从复制的核心原理当启动一个 slave node 的时候，它会发送一个 PSYNC 命令给 master node。如果这是 slave node 初次连接到 master node，那么会触发一次 full resynchronization 全量复制。此时 master 会启动一个后台线程，开始生成一份 RDB 快照文件，同时还会将从客户端 client 新收到的所有写命令缓存在内存中。RDB 文件生成完毕后， master 会将这个 RDB 发送给 slave，slave 会先写入本地磁盘，然后再从本地磁盘加载到内存中，接着 master 会将内存中缓存的写命令发送到 slave，slave 也会同步这些数据。slave node 如果跟 master node 有网络故障，断开了连接，会自动重连，连接之后 master node 仅会复制给 slave 部分缺少的数据。 过程原理1.当从库和主库建立MS关系后，会向主数据库发送SYNC命令2.主库接收到SYNC命令后会开始在后台保存快照(RDB持久化过程)，并将期间接收到的写命令缓存起来3.当快照完成后，主Redis会将快照文件和所有缓存的写命令发送给从Redis4.从Redis接收到后，会载入快照文件并且执行收到的缓存的命令5.之后，主Redis每当接收到写命令时就会将命令发送从Redis，从而保证数据的一致缺点所有的slave节点数据的复制和同步都由master节点来处理，会照成master节点压力太大，使用主从从结构来解决Redis集群的主从复制模型是怎样的？为了使在部分节点失败或者大部分节点无法通信的情况下集群仍然可用，所以集群使用了主从复制模型，每个节点都会有N-1个复制品生产环境中的 redis 是怎么部署的？redis cluster，10 台机器，5 台机器部署了 redis 主实例，另外 5 台机器部署了 redis 的从实例，每个主实例挂了一个从实例，5 个节点对外提供读写服务，每个节点的读写高峰qps可能可以达到每秒 5 万，5 台机器最多是 25 万读写请求/s。机器是什么配置？32G 内存+ 8 核 CPU + 1T 磁盘，但是分配给 redis 进程的是10g内存，一般线上生产环境，redis 的内存尽量不要超过 10g，超过 10g 可能会有问题。5 台机器对外提供读写，一共有 50g 内存。因为每个主实例都挂了一个从实例，所以是高可用的，任何一个主实例宕机，都会自动故障迁移，redis 从实例会自动变成主实例继续提供读写服务。你往内存里写的是什么数据？每条数据的大小是多少？商品数据，每条数据是 10kb。100 条数据是 1mb，10 万条数据是 1g。常驻内存的是 200 万条商品数据，占用内存是 20g，仅仅不到总内存的 50%。目前高峰期每秒就是 3500 左右的请求量。其实大型的公司，会有基础架构的 team 负责缓存集群的运维。说说Redis哈希槽的概念？Redis集群没有使用一致性hash,而是引入了哈希槽的概念，Redis集群有16384个哈希槽，每个key通过CRC16校验后对16384取模来决定放置哪个槽，集群的每个节点负责一部分hash槽。Redis集群会有写操作丢失吗？为什么？Redis并不能保证数据的强一致性，这意味这在实际中集群在特定的条件下可能会丢失写操作。Redis集群之间是如何复制的？异步复制Redis集群最大节点个数是多少？16384个Redis集群如何选择数据库？Redis集群目前无法做数据库选择，默认在0数据库。分区Redis是单线程的，如何提高多核CPU的利用率？可以在同一个服务器部署多个Redis的实例，并把他们当作不同的服务器来使用，在某些时候，无论如何一个服务器是不够的， 所以，如果你想使用多个CPU，你可以考虑一下分片（shard）。为什么要做Redis分区？分区可以让Redis管理更大的内存，Redis将可以使用所有机器的内存。如果没有分区，你最多只能使用一台机器的内存。分区使Redis的计算能力通过简单地增加计算机得到成倍提升，Redis的网络带宽也会随着计算机和网卡的增加而成倍增长。你知道有哪些Redis分区实现方案？客户端分区就是在客户端就已经决定数据会被存储到哪个redis节点或者从哪个redis节点读取。大多数客户端已经实现了客户端分区。代理分区 意味着客户端将请求发送给代理，然后代理决定去哪个节点写数据或者读数据。代理根据分区规则决定请求哪些Redis实例，然后根据Redis的响应结果返回给客户端。redis和memcached的一种代理实现就是Twemproxy查询路由(Query routing) 的意思是客户端随机地请求任意一个redis实例，然后由Redis将请求转发给正确的Redis节点。Redis Cluster实现了一种混合形式的查询路由，但并不是直接将请求从一个redis节点转发到另一个redis节点，而是在客户端的帮助下直接redirected到正确的redis节点。Redis分区有什么缺点？涉及多个key的操作通常不会被支持。例如你不能对两个集合求交集，因为他们可能被存储到不同的Redis实例（实际上这种情况也有办法，但是不能直接使用交集指令）。同时操作多个key,则不能使用Redis事务.分区使用的粒度是key，不能使用一个非常长的排序key存储一个数据集（The partitioning granularity is the key, so it is not possible to shard a dataset with a single huge key like a very big sorted set）当使用分区的时候，数据处理会非常复杂，例如为了备份你必须从不同的Redis实例和主机同时收集RDB / AOF文件。分区时动态扩容或缩容可能非常复杂。Redis集群在运行时增加或者删除Redis节点，能做到最大程度对用户透明地数据再平衡，但其他一些客户端分区或者代理分区方法则不支持这种特性。然而，有一种预分片的技术也可以较好的解决这个问题。分布式问题Redis实现分布式锁Redis为单进程单线程模式，采用队列模式将并发访问变成串行访问，且多客户端对Redis的连接并不存在竞争关系Redis中可以使用SETNX命令实现分布式锁。当且仅当 key 不存在，将 key 的值设为 value。 若给定的 key 已经存在，则 SETNX 不做任何动作SETNX 是『SET if Not eXists』(如果不存在，则 SET)的简写。返回值：设置成功，返回 1 。设置失败，返回 0 。 使用SETNX完成同步锁的流程及事项如下：使用SETNX命令获取锁，若返回0（key已存在，锁已存在）则获取失败，反之获取成功为了防止获取锁后程序出现异常，导致其他线程/进程调用SETNX命令总是返回0而进入死锁状态，需要为该key设置一个“合理”的过期时间释放锁，使用DEL命令将锁数据删除如何解决 Redis 的并发竞争 Key 问题所谓 Redis 的并发竞争 Key 的问题也就是多个系统同时对一个 key 进行操作，但是最后执行的顺序和我们期望的顺序不同，这样也就导致了结果的不同！推荐一种方案：分布式锁（zookeeper 和 redis 都可以实现分布式锁）。（如果不存在 Redis 的并发竞争 Key 问题，不要使用分布式锁，这样会影响性能）基于zookeeper临时有序节点可以实现的分布式锁。大致思想为：每个客户端对某个方法加锁时，在zookeeper上的与该方法对应的指定节点的目录下，生成一个唯一的瞬时有序节点。 判断是否获取锁的方式很简单，只需要判断有序节点中序号最小的一个。 当释放锁的时候，只需将这个瞬时节点删除即可。同时，其可以避免服务宕机导致的锁无法释放，而产生的死锁问题。完成业务流程后，删除对应的子节点释放锁。在实践中，当然是从以可靠性为主。所以首推Zookeeper。参考：https://www.jianshu.com/p/8bddd381de06分布式Redis是前期做还是后期规模上来了再做好？为什么？既然Redis是如此的轻量（单实例只使用1M内存），为防止以后的扩容，最好的办法就是一开始就启动较多实例。即便你只有一台服务器，你也可以一开始就让Redis以分布式的方式运行，使用分区，在同一台服务器上启动多个实例。一开始就多设置几个Redis实例，例如32或者64个实例，对大多数用户来说这操作起来可能比较麻烦，但是从长久来看做这点牺牲是值得的。这样的话，当你的数据不断增长，需要更多的Redis服务器时，你需要做的就是仅仅将Redis实例从一台服务迁移到另外一台服务器而已（而不用考虑重新分区的问题）。一旦你添加了另一台服务器，你需要将你一半的Redis实例从第一台机器迁移到第二台机器。什么是 RedLockRedis 官方站提出了一种权威的基于 Redis 实现分布式锁的方式名叫 Redlock，此种方式比原先的单节点的方法更安全。它可以保证以下特性：1.安全特性：互斥访问，即永远只有一个 client 能拿到锁2.避免死锁：最终 client 都可能拿到锁，不会出现死锁的情况，即使原本锁住某资源的 client crash 了或者出现了网络分区3.容错性：只要大部分 Redis 节点存活就可以正常提供服务缓存异常缓存雪崩缓存雪崩是指缓存同一时间大面积的失效，所以，后面的请求都会落到数据库上，造成数据库短时间内承受大量请求而崩掉。解决方案1.缓存数据的过期时间设置随机，防止同一时间大量数据过期现象发生。2.一般并发量不是特别多的时候，使用最多的解决方案是加锁排队。3.给每一个缓存数据增加相应的缓存标记，记录缓存的是否失效，如果缓存标记失效，则更新数据缓存。缓存穿透缓存穿透是指缓存和数据库中都没有的数据，导致所有的请求都落到数据库上，造成数据库短时间内承受大量请求而崩掉。解决方案1.接口层增加校验，如用户鉴权校验，id做基础校验，id1)k(k>1)个相互独立的哈希函数，保证在给定的空间、误判率下，完成元素判重的过程。它的优点是空间效率和查询时间都远远超过一般的算法，缺点是有一定的误识别率和删除困难。Bloom-Filter算法的核心思想就是利用多个不同的Hash函数来解决“冲突”。Hash存在一个冲突（碰撞）的问题，用同一个Hash得到的两个URL的值有可能相同。为了减少冲突，我们可以多引入几个Hash，如果通过其中的一个Hash值我们得出某元素不在集合中，那么该元素肯定不在集合中。只有在所有的Hash函数告诉我们该元素在集合中时，才能确定该元素存在于集合中。这便是Bloom-Filter的基本思想。Bloom-Filter一般用于在大数据量的集合中判定某元素是否存在。缓存击穿缓存击穿是指缓存中没有但数据库中有的数据（一般是缓存时间到期），这时由于并发用户特别多，同时读缓存没读到数据，又同时去数据库去取数据，引起数据库压力瞬间增大，造成过大压力。和缓存雪崩不同的是，缓存击穿指并发查同一条数据，缓存雪崩是不同数据都过期了，很多数据都查不到从而查数据库。解决方案1.设置热点数据永远不过期。2.加互斥锁，互斥锁缓存预热缓存预热就是系统上线后，将相关的缓存数据直接加载到缓存系统。这样就可以避免在用户请求的时候，先查询数据库，然后再将数据缓存的问题！用户直接查询事先被预热的缓存数据！解决方案1.直接写个缓存刷新页面，上线时手工操作一下；2.3.数据量不大，可以在项目启动的时候自动进行加载；4.5.定时刷新缓存；6.缓存降级当访问量剧增、服务出现问题（如响应时间慢或不响应）或非核心服务影响到核心流程的性能时，仍然需要保证服务还是可用的，即使是有损服务。系统可以根据一些关键数据进行自动降级，也可以配置开关实现人工降级。缓存降级的最终目的是保证核心服务可用，即使是有损的。而且有些服务是无法降级的（如加入购物车、结算）。在进行降级之前要对系统进行梳理，看看系统是不是可以丢卒保帅；从而梳理出哪些必须誓死保护，哪些可降级；比如可以参考日志级别设置预案：1.一般：比如有些服务偶尔因为网络抖动或者服务正在上线而超时，可以自动降级；2.3.警告：有些服务在一段时间内成功率有波动（如在95~100%之间），可以自动降级或人工降级，并发送告警；4.5.错误：比如可用率低于90%，或者数据库连接池被打爆了，或者访问量突然猛增到系统能承受的最大阀值，此时可以根据情况自动降级或者人工降级；6.7.严重错误：比如因为特殊原因数据错误了，此时需要紧急人工降级。8.服务降级的目的，是为了防止Redis服务故障，导致数据库跟着一起发生雪崩问题。因此，对于不重要的缓存数据，可以采取服务降级策略，例如一个比较常见的做法就是，Redis出现问题，不去数据库查询，而是直接返回默认值给用户。热点数据和冷数据热点数据，缓存才有价值对于冷数据而言，大部分数据可能还没有再次访问到就已经被挤出内存，不仅占用内存，而且价值不大。频繁修改的数据，看情况考虑使用缓存对于热点数据，比如我们的某IM产品，生日祝福模块，当天的寿星列表，缓存以后可能读取数十万次。再举个例子，某导航产品，我们将导航信息，缓存以后可能读取数百万次。数据更新前至少读取两次，缓存才有意义。这个是最基本的策略，如果缓存还没有起作用就失效了，那就没有太大价值了。那存不存在，修改频率很高，但是又不得不考虑缓存的场景呢？有！比如，这个读取接口对数据库的压力很大，但是又是热点数据，这个时候就需要考虑通过缓存手段，减少数据库的压力，比如我们的某助手产品的，点赞数，收藏数，分享数等是非常典型的热点数据，但是又不断变化，此时就需要将数据同步保存到Redis缓存，减少数据库压力。缓存热点key缓存中的一个Key(比如一个促销商品)，在某个时间点过期的时候，恰好在这个时间点对这个Key有大量的并发请求过来，这些请求发现缓存过期一般都会从后端DB加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端DB压垮。解决方案对缓存查询加锁，如果KEY不存在，就加锁，然后查DB入缓存，然后解锁；其他进程如果发现有锁就等待，然后等解锁后返回数据或者进入DB查询常用工具Redis支持的Java客户端都有哪些？官方推荐用哪个？Redisson、Jedis、lettuce等等，官方推荐使用Redisson。Redis和Redisson有什么关系？Redisson是一个高级的分布式协调Redis客服端，能帮助用户在分布式环境中轻松实现一些Java的对象 (Bloom filter, BitSet, Set, SetMultimap, ScoredSortedSet, SortedSet, Map, ConcurrentMap, List, ListMultimap, Queue, BlockingQueue, Deque, BlockingDeque, Semaphore, Lock, ReadWriteLock, AtomicLong, CountDownLatch, Publish / Subscribe, HyperLogLog)。Jedis与Redisson对比有什么优缺点？Jedis是Redis的Java实现的客户端，其API提供了比较全面的Redis命令的支持；Redisson实现了分布式和可扩展的Java数据结构，和Jedis相比，功能较为简单，不支持字符串操作，不支持排序、事务、管道、分区等Redis特性。Redisson的宗旨是促进使用者对Redis的关注分离，从而让使用者能够将精力更集中地放在处理业务逻辑上。其他问题Redis与Memcached的区别两者都是非关系型内存键值数据库，现在公司一般都是用 Redis 来实现缓存，而且 Redis 自身也越来越强大了！Redis 与 Memcached 主要有以下不同：对比参数 Redis Memcached类型 1. 支持内存 2. 非关系型数据库 1. 支持内存 2. 键值对形式 3. 缓存形式数据存储类型 1. String 2. List 3. Set 4. Hash 5. Sort Set 【俗称ZSet】 1. 文本型 2. 二进制类型查询【操作】类型 1. 批量操作 2. 事务支持 3. 每个类型不同的CRUD 1.常用的CRUD 2. 少量的其他命令附加功能 1. 发布/订阅模式 2. 主从分区 3. 序列化支持 4. 脚本支持【Lua脚本】 1. 多线程服务支持网络IO模型 1. 单线程的多路 IO 复用模型 1. 多线程，非阻塞IO模式事件库 自封转简易事件库AeEvent 贵族血统的LibEvent事件库持久化支持 1. RDB 2. AOF 不支持集群模式 原生支持 cluster 模式，可以实现主从复制，读写分离 没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据内存管理机制 在 Redis 中，并不是所有数据都一直存储在内存中，可以将一些很久没用的 value 交换到磁盘 Memcached 的数据则会一直在内存中，Memcached 将内存分割成特定长度的块来存储数据，以完全解决内存碎片的问题。但是这种方式会使得内存的利用率不高，例如块的大小为 128 bytes，只存储 100 bytes 的数据，那么剩下的 28 bytes 就浪费掉了。适用场景 复杂数据结构，有持久化，高可用需求，value存储内容较大 纯key-value，数据量非常大，并发量非常大的业务(1) memcached所有的值均是简单的字符串，redis作为其替代者，支持更为丰富的数据类型(2) redis的速度比memcached快很多(3) redis可以持久化其数据如何保证缓存与数据库双写时的数据一致性？你只要用缓存，就可能会涉及到缓存与数据库双存储双写，你只要是双写，就一定会有数据一致性的问题，那么你如何解决一致性问题？一般来说，就是如果你的系统不是严格要求缓存+数据库必须一致性的话，缓存可以稍微的跟数据库偶尔有不一致的情况，最好不要做这个方案，读请求和写请求串行化，串到一个内存队列里去，这样就可以保证一定不会出现不一致的情况串行化之后，就会导致系统的吞吐量会大幅度的降低，用比正常情况下多几倍的机器去支撑线上的一个请求。还有一种方式就是可能会暂时产生不一致的情况，但是发生的几率特别小，就是先更新数据库，然后再删除缓存。问题场景 描述 解决先写缓存，再写数据库，缓存写成功，数据库写失败 缓存写成功，但写数据库失败或者响应延迟，则下次读取（并发读）缓存时，就出现脏读 这个写缓存的方式，本身就是错误的，需要改为先写数据库，把旧缓存置为失效；读取数据的时候，如果缓存不存在，则读取数据库再写缓存先写数据库，再写缓存，数据库写成功，缓存写失败 写数据库成功，但写缓存失败，则下次读取（并发读）缓存时，则读不到数据 缓存使用时，假如读缓存失败，先读数据库，再回写缓存的方式实现需要缓存异步刷新 指数据库操作和写缓存不在一个操作步骤中，比如在分布式场景下，无法做到同时写缓存或需要异步刷新（补救措施）时候 确定哪些数据适合此类场景，根据经验值确定合理的数据不一致时间，用户数据刷新的时间间隔Redis常见性能问题和解决方案？1.Master最好不要做任何持久化工作，包括内存快照和AOF日志文件，特别是不要启用内存快照做持久化。2.如果数据比较关键，某个Slave开启AOF备份数据，策略为每秒同步一次。3.为了主从复制的速度和连接的稳定性，Slave和Master最好在同一个局域网内。4.尽量避免在压力较大的主库上增加从库5.Master调用BGREWRITEAOF重写AOF文件，AOF在重写的时候会占大量的CPU和内存资源，导致服务load过高，出现短暂服务暂停现象。6.为了Master的稳定性，主从复制不要用图状结构，用单向链表结构更稳定，即主从关系为：Master","link":"/2020/10/19/Redis%E9%9D%A2%E8%AF%95%E9%A2%982/"},{"title":"一个数组找出top k","text":"","link":"/2020/10/19/%E4%B8%80%E4%B8%AA%E6%95%B0%E7%BB%84%E6%89%BE%E5%87%BAtop%20k/"},{"title":"LRUCache数据结构","text":"LRUCache数据结构1234567891011121314151617181920class LRUCache { private LinkedHashMap cache; public LRUCache(int cacheSize) { cache = new LinkedHashMap(16, 0.75f, true) { protected boolean removeEldestEntry(Map.Entry eldest) { return size() > cacheSize; } }; } public int get(int key) { return cache.getOrDefault(key, -1); } public void put(int key, int value) { cache.put(key, value); }}","link":"/2020/10/19/LRUCache%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"title":"sqrt","text":"sqrt123456789101112131415public int mySqrt(int x) { if (x == 0) return 0; long left = 1; long right = x/2; while (left < right) { long mid = (right + left) / 2 + 1; if (mid > x / mid) { right = mid - 1; } else { left = mid; } } return (int)left;}","link":"/2020/10/19/sqrt/"},{"title":"三数之和","text":"三数之和12345678910111213141516171819202122232425262728293031323334353637383940class Solution { public List threeSum(int[] nums) { if(nums == null || nums.length < 3) return new ArrayList(); Arrays.sort(nums); List resultList = new ArrayList(); for(int i = 0; i < nums.length -2; i++) { int left = i+1; int right = nums.length-1; if(i != 0 && nums[i] == nums[i - 1]) continue; while(left < right && nums[i] < 1) { if(nums[i] + nums[left] + nums[right] > 0) { right--; } else if(nums[i] + nums[left] + nums[right] < 0) { left++; } else { List integerList = new ArrayList(); integerList.add(nums[i]); integerList.add(nums[left]); integerList.add(nums[right]); resultList.add(integerList); while(left < right && nums[left] == nums[left+1]) left++; while(left < right && nums[right] == nums[right-1]) right--; right--; left++; } } } return resultList; }}","link":"/2020/10/19/%E4%B8%89%E6%95%B0%E4%B9%8B%E5%92%8C/"},{"title":"两数相加","text":"两数相加123456789101112131415161718public ListNode addTwoNumbers(ListNode l1, ListNode l2) { if (l1 == null && l2 == null) return null; if (l2 == null) l2 = new ListNode(0); if (l1 == null) l1 = new ListNode(0); ListNode sumListNode = new ListNode(0); sumListNode.val = l1.val + l2.val; if (sumListNode.val >= 10) { sumListNode.val = sumListNode.val - 10; if (l1.next != null) { l1.next.val++; } else { l1.next = new ListNode(1); } } sumListNode.next = addTwoNumbers(l1.next, l2.next); return sumListNode; }","link":"/2020/10/19/%E4%B8%A4%E6%95%B0%E7%9B%B8%E5%8A%A0/"},{"title":"二叉搜索树最近公共祖先","text":"二叉搜索树最近公共祖先1234567891011121314class Solution { public TreeNode lowestCommonAncestor(TreeNode root, TreeNode p, TreeNode q) { if (root == null) return null; if (root == p || root == q) return root; if (root.val < p.val && root.val < q.val) { return lowestCommonAncestor(root.right, p, q); } else if (root.val > p.val && root.val > q.val) { return lowestCommonAncestor(root.left, p, q); } return root; }}","link":"/2020/10/19/%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91%E6%9C%80%E8%BF%91%E5%85%AC%E5%85%B1%E7%A5%96%E5%85%88/"},{"title":"二叉树是否存在路径和等于某整数","text":"二叉树是否存在路径和等于某整数1234567891011121314151617181920212223boolean ans = false;public boolean hasPathSum(TreeNode root, int sum) { if (root == null) { return false; } dfs(root,sum); return ans;}private void dfs(TreeNode root,int sum) { if (root == null) { return; } if (root.left == null && root.right == null) { if (sum == root.val) { ans = true; } } dfs(root.left,sum - root.val); dfs(root.right,sum - root.val);}","link":"/2020/10/19/%E4%BA%8C%E5%8F%89%E6%A0%91%E6%98%AF%E5%90%A6%E5%AD%98%E5%9C%A8%E8%B7%AF%E5%BE%84%E5%92%8C%E7%AD%89%E4%BA%8E%E6%9F%90%E6%95%B4%E6%95%B0/"},{"title":"二叉树的最近公共祖先","text":"二叉树的最近公共祖先12345678910111213141516public TreeNode lowestCommonAncestor(TreeNode root, TreeNode p, TreeNode q) { if (root == null) return null; if (root == p || root == q) return root; TreeNode left = lowestCommonAncestor(root.left, p, q); TreeNode right = lowestCommonAncestor(root.right, p, q); if (left != null && right != null) { return root; } else if (left != null) { return left; } else if (right != null) { return right; } return null;}","link":"/2020/10/19/%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E6%9C%80%E8%BF%91%E5%85%AC%E5%85%B1%E7%A5%96%E5%85%88/"},{"title":"二叉树的锯齿形遍历","text":"二叉树的锯齿形遍历12345678910111213141516171819202122232425262728293031class Solution { public List zigzagLevelOrder(TreeNode root) { List resultList = new ArrayList(); if (root == null) return resultList; LinkedList linkedList = new LinkedList(); linkedList.addLast(root); linkedList.addLast(null); LinkedList levelList = new LinkedList(); boolean isOrderLeft = true; while (linkedList.size() > 0) { TreeNode currNode = linkedList.pollFirst(); if (currNode != null) { if (isOrderLeft) levelList.addLast(currNode.val); else levelList.addFirst(currNode.val); if (currNode.left != null) linkedList.addLast(currNode.left); if (currNode.right != null) linkedList.addLast(currNode.right); } else { resultList.add(levelList); levelList = new LinkedList(); if (linkedList.size() > 0) linkedList.addLast(null); isOrderLeft = !isOrderLeft; } } return resultList; }}","link":"/2020/10/19/%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E9%94%AF%E9%BD%BF%E5%BD%A2%E9%81%8D%E5%8E%86/"},{"title":"二叉树的镜像","text":"二叉树的镜像1234567891011121314151617181920212223/** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) { val = x; } * } */class Solution { public TreeNode mirrorTree(TreeNode root) { if (root == null) return null; if (root.right == null && root.left == null) return root; TreeNode temp = root.right; root.right = root.left; root.left = temp; mirrorTree(root.left); mirrorTree(root.right); return root; }}","link":"/2020/10/19/%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E9%95%9C%E5%83%8F/"},{"title":"判断两颗树是否相同","text":"判断两颗树是否相同1234567891011class Solution { public boolean isSameTree(TreeNode p, TreeNode q) { if (p == null && q == null) return true; if ((p == null && q != null) || (p != null && q == null)) return false; if (p != null && q != null && p.val == q.val) return isSameTree(p.left, q.left) && isSameTree(p.right, q.right); return false; }}","link":"/2020/10/19/%E5%88%A4%E6%96%AD%E4%B8%A4%E9%A2%97%E6%A0%91%E6%98%AF%E5%90%A6%E7%9B%B8%E5%90%8C/"},{"title":"句子是否由词典构成","text":"句子是否由词典构成算法题：给一个词典和一个句子，判断是否句子是否可以通过词典构成之前的方法是依次判断完l,le,lee,leet再依次判断c,co,cod,code这样每次一个字母判断；现在依次判断字典里的单词：首先，判断字典里面的第一个单词“leet”,len(“leet”)=4, 由于i=4>=len, 且dp[i-len]=dp[0]=true,且单词“leet”与字符串[i-len,i]的子字符串相等，即”leet”.equals(s.substring(0,4))==true。因此dp[4]=true; 接下来依次判断i=5,6,7; 由于单词里的字典无法匹配剩余子字符串,即word.equals(s.substring(i-len,i))==false; 当i=6时，由于dp[4]==true,且对于字典里的单词“code”,len(code)==4,且”code”.equals(s.substring(4,6)==true，因此，dp[6]==true; i==s.length(),循环结束。 123456789101112131415161718192021class Solution { public boolean wordBreak(String s, List wordDict) { Set wordDictSet = new HashSet(wordDict); //使用HashSet查找时间复杂度为O(1) ArrayList查找时间复杂度为O(n) boolean[] dp = new boolean[s.length()+1]; //dp[i]表示字符串s的前i个字符组成的字符串s[0,i-1]是否能被空格拆分成一个或多个在字典中出现的单词 dp[0] = true; for(int i=1; i=len && dp[i-len]==true && word.equals(s.substring(i-len,i))){ dp[i] = true; break; } } } return dp[s.length()]; }}","link":"/2020/10/19/%E5%8F%A5%E5%AD%90%E6%98%AF%E5%90%A6%E7%94%B1%E8%AF%8D%E5%85%B8%E6%9E%84%E6%88%90/"},{"title":"卖股票的最佳时机","text":"卖股票的最佳时机1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950 public int maxProfit(int[] a) { int maxProfit = 0; for (int i = a.length -1; i >= 1 ; i--) { int j = i - 1; while(j >= 0) { int profit = a[i] - a[j]; maxProfit = Math.max(profit, maxProfit); j--; } } return maxProfit; }class Solution { public int maxProfit(int[] prices) { int minPrice = Integer.MAX_VALUE; int maxProfit = 0; for (int i = 0; i < prices.length; i++) { if (prices[i] < minPrice) { minPrice = prices[i]; } else if (prices[i] - minPrice > maxProfit) { maxProfit = prices[i] - minPrice; } } return maxProfit; }}class Solution { public int maxProfit(int[] prices) { int maxProfit = 0; for (int i = 1; i < prices.length; i++) { if (prices[i-1] < prices[i]) maxProfit += (prices[i] - prices[i-1]); } return maxProfit; }}class Solution { public int maxProfit(int[] prices) { if(prices.length","link":"/2020/10/19/%E5%8D%96%E8%82%A1%E7%A5%A8%E7%9A%84%E6%9C%80%E4%BD%B3%E6%97%B6%E6%9C%BA/"},{"title":"合并两个有序链表","text":"合并两个有序链表12345678910111213141516171819class Solution { public ListNode mergeTwoLists(ListNode l1, ListNode l2) { if (l1 == null) return l2; if (l2 == null) return l1; ListNode newNode = new ListNode(0); if (l1.val","link":"/2020/10/19/%E5%90%88%E5%B9%B6%E4%B8%A4%E4%B8%AA%E6%9C%89%E5%BA%8F%E9%93%BE%E8%A1%A8/"},{"title":"合并k个有序链表","text":"合并k个有序链表1234567891011121314151617181920212223class Solution { private PriorityQueue queue = new PriorityQueue((o1, o2) -> (o1.val - o2.val)); public ListNode mergeKLists(ListNode[] lists) { if (lists.length == 0) return null; ListNode resultNode = new ListNode(0); ListNode currNode = resultNode; for(ListNode node : lists) { if (node == null) continue; queue.add(node); } while(!queue.isEmpty()) { ListNode nextNode = queue.poll(); currNode.next = nextNode; currNode = currNode.next; if (nextNode.next != null) { queue.add(nextNode.next); } } return resultNode.next; }}","link":"/2020/10/19/%E5%90%88%E5%B9%B6k%E7%9A%84%E6%9C%89%E5%BA%8F%E9%93%BE%E8%A1%A8/"},{"title":"恢复二叉搜索树","text":"恢复二叉搜索树1234567891011121314151617181920212223class Solution { public void recoverTree(TreeNode root) { Deque stack = new LinkedList(); TreeNode firstNode = null; TreeNode secondNode = null; TreeNode pre = new TreeNode(Integer.MIN_VALUE); TreeNode p = root; while (p != null || !stack.isEmpty()) { while (p != null) { stack.push(p); p = p.left; } p = stack.pop(); if (firstNode == null && pre.val > p.val) firstNode = pre; if (firstNode != null && pre.val > p.val) secondNode = p; pre = p; p = p.right; } int tmp = firstNode.val; firstNode.val = secondNode.val; secondNode.val = tmp; }}","link":"/2020/10/19/%E6%81%A2%E5%A4%8D%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91/"},{"title":"对称二叉树的判断","text":"对称二叉树的判断123456789101112131415class Solution { public boolean isSymmetric(TreeNode root) { if (root == null) return true; return isSymmetricHelper(root.left, root.right); } private boolean isSymmetricHelper(TreeNode left, TreeNode right) { if (left == null && right == null) return true; if (left == null || right == null || left.val != right.val) return false; return isSymmetricHelper(left.left, right.right) && isSymmetricHelper(left.right, right.left); }}","link":"/2020/10/19/%E5%AF%B9%E7%A7%B0%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E5%88%A4%E6%96%AD/"},{"title":"排序链表","text":"排序链表12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879class SortList { public ListNode sortList(ListNode head) { if (head == null) { return head; } return mergeSort(head); } /** * @Description 递归分解序列为两个子序列，并向上并归排序 * 使用快慢指针法，快指针到终点时慢指针指向中点 */ public final ListNode mergeSort(ListNode head) { //回归条件 if (head.next == null) { return head; } //快指针,考虑到链表为2时的情况，fast比slow早一格 ListNode fast = head.next; //慢指针 ListNode slow = head; //快慢指针开跑 while (fast != null && fast.next != null) { fast = fast.next.next; slow = slow.next; } //找到右子链表头元素，复用fast引用 fast = slow.next; //将中点后续置空，切割为两个子链表 slow.next = null; //递归分解左子链表,得到新链表起点 head = mergeSort(head); //递归分解右子链表,得到新链表起点 fast = mergeSort(fast); //并归两个子链表 ListNode newHead = merge(head, fast);// ListNode.print(newHead); return newHead; } /** * @Description 以left节点为起点的左子序列 及 以right为起点的右子序列 并归为一个有序序列并返回头元素； * 传入的 left 及 right 都不可为 null */ public final ListNode merge(ListNode left, ListNode right) { //维护临时序列的头元素 ListNode head; if (left.val","link":"/2020/10/19/%E6%8E%92%E5%BA%8F%E9%93%BE%E8%A1%A8/"},{"title":"数组前k大的数","text":"数组前k大的数12345678910111213141516171819202122class KthLargest { final PriorityQueue queue; final int k; public KthLargest(int k, int[] nums) { this.k = k; queue = new PriorityQueue(); for (int num : nums) { add(num); } } public int add(int val) { if (queue.size() < k) queue.offer(val); else if (val > queue.peek()) { queue.poll(); queue.offer(val); } return queue.peek(); }}","link":"/2020/10/19/%E6%95%B0%E7%BB%84%E5%89%8Dk%E5%A4%A7%E7%9A%84%E6%95%B0/"},{"title":"最小栈","text":"最小栈1234567891011121314151617181920212223242526272829303132333435363738394041class MinStack { /** initialize your data structure here. */ private Node node; public MinStack() { } public void push(int x) { if (node == null) node = new Node(x, x); else node = new Node(x, Math.min(x, node.min), node); } public void pop() { node = node.next; } public int top() { return node.val; } public int getMin() { return node.min; } private class Node { int val; int min; Node next; private Node(int val, int min) { this(val, min, null); } private Node(int val, int min, Node next) { this.val = val; this.min = min; this.next = next; } }}","link":"/2020/10/19/%E6%9C%80%E5%B0%8F%E6%A0%88/"},{"title":"最长不重复子串","text":"最长不重复子串123456789101112131415161718192021class Solution { public int lengthOfLongestSubstring(String s) { if (s == null || s.length() == 0) return 0; char[] ch = s.toCharArray(); int maxValue = 1; for (int i = 0; i < ch.length - 1; i++) { int tempMaxValue = 0; Set characterSet = new HashSet(); for (int j = i; j < ch.length -1; j++) { characterSet.add(ch[j]); if (characterSet.add(ch[j + 1])) { tempMaxValue = Math.max(characterSet.size(), tempMaxValue); } else break; } maxValue = Math.max(maxValue, tempMaxValue); } return maxValue; }}","link":"/2020/10/19/%E6%9C%80%E9%95%BF%E4%B8%8D%E9%87%8D%E5%A4%8D%E5%AD%90%E4%B8%B2/"},{"title":"环形链表的入口","text":"环形链表的入口123456789101112131415161718192021public class Solution { public ListNode detectCycle(ListNode head) { if (head == null || head.next == null) return null; ListNode fastNode = head; ListNode slowNode = head; while (fastNode != null && fastNode.next != null) { fastNode = fastNode.next.next; slowNode = slowNode.next; if (fastNode != null && slowNode == fastNode) { fastNode = head; while (fastNode != slowNode) { fastNode = fastNode.next; slowNode = slowNode.next; } return fastNode; } } return null; }}","link":"/2020/10/19/%E7%8E%AF%E5%BD%A2%E9%93%BE%E8%A1%A8%E7%9A%84%E5%85%A5%E5%8F%A3/"},{"title":"相交链表","text":"相交链表123456789101112public class Solution { public ListNode getIntersectionNode(ListNode headA, ListNode headB) { ListNode tempA = headA; ListNode tempB = headB; while (tempA != tempB) { tempA = tempA == null ? headB : tempA.next; tempB = tempB == null ? headA : tempB.next; } return tempA; }}","link":"/2020/10/19/%E7%9B%B8%E4%BA%A4%E9%93%BE%E8%A1%A8/"},{"title":"单词反转","text":"单词反转12345678910public String reverseWords(String s) { String[] strs = s.split(\"\\\\s\"); StringBuilder stringBuilder = new StringBuilder(); for (int i = strs.length - 1; i >= 0; i--) { if (strs[i].equals(\"\")) continue; stringBuilder.append(strs[i].trim() + \" \"); } return stringBuilder.toString().trim();}","link":"/2020/10/19/%E5%8D%95%E8%AF%8D%E5%8F%8D%E8%BD%AC/"},{"title":"判定是否有环","text":"判定是否有环1234567891011121314public boolean hasCycle(ListNode node) { if (node == null || node.next == null) return false; ListNode fastNode = node; ListNode slowNode = node; while (fastNode != null && fastNode.next != null) { slowNode = slowNode.next; fastNode = fastNode.next.next; if (slowNode == fastNode) return true; } return false;}","link":"/2020/10/19/%E5%88%A4%E5%AE%9A%E6%98%AF%E5%90%A6%E6%9C%89%E7%8E%AF/"},{"title":"反转链表","text":"反转链表123456789101112class Solution { public ListNode reverseList(ListNode head) { if (head == null || head.next == null) return head; ListNode temp = head.next; ListNode newHead = reverseList(head.next); temp.next = head; head.next = null; return newHead; }}","link":"/2020/10/19/%E5%8F%8D%E8%BD%AC%E9%93%BE%E8%A1%A8/"},{"title":"队列实现栈","text":"队列实现栈1234567891011121314151617181920212223242526272829303132333435363738class MyStack { private Queue addQueue; private Queue rmQueue; /** Initialize your data structure here. */ public MyStack() { addQueue = new LinkedList(); rmQueue = new LinkedList(); } /** Push element x onto stack. */ public void push(int x) { addQueue.offer(x); while (!rmQueue.isEmpty()) addQueue.offer(rmQueue.poll()); Queue temp = addQueue; addQueue = rmQueue; rmQueue = temp; } /** Removes the element on top of the stack and returns that element. */ public int pop() { return rmQueue.poll(); } /** Get the top element. */ public int top() { return rmQueue.peek(); } /** Returns whether the stack is empty. */ public boolean empty() { return rmQueue.isEmpty(); }} 栈实现队列1234567891011121314151617181920212223242526272829303132333435363738394041class MyQueue { private Stack addStack; private Stack rmStack; /** Initialize your data structure here. */ public MyQueue() { addStack = new Stack(); rmStack = new Stack(); } /** Push element x to the back of queue. */ public void push(int x) { addStack.add(x); } /** Removes the element from in front of queue and returns that element. */ public int pop() { if (rmStack.isEmpty()) { while(!addStack.isEmpty()) { rmStack.push(addStack.pop()); } } return rmStack.pop(); } /** Get the front element. */ public int peek() { if(rmStack.isEmpty()) { while(!addStack.isEmpty()) { rmStack.push(addStack.pop()); } } return rmStack.peek(); } /** Returns whether the queue is empty. */ public boolean empty() { return rmStack.isEmpty() && addStack.isEmpty(); }}","link":"/2020/10/19/%E9%98%9F%E5%88%97%E5%AE%9E%E7%8E%B0%E6%A0%88/"},{"title":"有效的括号","text":"有效的括号12345678910111213141516171819class Solution { public boolean isValid(String s) { Map map = new HashMap(); map.put( ')','('); map.put( '}','{'); map.put( ']','['); Stack stack = new Stack(); char[] ss = s.toCharArray(); for (char ch : ss) { if (!map.containsKey(ch )) { stack.push(ch); } else { if (stack.isEmpty() || !stack.pop().equals(map.get(ch))) return false; } } return stack.isEmpty(); }}","link":"/2020/10/19/%E6%9C%89%E6%95%88%E7%9A%84%E6%8B%AC%E5%8F%B7/"},{"title":"链表交换元素","text":"链表交换元素12345678910class Solution { public ListNode swapPairs(ListNode head) { if (head == null || head.next == null) return head; ListNode newNode = head.next; head.next = swapPairs(newNode.next); newNode.next = head; return newNode; }}","link":"/2020/10/19/%E9%93%BE%E8%A1%A8%E4%BA%A4%E6%8D%A2%E5%85%83%E7%B4%A0/"},{"title":"验证二叉搜索树","text":"最小栈12345678910111213141516171819202122232425262728293031323334353637383940414243444546class Solution { public boolean isValidBST(TreeNode node) { return valid(node, Long.MIN_VALUE, Long.MAX_VALUE); } public boolean valid(TreeNode node, long min, long max) { if (node == null) return true; if (node.val = max) return false; return valid(node.left, min, node.val) && valid(node.right, node.val, max); }}Long preValue = Long.MIN_VALUE;public boolean isValidBST(TreeNode node) { if (node != null) { if (!isValidBST(node.left)) return false; if (node.val","link":"/2020/10/19/%E9%AA%8C%E8%AF%81%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91/"},{"title":"todo/N皇后问题","text":"","link":"/2020/10/19/todo/N%E7%9A%87%E5%90%8E%E9%97%AE%E9%A2%98/"},{"title":"todo/数组墙问题","text":"","link":"/2020/10/19/todo/%E6%95%B0%E7%BB%84%E5%A2%99%E9%97%AE%E9%A2%98/"},{"title":"todo/单词搜索","text":"","link":"/2020/10/19/todo/%E5%8D%95%E8%AF%8D%E6%90%9C%E7%B4%A2/"},{"title":"todo/top k问题","text":"","link":"/2020/10/19/todo/top%20k%E9%97%AE%E9%A2%98/"},{"title":"todo/红包算法","text":"","link":"/2020/10/19/todo/%E7%BA%A2%E5%8C%85%E7%AE%97%E6%B3%95/"},{"title":"线程同步锁机制","text":"一，CountDownLatch方法有await、countDown、getCount三个主要方法 1234567891011121314151617181920212223242526272829303132import java.util.concurrent.CountDownLatch;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;public class CountDownLatchDemo { private static CountDownLatch startSignal = new CountDownLatch(1); //用来表示裁判员需要维护的是6个运动员 private static CountDownLatch endSignal = new CountDownLatch(6); public static void main(String[] args) throws InterruptedException { ExecutorService executorService = Executors.newFixedThreadPool(6); for (int i = 0; i < 6; i++) { executorService.execute(() -> { try { System.out.println(Thread.currentThread().getName() + \" 运动员等待裁判员响哨！！！\"); startSignal.await(); System.out.println(Thread.currentThread().getName() + \"正在全力冲刺\"); endSignal.countDown();//当6个线程全部执行完毕，任务结束 System.out.println(Thread.currentThread().getName() + \" 到达终点\"); } catch (InterruptedException e) { e.printStackTrace(); } }); } System.out.println(\"裁判员发号施令啦！！！\"); startSignal.countDown();//使 CountDownLatch 初始值 N 减 1；，此时startSignal减为0，线程开始向下执行 endSignal.await(); System.out.println(\"所有运动员到达终点，比赛结束！\"); executorService.shutdown(); }} 二，CyclicBarrier1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071/** * 导游线程，都到达目的地时，发放护照和签证 */public class TourGuideTask implements Runnable{ @Override public void run() { System.out.println(\"****导游分发护照签证****\"); try { //模拟发护照签证需要2秒 Thread.sleep(2000); } catch (InterruptedException e) { e.printStackTrace(); } }}import java.util.concurrent.BrokenBarrierException;import java.util.concurrent.CyclicBarrier;/** * 旅行线程 */public class TravelTask implements Runnable{ private CyclicBarrier cyclicBarrier; private String name; private int arriveTime;//赶到的时间 public TravelTask(CyclicBarrier cyclicBarrier,String name,int arriveTime){ this.cyclicBarrier = cyclicBarrier; this.name = name; this.arriveTime = arriveTime; } @Override public void run() { try { //模拟达到需要花的时间 Thread.sleep(arriveTime * 1000); System.out.println(name +\"到达集合点\"); cyclicBarrier.await(); System.out.println(name +\"开始旅行啦～～\"); cyclicBarrier.await(); System.out.println(name + \"回家，各找各妈\"); } catch (InterruptedException e) { e.printStackTrace(); } catch (BrokenBarrierException e) { e.printStackTrace(); } }}import java.util.concurrent.CyclicBarrier;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;public class Client { public static void main(String[] args) throws Exception{ CyclicBarrier cyclicBarrier = new CyclicBarrier(3,new TourGuideTask()); ExecutorService executor = Executors.newFixedThreadPool(3); //登哥最大牌，到的最晚 executor.execute(new TravelTask(cyclicBarrier,\"哈登\",5)); executor.execute(new TravelTask(cyclicBarrier,\"保罗\",3)); executor.execute(new TravelTask(cyclicBarrier,\"戈登\",1)); }} 三，Phaser四，ReadWriteLock1.Java并发库中ReetrantReadWriteLock实现了ReadWriteLock接口并添加了可重入的特性2.ReetrantReadWriteLock读写锁的效率明显高于synchronized关键字3.ReetrantReadWriteLock读写锁的实现中，读锁使用共享模式；写锁使用独占模式，换句话说，读锁可以在没有写锁的时候被多个线程同时持有，写锁是独占的4.ReetrantReadWriteLock读写锁的实现中，需要注意的，当有读锁时，写锁就不能获得；而当有写锁时，除了获得写锁的这个线程可以获得读锁外，其他线程不能获得读锁 1234567891011import java.util.concurrent.locks.ReentrantReadWriteLock;public class Test1 { //为同一个线程中，在没有释放读锁的情况下，就去申请写锁，这属于锁升级，ReentrantReadWriteLock是不支持的。 public static void main(String[] args) { ReentrantReadWriteLock rtLock = new ReentrantReadWriteLock(); rtLock.readLock().lock(); System.out.println(\"get readLock.\"); rtLock.writeLock().lock(); System.out.println(\"blocking\"); }} 12345678910111213public class Test2 { //ReentrantReadWriteLock支持锁降级，上面代码不会产生死锁。 // 这段代码虽然不会导致死锁，但没有正确的释放锁。从写锁降级成读锁， // 并不会自动释放当前线程获取的写锁，仍然需要显示的释放，否则别的线程永远也获取不到写锁。 public static void main(String[] args) { ReentrantReadWriteLock rtLock = new ReentrantReadWriteLock(); rtLock.writeLock().lock(); System.out.println(\"writeLock\"); rtLock.readLock().lock(); System.out.println(\"get read lock\"); }} 五，SemaphoreSemaphore也是一个线程同步的辅助类，可以维护当前访问自身的线程个数，并提供了同步机制。使用Semaphore可以控制同时访问资源的线程个数，例如，实现一个文件允许的并发访问数。Semaphore的主要方法摘要： void acquire():从此信号量获取一个许可，在提供一个许可前一直将线程阻塞，否则线程被中断。 void release():释放一个许可，将其返回给信号量。 int availablePermits():返回此信号量中当前可用的许可数。 boolean hasQueuedThreads():查询是否有线程正在等待获取。 1234567891011121314151617// 创建一个计数阈值为5的信号量对象// 只能5个线程同时访问Semaphore semp = new Semaphore(5);try { // 申请许可 semp.acquire(); try { // 业务逻辑 } catch (Exception e) { } finally { // 释放许可 semp.release(); }} catch (InterruptedException e) { } 六，Exchange两个线程之间交换数据","link":"/2020/10/20/%E7%BA%BF%E7%A8%8B%E5%90%8C%E6%AD%A5%E9%94%81%E6%9C%BA%E5%88%B6/"},{"title":"AbstractQueuedSynchronizer","text":"一，AQS如何设置链表尾巴compareAndGetTail(oldTail, node);一般来说锁整个链表，改为只锁尾巴，通过cas操作，不需要把原来的整个链表上锁 二，CLH锁AQS中的等待队列：是一个双向链表，并使用了“CLH锁”的思想实现等待队列（1）CLH锁是一个自旋锁，能确保无饥饿性，提供先来先服务的公平性。 （2）CLH锁也是一种基于链表的可扩展、高性能、公平的自旋锁，申请线程只在本地变量上自旋，它不断轮询前驱的状态，如果发现前驱释放了锁就结束自旋。 （3）在AQS中，等待队列中的每个节点也是类似的去轮训前继节点的状态。不过为了减少资源浪费，会加入线程waitting的优化。当然，这不是唯一的获取资源的方式，如果头部节点释放资源后，也会主动的去唤醒waitting状态的后继节点前言谈到并发，我们不得不说AQS(AbstractQueuedSynchronizer)，所谓的AQS即是抽象的队列式的同步器，内部定义了很多锁相关的方法，我们熟知的ReentrantLock、ReentrantReadWriteLock、CountDownLatch、Semaphore等都是基于AQS来实现的。 三，AQS实现原理AQS中 维护了一个volatile int state（代表共享资源）和一个FIFO线程等待队列（多线程争用资源被阻塞时会进入此队列）。 这里volatile能够保证多线程下的可见性，当state=1则代表当前对象锁已经被占有，其他线程来加锁时则会失败，加锁失败的线程会被放入一个FIFO的等待队列中，比列会被UNSAFE.park()操作挂起，等待其他获取锁的线程释放锁才能够被唤醒。 另外state的操作都是通过CAS来保证其并发修改的安全性。 四，参考URLhttps://blog.csdn.net/weixin_43314519/article/details/108160297","link":"/2020/10/20/AbstractQueuedSynchronizer/"},{"title":"Java引用之强软弱虚","text":"title: Java引用之强软弱虚toc: truecategories: javatags: javathumbnail: /logo/java.jpg—Java引用之强软弱虚一，强引用默认的引用就是强引用，NormalReference二，软引用SoftReference，当有一个对象(字节数组)被一个软引用所指向的时候，只有系统内存不够的时候，才会回收，非常适合做缓存使用三，弱引用弱引用只要遇到GC就会回收123456789101112ReferenceQueue referenceQueue = new ReferenceQueue();String str = new String(\"abc\");SoftReference softReference = new SoftReference(str, referenceQueue);str = null;// Notify GCSystem.gc();System.out.println(softReference.get()); // abcReference reference = referenceQueue.poll();System.out.println(reference); //null 四，虚引用虚引用顾名思义，就是形同虚设。与其他几种引用都不同，虚引用并不会决定对象的生命周期。如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收器回收。应用场景：虚引用主要用来跟踪对象被垃圾回收器回收的活动。虚引用与软引用和弱引用的一个区别在于： 虚引用必须和引用队列(ReferenceQueue)联合使用。当垃圾回收器准备回收一个对象时，如果发现它还有虚引用，就会在回收对象的内存之前，把这个虚引用加入到与之关联的引用队列中。","link":"/2020/10/20/Java%E5%BC%95%E7%94%A8%E4%B9%8B%E5%BC%BA%E8%BD%AF%E5%BC%B1%E8%99%9A/"},{"title":"ThreadLocal","text":"title: ThreadLocaltoc: truecategories: javatags: javathumbnail: /logo/java.jpg—ThreadLocal 一，ThreadLocal简介ThreadLocalMap是Thread中的一个属性，ThreadLocal.ThreadLocalMapThreadLocal不是为了解决多线程访问共享变量，而是为每个线程创建一个单独的变量副本，提供了保持对象的方法和避免参数传递的复杂性。 二，ThreadLocal内存泄漏问题每个thread中都存在一个map, map的类型是ThreadLocal.ThreadLocalMap.Map中的key为一个threadlocal实例. 这个Map的确使用了弱引用,不过弱引用只是针对key.每个key都弱引用指向threadlocal.当把threadlocal实例置为null以后,没有任何强引用指向threadlocal实例,所以threadlocal将会被gc回收. 但是,我们的value却不能回收,因为存在一条从current thread连接过来的强引用. 只有当前thread结束以后,current thread就不会存在栈中,强引用断开, Current Thread, Map, value将全部被GC回收。所以得出一个结论就是只要这个线程对象被gc回收，就不会出现内存泄露，但在threadLocal设为null和线程结束这段时间不会被回收的，就发生了我们认为的内存泄露。其实这是一个对概念理解的不一致，也没什么好争论的。最要命的是线程对象不被回收的情况，这就发生了真正意义上的内存泄露。比如使用线程池的时候，线程结束是不会销毁的，会再次使用的就可能出现内存泄露 。（在web应用中，每次http请求都是一个线程，tomcat容器配置使用线程池时会出现内存泄漏问题）","link":"/2020/10/20/ThreadLocal/"},{"title":"ThreadPoolExecutor的七个参数","text":"ThreadPoolExecutor的七个参数corePoolSize：线程池的基本大小，即在没有任务需要执行的时候线程池的大小，并且只有在工作队列满了的情况下才会创建超出这个数量的线程。maximumPoolSize：线程池中允许的最大线程数，线程池中的当前线程数目不会超过该值。如果队列中任务已满，并且当前线程个数小于maximumPoolSize，那么会创建新的线程来执行任务。keepAliveTime当线程空闲时间达到keepAliveTime，该线程会退出，直到线程数量等于corePoolSize。如果allowCoreThreadTimeout设置为true，则所有线程均会退出直到线程数量为0。workQueueArrayBlockingQueue、LinkedBlockingQueuethreadFactory线程工厂，自定义线程名，指定线程优先级handler拒绝策略有4中拒绝策略1，Abort:抛异常2，Discard:扔掉，不抛异常3，DiscardOldest：扔掉排队时间最久的4，CallerRuns：调用者处理服务 线程池执行步骤当线程数小于核心线程数时，创建线程。当线程数大于等于核心线程数，且任务队列未满时，将任务放入任务队列。当线程数大于等于核心线程数，且任务队列已满若线程数小于最大线程数，创建线程若线程数等于最大线程数，抛出异常，拒绝任务 具体方法1234567public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) 线程池设置大小建议N(threads) = N(cpu)*U(cpu,期望利用率) * (1+w/c)","link":"/2020/10/20/ThreadPoolExecutor%E7%9A%84%E4%B8%83%E4%B8%AA%E5%8F%82%E6%95%B0/"},{"title":"todo/冒泡","text":"","link":"/2020/10/20/todo/%E5%86%92%E6%B3%A1/"},{"title":"todo/快排","text":"","link":"/2020/10/20/todo/%E5%BF%AB%E6%8E%92/"},{"title":"todo/选择","text":"","link":"/2020/10/20/todo/%E9%80%89%E6%8B%A9/"},{"title":"todo/堆排","text":"","link":"/2020/10/20/todo/%E5%A0%86%E6%8E%92/"},{"title":"ik分词原理及源码解析","text":"做搜索技术的不可能不接触分词器。个人认为为什么搜索引擎无法被数据库所替代的原因主要有两点，一个是在数据量比较大的时候，搜索引擎的查询速度快，第二点在于，搜索引擎能做到比数据库更理解用户。第一点好理解，每当数据库的单个表大了，就是一件头疼的事，还有在较大数据量级的情况下，你让数据库去做模糊查询，那也是一件比较吃力的事（当然前缀匹配会好得多），设计上就应当避免。关于第二点，搜索引擎如何理解用户，肯定不是简单的靠匹配，这里面可以加入很多的处理，甚至加入各种自然语言处理的高级技术，而比较通用且基本的方法就是靠分词器来完成，而且这是一种比较简单而且高效的处理方法。 分词技术是搜索技术里面的一块基石。很多人用过，如果你只是为了简单快速地搭一个搜索引擎，你确实不用了解太深。但一旦涉及效果问题，分词器上就可以做很多文章。例如， 在实我们际用作电商领域的搜索的工作中，类目预判的实现就极须依赖分词，至少需要做到可以对分词器动态加规则。再一个简单的例子，如果你的优化方法就是对不同的词分权重，提高一些重点词的权重的话，你就需要依赖并理解分词器。本文将根据ik分配器的原码对其实现做一定分析。其中的重点，主要3点，1、词典树的构建，即将现在的词典加载到一个内存结构中去， 2、词的匹配查找，也就相当生成对一个句话中词的切分方式，3、歧义判断，即对不同切分方式的判定，哪种应是更合理的。代码原网址为：https://code.google.com/p/ik-analyzer/已上传github，可访问：https://github.com/quentinxxz/Search/tree/master/IKAnalyzer2012FF_hf1_source/ 词典做后台数据相关操作，一切工作的源头都是数据来源了。IK分词器为我们词供了三类词表分别是：1、主词表 main2012.dic 2、量词表quantifier.dic 3、停用词stopword.dic。Dictionary为字典管理类中，分别加载了这个词典到内存结构中。具体的字典代码，位于org.wltea.analyzer.dic.DictSegment。 这个类实现了一个分词器的一个核心数据结构，即Tire Tree。 Tire Tree（字典树）是一种结构相当简单的树型结构，用于构建词典，通过前缀字符逐一比较对方式，快速查找词，所以有时也称为前缀树。具体的例子如下。 图1从左来看，abc，abcd，abd，b，bcd…..这些词就是存在树中的单词。当然中文字符也可以一样处理，但中文字符的数目远多于26个，不应该以位置代表字符（英文的话，可以每节点包完一个长度为26的数组），如此的话，这棵tire tree会变得相当扩散，并占用内存，因而有一个tire Tree的变种，三叉字典树（Ternary Tree），保证占用较小的内存。Ternary Tree不在ik分词器中使用，所以不在此详述，请参考文章http://www.cnblogs.com/rush/archive/2012/12/30/2839996.htmlIK中采用的是一种比方简单的实现。先看一下，DictSegment类的成员： class DictSegment implements Comparable{ //公用字典表，存储汉字 private static final Map charMap = new HashMap(16 , 0.95f); //数组大小上限 private static final int ARRAY_LENGTH_LIMIT = 3; //Map存储结构 private Map childrenMap; //数组方式存储结构 private DictSegment[] childrenArray; //当前节点上存储的字符 private Character nodeChar; //当前节点存储的Segment数目 //storeSize ARRAY_LENGTH_LIMIT ,则使用Map存储 private int storeSize = 0; //当前DictSegment状态 ,默认 0 , 1表示从根节点到当前节点的路径表示一个词 private int nodeState = 0; …… 这里有两种方式去存储，根据ARRAY_LENGTH_LIMIT作为阈值来决定，如果当子节点数，不太于阈值时，采用数组的方式childrenArray来存储，当子节点数大于阈值时，采用Map的方式childrenMap来存储，childrenMap是采用HashMap实现的。这样做好处在于，节省内存空间。因为HashMap的方式的方式，肯定是需要预先分配内存的，就可能会存在浪费的现象，但如果全都采用数组去存组（后续采用二分的方式查找），你就无法获得O（1）的算法复杂度。所以这里采用了两者方式，当子节点数很少时，用数组存储，当子结点数较多时候，则全部迁至hashMap中去。在构建过程中，会将每个词一步步地加入到字典树中，这是一个递归的过程： /** 加载填充词典片段 @param charArray @param begin @param length @param enabled /private synchronized void fillSegment(char[] charArray , int begin , int length , int enabled){ …… //搜索当前节点的存储，查询对应keyChar的keyChar，如果没有则创建 DictSegment ds = lookforSegment(keyChar , enabled); if(ds != null){ //处理keyChar对应的segment if(length > 1){ //词元还没有完全加入词典树 ds.fillSegment(charArray, begin + 1, length - 1 , enabled); }else if (length == 1){ //已经是词元的最后一个char,设置当前节点状态为enabled， //enabled=1表明一个完整的词，enabled=0表示从词典中屏蔽当前词 ds.nodeState = enabled; } } }其中lookforSegment，就会在所在子树的子节点中查找，如果是少于ARRAY_LENGTH_LIMIT阈值，则是为数组存储，采用二分查找；如果大于ARRAY_LENGTH_LIMIT阈值，则为HashMap存储，直接查找。 词语切分IK分词器，基本可分为两种模式，一种为smart模式，一种为非smart模式。例如原文：张三说的确实在理smart模式的下分词结果为：张三 | 说的 | 确实 | 在理而非smart模式下的分词结果为：张三 | 三 | 说的 | 的确 | 的 | 确实 | 实在 | 在理 可见非smart模式所做的就是将能够分出来的词全部输出；smart模式下，IK分词器则会根据内在方法输出一个认为最合理的分词结果，这就涉及到了歧义判断。首来看一下最基本的一些元素结构类： public class Lexeme implements Comparable{ …… //词元的起始位移 private int offset; //词元的相对起始位置 private int begin; //词元的长度 private int length; //词元文本 private String lexemeText; //词元类型 private int lexemeType; …… 这里的Lexeme（词元），就可以理解为是一个词语或个单词。其中的begin，是指其在输入文本中的位置。注意，它是实现Comparable的，起始位置靠前的优先，长度较长的优先，这可以用来决定一个词在一条分词结果的词元链中的位置，可以用于得到上面例子中分词结果中的各个词的顺序。 /* 词元在排序集合中的比较算法 @see java.lang.Comparable#compareTo(java.lang.Object) /public int compareTo(Lexeme other) {//起始位置优先 if(this.begin < other.getBegin()){ return -1; }else if(this.begin == other.getBegin()){ //词元长度优先 if(this.length > other.getLength()){ return -1; }else if(this.length == other.getLength()){ return 0; }else {//this.length < other.getLength() return 1; } }else{//this.begin > other.getBegin() return 1; }}还有一个重要的结构就是词元链，声明如下 /** Lexeme链（路径） /class LexemePath extends QuickSortSet implements Comparable一条LexmePath，你就可以认为是上述分词的一种结果，根据前后顺序组成一个链式结构。可以看到它实现了QuickSortSet，所以它本身在加入词元的时候，就在内部完成排序，形成了一个有序的链，而排序规则就是上面Lexeme的compareTo方法所实现的。你也会注意到，LexemePath也是实现Comparable接口的，这就是用于后面的歧义分析用的，下一节介绍。另一个重要的结构是AnalyzeContext，这里面就主要存储了输入信息 的文本，切分出来的lemexePah ，分词结果等一些相关的上下文信息。 IK中默认用到三个子分词器，分别是LetterSegmenter（字母分词器），CN_QuantifierSegment(量词分词器)，CJKSegmenter(中日韩分词器)。分词是会先后经过这三个分词器，我们这里重点根据CJKSegment分析。其核心是一个analyzer方法。 public void analyze(AnalyzeContext context) { ……. //优先处理tmpHits中的hit if(!this.tmpHits.isEmpty()){ //处理词段队列 Hit[] tmpArray = this.tmpHits.toArray(new Hit[this.tmpHits.size()]); for(Hit hit : tmpArray){ hit = Dictionary.getSingleton().matchWithHit(context.getSegmentBuff(), context.getCursor() , hit); if(hit.isMatch()){ //输出当前的词 Lexeme newLexeme = new Lexeme(context.getBufferOffset() , hit.getBegin() , context.getCursor() - hit.getBegin() + 1 , Lexeme.TYPE_CNWORD); context.addLexeme(newLexeme); if(!hit.isPrefix()){//不是词前缀，hit不需要继续匹配，移除 this.tmpHits.remove(hit); } }else if(hit.isUnmatch()){ //hit不是词，移除 this.tmpHits.remove(hit); } } } //********************************* //再对当前指针位置的字符进行单字匹配 Hit singleCharHit = Dictionary.getSingleton().matchInMainDict(context.getSegmentBuff(), context.getCursor(), 1); if(singleCharHit.isMatch()){//首字成词 //输出当前的词 Lexeme newLexeme = new Lexeme(context.getBufferOffset() , context.getCursor() , 1 , Lexeme.TYPE_CNWORD); context.addLexeme(newLexeme); //同时也是词前缀 if(singleCharHit.isPrefix()){ //前缀匹配则放入hit列表 this.tmpHits.add(singleCharHit); } }else if(singleCharHit.isPrefix()){//首字为词前缀 //前缀匹配则放入hit列表 this.tmpHits.add(singleCharHit); } ……}从下半截代码看起，这里的matchInMain就是用于匹配主题表内的词的方法。这里的主词表已经加载至一个字典树之内，所以整个过程也就是一个从树根层层往下走的一个层层递归的方式，但这里只处理单字，不会去递归。而匹配的结果一共三种UNMATCH（未匹配），MATCH（匹配）， PREFIX（前缀匹配），Match指完全匹配已经到达叶子节点，而PREFIX是指当前对上所经过的匹配路径存在，但未到达到叶子节点。此外一个词也可以既是MATCH也可以是PREFIX，例如图1中的abc。前缀匹配的都被存入了tempHit中去。而完整匹配的都存入context中保存。继续看上半截代码，前缀匹配的词不应该就直接结束，因为有可能还能往后继续匹配更长的词，所以上半截代码所做的就是对这些词继续匹配。matchWithHit，就是在当前的hit的结果下继续做匹配。如果得到MATCH的结果，便可以在context中加入新的词元。通过这样不段匹配，循环补充的方式，我们就可以得到所有的词，至少能够满足非smart模式下的需求。 歧义判断IKArbitrator(歧义分析裁决器)是处理歧义的主要类。如果觉着我这说不清，也可以参考的博客：http://fay19880111-yeah-net.iteye.com/blog/1523740 在上一节中，我们提到LexemePath是实现compareble接口的。 public int compareTo(LexemePath o) { //比较有效文本长度 if(this.payloadLength > o.payloadLength){ return -1; }else if(this.payloadLength < o.payloadLength){ return 1; }else{ //比较词元个数，越少越好 if(this.size() < o.size()){ return -1; }else if (this.size() > o.size()){ return 1; }else{ //路径跨度越大越好 if(this.getPathLength() > o.getPathLength()){ return -1; }else if(this.getPathLength() < o.getPathLength()){ return 1; }else { //根据统计学结论，逆向切分概率高于正向切分，因此位置越靠后的优先 if(this.pathEnd > o.pathEnd){ return -1; }else if(pathEnd < o.pathEnd){ return 1; }else{ //词长越平均越好 if(this.getXWeight() > o.getXWeight()){ return -1; }else if(this.getXWeight() < o.getXWeight()){ return 1; }else { //词元位置权重比较 if(this.getPWeight() > o.getPWeight()){ return -1; }else if(this.getPWeight() < o.getPWeight()){ return 1; } } } } } } return 0; }显然作者在这里定死了一些排序的规则，依次比较有效文本长度、词元个数、路径跨度…..IKArbitrator有一个judge方法，对不同路径做了比较。 private LexemePath judge(QuickSortSet.Cell lexemeCell , int fullTextLength){ //候选路径集合 TreeSet pathOptions = new TreeSet(); //候选结果路径 LexemePath option = new LexemePath(); //对crossPath进行一次遍历,同时返回本次遍历中有冲突的Lexeme栈 Stack lexemeStack = this.forwardPath(lexemeCell , option); //当前词元链并非最理想的，加入候选路径集合 pathOptions.add(option.copy()); //存在歧义词，处理 QuickSortSet.Cell c = null; while(!lexemeStack.isEmpty()){ c = lexemeStack.pop(); //回滚词元链 this.backPath(c.getLexeme() , option); //从歧义词位置开始，递归，生成可选方案 this.forwardPath(c , option); pathOptions.add(option.copy()); } //返回集合中的最优方案 return pathOptions.first(); }其核心处理思想是从第一个词元开始，遍历各种路径，然后加入至一个TreeSet中，实现了排序，取第一个即可。 其它说明1、stopWord(停用词)，会在最后输出结果的阶段（AnalyzeContext. getNextLexeme）被移除，不会在分析的过程中移除，否则也会存在风险。2、可以从LexemePath的compareTo方法中看出，Ik的排序方法特别粗略，如果比较发现path1的词个数，比path2的个数少，就直接判定path1更优。其实这样的规则，并未完整的参考各个分出来的词的实际情况，我们可能想加入每个词经统计出现的频率等信息，做更全面的打分，这样IK原有的比较方法就是不可行的。关于如何修改的思路可以参考另一篇博客，其中介绍了一种通过最短路径思路去处理的方法: http://www.hankcs.com/nlp/segment/n-shortest-path-to-the-java-implementation-and-application-segmentation.html 3、未匹配的单字，不论是否在smart模式下，最后都会输出，其处理时机在最后输出结果阶段，具体代码位于在AnalyzeContext. outputToResult方法中。","link":"/2020/10/20/ik%E5%88%86%E8%AF%8D%E5%8E%9F%E7%90%86%E5%8F%8A%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/"},{"title":"todo/elasticsearch搜索优化","text":"","link":"/2020/10/20/todo/elasticsearch%E6%90%9C%E7%B4%A2%E4%BC%98%E5%8C%96/"},{"title":"todo/elasticsearch搜索过程","text":"","link":"/2020/10/20/todo/elasticsearch%E6%90%9C%E7%B4%A2%E8%BF%87%E7%A8%8B/"},{"title":"todo/elasticsearch索引优化","text":"","link":"/2020/10/20/todo/elasticsearch%E7%B4%A2%E5%BC%95%E4%BC%98%E5%8C%96/"},{"title":"todo/elasticsearch选主算法","text":"","link":"/2020/10/20/todo/elasticsearch%E9%80%89%E4%B8%BB%E7%AE%97%E6%B3%95/"},{"title":"Java运行时数据区","text":"Java运行时数据区Java虚拟机在执行Java程序过程中会把内存区域划分为若干个不同的数据区域，这些区域各有各自的用途、创建和销毁时间。 Java虚拟机运行时数据区程序计数器程序计数器占用较小的内存空间，可以看做是当前线程所执行的字节码的行号指示器，由于Java虚拟机的多线程是通过线程轮流切换并分配处理器执行时间的方式来实现的，在任何一个确定的时刻，一个处理器（对于多核处理器来说就是一个内核）都只会执行一条线程中的指令。因此，为了线程切换后能够恢复到正确的执行位置，每条线程都需要有一个独立的程序计数器。 如果线程正在执行Java方法，则计数器记录的是正在执行的虚拟机字节码指令的地址；如果正在执行的是Native方法，则这个计数器则为空。 Java虚拟机栈虚拟机栈也是线程私有，而且生命周期与线程相同，每个Java方法在执行的时候都会创建一个栈帧（Stack Frame）用于存储局部变量表、操作数栈、动态链接、方法出口等信息。 局部变量表：存放了编译器可知的各种基本数据类型（boolean、byte等）、对象引用（reference类型，它不等同于对象本身，可能是一个指向对象起始地址的引用指针，也可能是指向另一个代表对象的句柄或其他次对象相关的位置）和returnAddress类型（指向了一条字节码指令的地址）局部变量表Java虚拟机规范中，对该区域规定了这两种异常情况： 如果线程请求的栈深度大于虚拟机所允许的深度，讲抛出StackOverflowError异常；虚拟机栈可以动态拓展，当扩展时无法申请到足够的内存，就会抛出OutOfMemoryError异常。本地方法栈本地方法栈的作用与虚拟机栈作用是非常类似的。 Java堆对大多数应用来说，Java堆（Heap）是Java虚拟机所管理的内存中最大的一块，Java堆是被所有线程共享的一块内存区域，在虚拟机启动时创建。该内存区域唯一的目的就是存放对象实例，Java对象实例以及数组都在堆上分配（随着JIT编译器发展等技术成熟，所有对象分配在堆上也渐渐不是那么“绝对”了）。 Java堆是垃圾收集器管理的主要区域，因此Java堆也常被称为“GC堆”，由于现在收集器基于分代收集算法，Java堆还可以细分为：新生代和老年代。 根据Java虚拟机规范的规定，Java堆可以处于物理上不连续的内存空间中，只要逻辑上是连续的即可，就像我们的磁盘空间一样（或者说，像链表一样虽然内存上不一定连续，但逻辑上是连续）。如果在堆中没有内存完成实例分配，而且堆也没办法再扩展时，将会抛出OutOfMemoryError异常。 方法区方法区与Java堆一样，是各个线程共享的内存区域，用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。Java虚拟机规范对方法区的限制非常宽松，除了和Java堆一样不需要连续的内存和可以选择固定大小或者可拓展外，还可以选择不实现垃圾收集。相对而言，垃圾收集行为在这个区域是比较少出现的，但并非数据进入了方法区就成为了永久代。该区域的内存回收目标主要是针对常量池的回收和对类型的卸载。 Java虚拟机规范规定，当方法区无法满足内存分配需求时，讲抛出OutOfMemoryError异常。 运行时常量池运行时常量池是方法区的一部分，Class文件中除了有关类的版本、字段、方法、接口等描述信息外，还有一项信息是常量池，用于存放编译期生成的各种字面量和符号引用，这部分内容将在类加载后进入方法区的运行时常量池中存放。 运行时常量池相对于Class文件常量池的另一个重要特征是具备动态性，Java语言并非不要求常量一定只有编译期才能产生，也就是并非预置入Class文件中常量池的内容才能进入方法区运行时常量池，运行期间也可以将新的常量池放入池中。","link":"/2020/10/21/todo/Java%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA/"}],"tags":[{"name":"elasticsearch","slug":"elasticsearch","link":"/tags/elasticsearch/"},{"name":"linux","slug":"linux","link":"/tags/linux/"},{"name":"git","slug":"git","link":"/tags/git/"},{"name":"java","slug":"java","link":"/tags/java/"},{"name":"人文","slug":"人文","link":"/tags/%E4%BA%BA%E6%96%87/"}],"categories":[{"name":"elasticsearch","slug":"elasticsearch","link":"/categories/elasticsearch/"},{"name":"linux","slug":"linux","link":"/categories/linux/"},{"name":"git","slug":"git","link":"/categories/git/"},{"name":"java","slug":"java","link":"/categories/java/"},{"name":"人文","slug":"人文","link":"/categories/%E4%BA%BA%E6%96%87/"},{"name":"kafka","slug":"kafka","link":"/categories/kafka/"},{"name":"算法","slug":"算法","link":"/categories/%E7%AE%97%E6%B3%95/"}]}