{"pages":[],"posts":[{"title":"ElasticSearch之索引模板","text":"一，模板简述template大致分成setting和mappings两部分：索引可使用预定义的模板进行创建,这个模板称作Index templates。模板设置包括settings和mappings，通过模式匹配的方式使得多个索引重用一个模板。 settings主要作用于index的一些相关配置信息，如分片数、副本数，tranlog同步条件、refresh等。 mappings主要是一些说明信息，大致又分为_all、_source、prpperties这三部分： (1) _all：主要指的是AllField字段，我们可以将一个或多个都包含进来，在进行检索时无需指定字段的情况下检索多个字段。设置“_all” : {“enabled” : true} (2) _source：主要指的是SourceField字段，Source可以理解为ES除了将数据保存在索引文件中，另外还有一份源数据。_source字段在我们进行检索时相当重要，如果在{“enabled” : false}情况下默认检索只会返回ID， 你需要通过Fields字段去到索引中去取数据，效率不是很高。但是enabled设置为true时，索引会比较大，这时可以通过Compress进行压缩和inclueds、excludes来在字段级别上进行一些限制，自定义哪些字段允许存储。 (3) properties：这是最重要的步骤，主要针对索引结构和字段级别上的一些设置。 咱们通常在elasticsearch中 post mapping信息，每重新创建索引便到设置mapping，分片，副本信息。非常繁琐。强烈建议大家通过设置template方式设置索引信息。设置索引名，通过正则匹配的方式匹配到相应的模板。ps:直接修改mapping的优先级>索引template。索引匹配了多个template，当属性等配置出现不一致的，以order的最大值为准，order默认值为0 二，创建模板例如： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455{ \"template\": \"pmall*\", \"settings\": { \"index.number_of_shards\": 1, \"number_of_replicas\": 4, \"similarity\": { \"IgnoreTFSimilarity\": { \"type\": \"IgoreTFSimilarity\" } } }, \"mappings\": { \"_default_\": { \"_source\": { \"enabled\": false } }, \"commodity\": { \"properties\": { \"sold\": { \"type\": \"long\" }, \"online_time\": { \"type\": \"long\" }, \"price\": { \"type\": \"long\" }, \"publish_time\": { \"type\": \"long\" }, \"id\": { \"type\": \"long\" }, \"catecode\": { \"type\": \"integer\" }, \"title\": { \"search_analyzer\": \"ikSmart\", \"similarity\": \"IgnoreTFSimilarity\", \"analyzer\": \"ik\", \"type\": \"text\" }, \"content\": { \"index\": false, \"store\": true, \"type\": \"keyword\" }, \"status\": { \"type\": \"integer\" } } } }} 三，删除模板12DELETE /_template/template_1 四，查看模板：1GET /_template/template_1 也可以通过模糊匹配得到多个模板信息 1GET /_template/temp* 可以批量查看模板 1GET /_template/template_1,template_2 验证模板是否存在： 1HEAD _template/template_1 五：多个模板同时匹配，以order顺序倒排，order越大，优先级越高1234567891011121314151617181920212223242526272829 PUT /_template/template_1{ \"template\" : \"*\", \"order\" : 0, \"settings\" : { \"number_of_shards\" : 1 }, \"mappings\" : { \"type1\" : { \"_source\" : { \"enabled\" : false } } }}PUT /_template/template_2{ \"template\" : \"te*\", \"order\" : 1, \"settings\" : { \"number_of_shards\" : 1 }, \"mappings\" : { \"type1\" : { \"_source\" : { \"enabled\" : true } } }} 六，模板版本号模板可以选择添加版本号，这可以是任何整数值，以便简化外部系统的模板管理。版本字段是完全可选的，它仅用于模板的外部管理。要取消设置版本，只需替换模板即可 创建模板： 123456789PUT /_template/template_1{ \"template\" : \"*\", \"order\" : 0, \"settings\" : { \"number_of_shards\" : 1 }, \"version\": 123} 查看模板版本号： 1GET /_template/template_1?filter_path=*.version 响应如下： 12345{ \"template_1\" : { \"version\" : 123 }} 七，参考：[url=https://www.elastic.co/guide/en/elasticsearch/reference/5.4/indices-templates.html]indices-templates[/url]","link":"/2020/03/06/ElasticSearch%E4%B9%8B%E7%B4%A2%E5%BC%95%E6%A8%A1%E6%9D%BF/"},{"title":"Elasticsearch 搜索模块之preference参数","text":"##一，preference简述 elasticsearch可以使用preference参数来指定分片查询的优先级，即我们可以通过该参数来控制搜索时的索引数据分片。 如不设置该参数：在所有有效的主分片以及副本间轮询。 具体可看下：OperationRouting.java类 123public ShardIterator activeInitializingShardsRandomIt() { return activeInitializingShardsIt(shuffler.nextSeed());} 自增，以实现shard间轮询操作 123456789101112131415public int nextSeed() { return seed.getAndIncrement(); }``` ```javapublic ShardIterator activeInitializingShardsIt(int seed) { if (allInitializingShards.isEmpty()) { return new PlainShardIterator(shardId, shuffler.shuffle(activeShards, seed)); } ArrayList ordered = new ArrayList(activeShards.size() + allInitializingShards.size()); ordered.addAll(shuffler.shuffle(activeShards, seed)); ordered.addAll(allInitializingShards); return new PlainShardIterator(shardId, ordered);} private ShardIterator preferenceActiveShardIterator(IndexShardRoutingTable indexShard, String localNodeId, DiscoveryNodes nodes, @Nullable String preference) { if (preference == null || preference.isEmpty()) { if (awarenessAttributes.length == 0) { return indexShard.activeInitializingShardsRandomIt(); } else { return indexShard.preferAttributesActiveInitializingShardsIt(awarenessAttributes, nodes); } } if (preference.charAt(0) == '_') { Preference preferenceType = Preference.parse(preference); if (preferenceType == Preference.SHARDS) { // starts with _shards, so execute on specific ones int index = preference.indexOf('|'); String shards; if (index == -1) { shards = preference.substring(Preference.SHARDS.type().length() + 1); } else { shards = preference.substring(Preference.SHARDS.type().length() + 1, index); } String ids = Strings.splitStringByCommaToArray(shards); boolean found = false; for (String id : ids) { if (Integer.parseInt(id) == indexShard.shardId().id()) { found = true; break; } } if (!found) { return null; } // no more preference if (index == -1 || index == preference.length() - 1) { if (awarenessAttributes.length == 0) { return indexShard.activeInitializingShardsRandomIt(); } else { return indexShard.preferAttributesActiveInitializingShardsIt(awarenessAttributes, nodes); } } else { // update the preference and continue preference = preference.substring(index + 1); } } preferenceType = Preference.parse(preference); switch (preferenceType) { case PREFER_NODES: final Set nodesIds = Arrays.stream( preference.substring(Preference.PREFER_NODES.type().length() + 1).split(\",\") ).collect(Collectors.toSet()); return indexShard.preferNodeActiveInitializingShardsIt(nodesIds); case LOCAL: return indexShard.preferNodeActiveInitializingShardsIt(Collections.singleton(localNodeId)); case PRIMARY: return indexShard.primaryActiveInitializingShardIt(); case REPLICA: return indexShard.replicaActiveInitializingShardIt(); case PRIMARY_FIRST: return indexShard.primaryFirstActiveInitializingShardsIt(); case REPLICA_FIRST: return indexShard.replicaFirstActiveInitializingShardsIt(); case ONLY_LOCAL: return indexShard.onlyNodeActiveInitializingShardsIt(localNodeId); case ONLY_NODES: String nodeAttributes = preference.substring(Preference.ONLY_NODES.type().length() + 1); return indexShard.onlyNodeSelectorActiveInitializingShardsIt(nodeAttributes.split(\",\"), nodes); default: throw new IllegalArgumentException(\"unknown preference [\" + preferenceType + \"]\"); } } // if not, then use it as the index if (awarenessAttributes.length == 0) { return indexShard.activeInitializingShardsIt(Murmur3HashFunction.hash(preference)); } else { return indexShard.preferAttributesActiveInitializingShardsIt(awarenessAttributes, nodes, Murmur3HashFunction.hash(preference)); } } 二，结果震荡问题（Bouncing Results） 搜索同一query，结果ES返回的顺序却不尽相同，这就是请求轮询到不同分片，而未设置排序条件，相同相关性评分情况下，是按照所在segment中​lucene id来排序的，相同数据的不同备份之间该id是不能保证一致的，故造成结果震荡问题。如设置该参数，则有一下9种情况 _primary:发送到集群的相关操作请求只会在主分片上执行。_primary_first:指查询会先在主分片中查询，如果主分片找不到（挂了），就会在副本中查询。_replica:发送到集群的相关操作请求只会在副本上执行。_replica_first：指查询会先在副本中查询，如果副本找不到（挂了），就会在主分片中查询。_local: 指查询操作会优先在本地节点有的分片中查询，没有的话再在其它节点查询。_prefer_nodes:abc,xyz:在提供的节点上优先执行（在这种情况下为’abc’或’xyz’）_shards:2,3：限制操作到指定的分片。 （2和“3”）。这个偏好可以与其他偏好组合，但必须首先出现：_shards：2,3 | _primary_only_nodes:node1,node2:指在指定id的节点里面进行查询，如果该节点只有要查询索引的部分分片，就只在这部分分片中查找，不同节点之间用“，”分隔。 custom(自定义)：注意自定义的preference参数不能以下划线”_”开头。当preference为自定义时，即该参数不为空，且开头不以“下划线”开头时，特别注意：如果以用户query作为自定义preference时，一定要处理以下划线开头的情况，这种情况下如果不属于以上8种情况，则会抛出异常。 三，参考： https://www.elastic.co/guide/en/elasticsearch/reference/current/search-request-preference.html","link":"/2020/03/06/Elasticsearch%20%E6%90%9C%E7%B4%A2%E6%A8%A1%E5%9D%97%E4%B9%8Bpreference%E5%8F%82%E6%95%B0/"},{"title":"Elasticsearch源码编译by Intellij Idea","text":"##一、软件环境Intellij Idea:2017.1版本Elasticsearch源码版本:5.3.1JDK:1.8.0_111Gradle :建议3.3及以上版本。官网：https://gradle.org/##二、下载Elasticsearch源码到github clone源码，https://github.com/elastic/elasticsearch.git，建议选择稳定版本分支。 ##三、导入idea1，##编译执行gradle build.gradle，报错：you must run gradle idea from the root of elasticsearch before importing into intellij解决办法：运行命令：gradle idea。同理如使用eclipse编译器，运行gradle eclipse。该过程会向mvn仓库下载响应的jar包，视网络情况，大概会持续20分钟。 ##2，运行org.elasticsearch.bootstrap.Elasticsearch 方法，报错：“path.home is not configured” when starting ES in transport and client mode“，解决办法：在VM options中加入配置：-Des.path.home=/home/jiangtao/code/elasticsearch/core，即指向相应的core模块的路径。 ##3，报错：org.elasticsearch.bootstrap.BootstrapException: java.nio.file.NoSuchFileException 123456789101112Exception in thread \"main\" org.elasticsearch.bootstrap.BootstrapException: java.nio.file.NoSuchFileException: /home/jiangtao/code/elasticsearch/core/config Likely root cause: java.nio.file.NoSuchFileException: /home/jiangtao/code/elasticsearch/core/config at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86) at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) at sun.nio.fs.UnixFileAttributeViews$Basic.readAttributes(UnixFileAttributeViews.java:55) at sun.nio.fs.UnixFileSystemProvider.readAttributes(UnixFileSystemProvider.java:144) at sun.nio.fs.LinuxFileSystemProvider.readAttributes(LinuxFileSystemProvider.java:99) at java.nio.file.Files.readAttributes(Files.java:1737) at java.nio.file.FileTreeWalker.getAttributes(FileTreeWalker.java:225) at java.nio.file.FileTreeWalker.visit(FileTreeWalker.java:276) at java.nio.file.FileTreeWalker.walk(FileTreeWalker.java:322) at java.nio.file.Files.walkFileTree(Files.java:2662) 解决办法：将distribution模块src路径下的config整个文件copy到core模块中 ##4，报错： ERROR Could not register mbeans java.security.AccessControlException 1234567892017-06-06 09:52:08,007 main ERROR Could not register mbeans java.security.AccessControlException: access denied (\"javax.management.MBeanTrustPermission\" \"register\") at java.security.AccessControlContext.checkPermission(AccessControlContext.java:472) at java.lang.SecurityManager.checkPermission(SecurityManager.java:585) at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.checkMBeanTrustPermission(DefaultMBeanServerInterceptor.java:1848) at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:322) at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522) at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:91) at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:84) 解决办法：禁用jmx,在VM options中继续添加配置： -Dlog4j2.disable.jmx=true。注意：在VM options中多个配置中间用空格分隔。123456789101112131415161718192021##5，报错： java.lang.IllegalStateException: Unsupported transport.type 错误栈如下：```java[2017-06-06T10:04:21,327][WARN ][o.e.b.ElasticsearchUncaughtExceptionHandler] uncaught exception in thread [main]org.elasticsearch.bootstrap.StartupException: java.lang.IllegalStateException: Unsupported transport.type at org.elasticsearch.bootstrap.Elasticsearch.init(Elasticsearch.java:127) ~[main/:?]at org.elasticsearch.bootstrap.Elasticsearch.execute(Elasticsearch.java:114) ~[main/:?]at org.elasticsearch.cli.EnvironmentAwareCommand.execute(EnvironmentAwareCommand.java:58) ~[main/:?]at org.elasticsearch.cli.Command.mainWithoutErrorHandling(Command.java:122) ~[main/:?]at org.elasticsearch.cli.Command.main(Command.java:88) ~[main/:?]at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:91) ~[main/:?]at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:84) ~[main/:?]Caused by: java.lang.IllegalStateException: Unsupported transport.type at org.elasticsearch.common.network.NetworkModule.getTransportSupplier(NetworkModule.java:213) ~[main/:?]at org.elasticsearch.node.Node.(Node.java:421) ~[main/:?]at org.elasticsearch.node.Node.(Node.java:242) ~[main/:?]at org.elasticsearch.bootstrap.Bootstrap$6.(Bootstrap.java:242) ~[main/:?]at org.elasticsearch.bootstrap.Bootstrap.setup(Bootstrap.java:242) ~[main/:?]at org.elasticsearch.bootstrap.Bootstrap.init(Bootstrap.java:360) ~[main/:?]at org.elasticsearch.bootstrap.Elasticsearch.init(Elasticsearch.java:123) ~[main/:?]... 6 more 这个是由于依赖的transport等jar并没有找到，可以在项目根目录找到models模块，然后将下面目录打包，然后copy到distribution/src/main/models目录下，也可以直接去官网（https://www.elastic.co/downloads/elasticsearch）下载zip包，解压后直接copy。我直接去官网下载的zip包：从官网下载完毕zip包后，具体解决办法请看：错误 6。 ##6，copy module版本冲突错误栈如下： 123456789org.elasticsearch.bootstrap.StartupException: java.lang.IllegalArgumentException: Plugin [lang-expression] is incompatible with Elasticsearch [5.3.4]. Was designed for version [5.3.1] at org.elasticsearch.bootstrap.Elasticsearch.init(Elasticsearch.java:127) ~[main/:?] at org.elasticsearch.bootstrap.Elasticsearch.execute(Elasticsearch.java:114) ~[main/:?] at org.elasticsearch.cli.EnvironmentAwareCommand.execute(EnvironmentAwareCommand.java:58) ~[main/:?] at org.elasticsearch.cli.Command.mainWithoutErrorHandling(Command.java:122) ~[main/:?] at org.elasticsearch.cli.Command.main(Command.java:88) ~[main/:?]at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:91) ~[main/:?]at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:84) ~[main/:?]Caused by: java.lang.IllegalArgumentException: Plugin [lang-expression] is incompatible with Elasticsearch [5.3.4]. Was designed for version [5.3.1] 解决办法：修改es当前版本将core模块中的Version.java类由public static final Version CURRENT = V_5_3_4_UNRELEASED;修改为：public static final Version CURRENT = V_5_3_1;","link":"/2020/03/06/Elasticsearch%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91by%20Intellij%20Idea/"},{"title":"Elasticsearch负载高问题排查","text":"我们Elasticsearch集群近几日负载飙高，排查思路记录如下； 查看日志信息，确定是否存在异常情况 12cd ${ES_HOME}/logstail -100f ES.log 频繁Full GC往往会引起负载飙高，故查看ES集群GC 情况， 使用命令： 1jstat -gcutil 近一个多月，服务共Full GC700余次，平均每次Full GC耗时90ms，符合预期，排除Full GC问题导致负载飙高；4. 找到ES中占用CPU的线程ID 1top -Hp PID 如找到ES进程中2291线程较费CPU 将得到的线程id，转化为16进制 12printf %x 2291输出结果：8f3 使用jstack分析线程状态jstack命令主要用于调试java程序运行过程中的线程堆栈信息 1jstack PID >> pid.txt 8.查看pid.txt文件，分析线程对应的堆栈信息由步骤6得到 16进制线程“8f3” 12vim pid.txt//查找线程“8f3”对应信息 内容如下 123456789101112131415\"elasticsearch[data-es12][write][T#3]\" #94 daemon prio=5 os_prio=0 tid=0x00007f3254017800 nid=0x8f3 waiting for monitor entry [0x00007f2d37a7a000] java.lang.Thread.State: BLOCKED (on object monitor) at org.elasticsearch.index.translog.TranslogWriter.syncUpTo(TranslogWriter.java:342) - waiting to lock (a java.lang.Object) at org.elasticsearch.index.translog.Translog.ensureSynced(Translog.java:797) at org.elasticsearch.index.translog.Translog.ensureSynced(Translog.java:818) at org.elasticsearch.index.engine.InternalEngine.ensureTranslogSynced(InternalEngine.java:489) at org.elasticsearch.index.shard.IndexShard$5.write(IndexShard.java:2782) at org.elasticsearch.common.util.concurrent.AsyncIOProcessor.processList(AsyncIOProcessor.java:107) at org.elasticsearch.common.util.concurrent.AsyncIOProcessor.drainAndProcess(AsyncIOProcessor.java:99) at org.elasticsearch.common.util.concurrent.AsyncIOProcessor.put(AsyncIOProcessor.java:82) at org.elasticsearch.index.shard.IndexShard.sync(IndexShard.java:2804) at org.elasticsearch.action.support.replication.TransportWriteAction$AsyncAfterWriteAction.run(TransportWriteAction.java:355) at org.elasticsearch.action.support.replication.TransportWriteAction$WritePrimaryResult.(TransportWriteAction.java:151) at 该线程正处于堵塞状态。 9，原因分析从ES索引数据创建机制说起写请求首先先写到内存一份数据，然后写translog，默认每1秒进行refresh，将索引写入到文件系统；该ES集群是ELK日志查询服务，特点读多写少，我们TB级数据，上千个索引，refresh_interval参数1s，在日志服务中显然不太合适，是时候调整下该参数配置了。 10，参数调整 123456http://ip:port/logstash*/_settings PUT{ \"settings\": { \"refresh_interval\": \"5m\" }} 11，问题解决","link":"/2020/03/20/Elasticsearch%E8%B4%9F%E8%BD%BD%E9%AB%98%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5/"},{"title":"Git如何回退版本","text":"首先使用git log查看最近几次提交的版本号，如版本号”0250cd”; 在命令行输入 git reset –hard 0250cd，成功后会提示”head is now at 0250cd”； git push -f -u origin you_branch,you_branch需要回退的分支名","link":"/2020/03/20/Git%E5%A6%82%E4%BD%95%E5%9B%9E%E9%80%80%E7%89%88%E6%9C%AC/"},{"title":"Git如何回退版本","text":"目录 1、什么是垃圾 2、如何定位垃圾 reference count Root Searching 3、常见的垃圾回收算法 Mark-Sweep(标记清除) Copying(拷贝算法） Mark-Compact（标记压缩)​ 4、JVM内存分代模型(用于分代垃圾回收算法） 堆内存逻辑分区 5、垃圾回收器 Serial Parallel Scavenge ParNew SerialOld Parallel Old CMS 6、JVM参数 7、思维导图 1、什么是垃圾 内存分配与回收方式： C语言：malloc、free C++：new、delete Java：new 自动回收内存 自动回收内存系统不容易出错，手动回收内存，容易出现以下的错误： 忘记回收 多次回收 垃圾的定义：没有任何引用指向的一个对象或者多个对象(循环引用）。 当把成员变量设置为空(null)之后，不再指向任何引用对象，那么该对象就被称作垃圾： 还有一种情况，多个对象之间互相引用，但是没有其他的引用指向这个循环的对象。 2、如何定位垃圾 reference count 当引用计数变为0的时候，这个对象就成为垃圾了。但是引用计数不能解决对象循环引用 如下： 每个引用计数都是1，但是它们全部是垃圾，所以用引用计数的方式的话，这些垃圾就找不到了，会发生内存泄漏。 Root Searching 根可达或者根搜索算法。 通过程序找到一些根对象，通过根对象找到它所连接的那些对象不是垃圾，其他的都是垃圾。 Roots：线程栈变量、静态变量、常量池、JNI指针 3、常见的垃圾回收算法 Mark-Sweep(标记清除) 将可回收的对象标记为非垃圾。 缺点：位置不连续，产生内存碎片。 Copying(拷贝算法） 内存一分为二，将存活对象复制到未使用的内存中，原内存全部标记为可使用；新分配内存时先分配存活对象所在的那段内存，垃圾回收时，重复上述操作。 特点：没有碎片，但是内浪费空间。最大的问题：内存浪费。 Mark-Compact（标记压缩) 将存活对象依次复制到垃圾对象和未使用的区域中，结合了标记清除和拷贝的做法，但是效率比copy略低。 三种方法找垃圾的效率是一致的，区别在于找到垃圾后对其进行整理的方式。拷贝算法是内存拷贝，是线性地址的拷贝，速度很快的，效率很高。但是压缩算法却不这么简单，因为任意一个内存进行移动时，如果是多线程， 都要进行线程同步；如果是单线程，那单线程的效率本来就低。 所以任何一块内存挪动都要进行线程同步，所以效率肯定是很低的。 4、JVM内存分代模型(用于分代垃圾回收算法） 目前，生产环境中普遍使用的是JDK1.7或JDK1.8，根据JDK版本不同，分代也不同。 JVM中分代：新生代+老年代+永久代(JDK1.7)/元数据区(JDK1.8)Metaspace。 永久代和元数据区是装载Class的，将硬盘上的Class对象load到内存的时候，装载了永久代或者元数据区域，具体放在哪里区别于使用的JDK版本 永久代必须指定大小限制，而元数据可以设置，也可不设置，无上限(受限于物理内存） 字符串常量在JDK1.7中，是放在永久代区域；而JDK1.8中，是放在堆里 MethodArea是一个逻辑概念，并不是指的一个区域，在JDK1.7中对应的就是永久代，JDK1.8中对应的是元数据 堆内存逻辑分区 新生代中分了两类区域，eden和survivor，而survivor有两块。默认的比例，新生代：老年代=1：3，新生代中eden: survivor：survivor = 8:1:1。 之所以新生代中按照这个比例分配，是因为eden区在GC的时候，90%的对象都会被回收，剩下的存活对象在survivor区是可以放下的。 当创建一个对象时，默认会去找eden区， 如果对象特别大，eden区装不下则直接进入老年代。 新生代 = Eden + 2个survivor区(survivor0、survivor1）： YGC(Young GC)回收后，大多数的对象会被回收，活着的对象进入survivor0 再次YGC，活着的对象eden+s0拷贝到s1，将eden和s0清空 再次YGC，活着的对象eden+s1拷贝到s0，将eden和s1清空 年龄足够->老年代(年龄足够：15，CMS 6) survivor区装不下的时候，装不下的部分直接进入老年代 老年代： 顽固份子 老年代区域满了，就进行Full GC(简称FGC, FGC包括新生代和老年代同时GC) GC Tuning：尽量减少FGC。 5、垃圾回收器 Serial、ParNew、Parallel Scavenge是用于回收Young Generation CMS、Serial Old、Parallel Old是用于回收Old Generation G1、ZGC、Shenandoah不区分老年代和新生代。 Epsilon是一个空的GC，仅仅用于调试JDK。 图中的红色虚线表示可以配合使用。 Serial 垃圾回收的时候，程序是无法执行的。stop-the-world(STW)是停止程序运行，回收线程开始运行，回收结束后程序再接着运行。 Parallel Scavenge 并行回收，多个线程同时进行垃圾回收。 ParNew 配合CMS的年轻代并行回收。 SerialOld 单线程回收算法用于old区域 Parallel Old 多线程回收算法用于old区域 CMS ConcurrentMarkSweep，用于回收老年代，在垃圾回收的同时程序也能运行。(黄色的表示垃圾回收线程，蓝色表示程序执行线程） 调优针对的是Serial、Parallel Scavenge和Serial Old、Parallel New，因为JDK1.8默认的垃圾回收：Parallel Scavenge + Parallel Old。 6、JVM参数 JVM的命令行参数参考：https://docs.oracle.com/javase/8/docs/technotes/tools/unix/java.html JVM参数分类： 标准：-开头，所有的HotSpot都支持。 如：java -version 非标准：-X开头，特定版本HotSpot支持特定命令 不稳定：-XX开头，下个版本可能取消 -XX: +PrintFlagsFinal --- 设置值（最终生效值) -XX:+PrintFlagsInitial --- 默认值 -XX:+PrintCommandLineFlags ---命令行参数 7、思维导图 参考文档： https://blogs.oracle.com/jonthecollector/our-collectors https://blogs.oracle.com/jonthecollector/why-not-a-grand-unified-garbage-collector","link":"/2020/02/26/jvm-GC-and-GC-Tuning/"},{"title":"lambda表达式","text":"一，排序对数组从小到大排序 123public void sortUsingLambda(List indexs) { Collections.sort(indexs, (s1, s2) -> s1.compareTo(s2));} 更简洁的实现方式 123public void sortUsingLambda(List indexs) { Collections.sort(indexs, Integer::compareTo);} 对数组从小到大排序 123public void sortUsingLambda(List indexs) { Collections.sort(indexs, (s1, s2) -> s2.compareTo(s1));} 从小到大简洁实现 123public void sortUsingLambda(List indexs) { Collections.sort(indexs, Comparator.reverseOrder());} 二，list转map①：取list中某2个字段作为Map的K,V 123public Map getIdNameMap(List accounts) { return accounts.stream().collect(Collectors.toMap(Account::getId, Account::getUsername));} ②：将id和实体Bean做为K,V 123public Map getIdAccountMap(List accounts) { return accounts.stream().collect(Collectors.toMap(Account::getId, account -> account));} 或者这样写 123public Map getIdAccountMap(List accounts) { return accounts.stream().collect(Collectors.toMap(Account::getId, Function.identity()));} account -> account是一个返回本身的lambda表达式，后面的使用Function接口中的一个默认方法代替，使整个方法更简洁优雅。③：key存在重复记录时处理 123public Map getNameAccountMap(List accounts) { return accounts.stream().collect(Collectors.toMap(Account::getUsername, Function.identity(), (key1, key2) -> key2));} ④：使用某个具体的Map类来保存，如保存时使用LinkedHashMap 123public Map getNameAccountMap(List accounts) { return accounts.stream().collect(Collectors.toMap(Account::getUsername, Function.identity(), (key1, key2) -> key2, LinkedHashMap::new));} ⑤：List转List 123456789101112public Map getCodeListMap(){ if(CollectionUtils.isEmpty(codeListMap)){ List codeList = this.getCodeList(); Set keySet = codeList.stream().map(code -> code.getCodeKbn()).collect(Collectors.toSet()); Iterator it = keySet.iterator(); while(it.hasNext()) { String key = it.next(); codeListMap.put(key, codeList.stream().filter(code -> code.getCodeKbn().equals(key)).collect(Collectors.toList())); } } return codeListMap;} 三，Map转List 1234567891011121314151617Map map = new HashMap();// Convert all Map keys to a ListList result = new ArrayList(map.keySet());// Convert all Map values to a ListList result2 = new ArrayList(map.values());// Java 8, Convert all Map keys to a ListList result3 = map.keySet().stream() .collect(Collectors.toList());// Java 8, Convert all Map values to a ListList result4 = map.values().stream() .collect(Collectors.toList());// Java 8, seem a bit long, but you can enjoy the Stream features like filter and etc.List result5 = map.values().stream() .filter(x -> !\"apple\".equalsIgnoreCase(x)) .collect(Collectors.toList());// Java 8, split a map into 2 List, it works!// refer example 3 below","link":"/2020/03/06/lambda%E8%A1%A8%E8%BE%BE%E5%BC%8F/"}],"tags":[{"name":"elasticsearch","slug":"elasticsearch","link":"/tags/elasticsearch/"},{"name":"git","slug":"git","link":"/tags/git/"},{"name":"java","slug":"java","link":"/tags/java/"}],"categories":[{"name":"elasticsearch","slug":"elasticsearch","link":"/categories/elasticsearch/"},{"name":"git","slug":"git","link":"/categories/git/"},{"name":"java","slug":"java","link":"/categories/java/"}]}