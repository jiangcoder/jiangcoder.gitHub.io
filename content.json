{"pages":[],"posts":[{"title":"ElasticSearch之索引模板","text":"一，模板简述template大致分成setting和mappings两部分：索引可使用预定义的模板进行创建,这个模板称作Index templates。模板设置包括settings和mappings，通过模式匹配的方式使得多个索引重用一个模板。 settings主要作用于index的一些相关配置信息，如分片数、副本数，tranlog同步条件、refresh等。 mappings主要是一些说明信息，大致又分为_all、_source、prpperties这三部分： (1) _all：主要指的是AllField字段，我们可以将一个或多个都包含进来，在进行检索时无需指定字段的情况下检索多个字段。设置“_all” : {“enabled” : true} (2) _source：主要指的是SourceField字段，Source可以理解为ES除了将数据保存在索引文件中，另外还有一份源数据。_source字段在我们进行检索时相当重要，如果在{“enabled” : false}情况下默认检索只会返回ID， 你需要通过Fields字段去到索引中去取数据，效率不是很高。但是enabled设置为true时，索引会比较大，这时可以通过Compress进行压缩和inclueds、excludes来在字段级别上进行一些限制，自定义哪些字段允许存储。 (3) properties：这是最重要的步骤，主要针对索引结构和字段级别上的一些设置。 咱们通常在elasticsearch中 post mapping信息，每重新创建索引便到设置mapping，分片，副本信息。非常繁琐。强烈建议大家通过设置template方式设置索引信息。设置索引名，通过正则匹配的方式匹配到相应的模板。ps:直接修改mapping的优先级>索引template。索引匹配了多个template，当属性等配置出现不一致的，以order的最大值为准，order默认值为0 二，创建模板例如： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455{ \"template\": \"pmall*\", \"settings\": { \"index.number_of_shards\": 1, \"number_of_replicas\": 4, \"similarity\": { \"IgnoreTFSimilarity\": { \"type\": \"IgoreTFSimilarity\" } } }, \"mappings\": { \"_default_\": { \"_source\": { \"enabled\": false } }, \"commodity\": { \"properties\": { \"sold\": { \"type\": \"long\" }, \"online_time\": { \"type\": \"long\" }, \"price\": { \"type\": \"long\" }, \"publish_time\": { \"type\": \"long\" }, \"id\": { \"type\": \"long\" }, \"catecode\": { \"type\": \"integer\" }, \"title\": { \"search_analyzer\": \"ikSmart\", \"similarity\": \"IgnoreTFSimilarity\", \"analyzer\": \"ik\", \"type\": \"text\" }, \"content\": { \"index\": false, \"store\": true, \"type\": \"keyword\" }, \"status\": { \"type\": \"integer\" } } } }} 三，删除模板12DELETE /_template/template_1 四，查看模板：1GET /_template/template_1 也可以通过模糊匹配得到多个模板信息 1GET /_template/temp* 可以批量查看模板 1GET /_template/template_1,template_2 验证模板是否存在： 1HEAD _template/template_1 五：多个模板同时匹配，以order顺序倒排，order越大，优先级越高1234567891011121314151617181920212223242526272829 PUT /_template/template_1{ \"template\" : \"*\", \"order\" : 0, \"settings\" : { \"number_of_shards\" : 1 }, \"mappings\" : { \"type1\" : { \"_source\" : { \"enabled\" : false } } }}PUT /_template/template_2{ \"template\" : \"te*\", \"order\" : 1, \"settings\" : { \"number_of_shards\" : 1 }, \"mappings\" : { \"type1\" : { \"_source\" : { \"enabled\" : true } } }} 六，模板版本号模板可以选择添加版本号，这可以是任何整数值，以便简化外部系统的模板管理。版本字段是完全可选的，它仅用于模板的外部管理。要取消设置版本，只需替换模板即可 创建模板： 123456789PUT /_template/template_1{ \"template\" : \"*\", \"order\" : 0, \"settings\" : { \"number_of_shards\" : 1 }, \"version\": 123} 查看模板版本号： 1GET /_template/template_1?filter_path=*.version 响应如下： 12345{ \"template_1\" : { \"version\" : 123 }} 七，参考：[url=https://www.elastic.co/guide/en/elasticsearch/reference/5.4/indices-templates.html]indices-templates[/url]","link":"/2020/03/06/ElasticSearch%E4%B9%8B%E7%B4%A2%E5%BC%95%E6%A8%A1%E6%9D%BF/"},{"title":"Elasticsearch 搜索模块之preference参数","text":"##一，preference简述 elasticsearch可以使用preference参数来指定分片查询的优先级，即我们可以通过该参数来控制搜索时的索引数据分片。 如不设置该参数：在所有有效的主分片以及副本间轮询。 具体可看下：OperationRouting.java类 123public ShardIterator activeInitializingShardsRandomIt() { return activeInitializingShardsIt(shuffler.nextSeed());} 自增，以实现shard间轮询操作 123public int nextSeed() { return seed.getAndIncrement(); } 123456789public ShardIterator activeInitializingShardsIt(int seed) { if (allInitializingShards.isEmpty()) { return new PlainShardIterator(shardId, shuffler.shuffle(activeShards, seed)); } ArrayList ordered = new ArrayList(activeShards.size() + allInitializingShards.size()); ordered.addAll(shuffler.shuffle(activeShards, seed)); ordered.addAll(allInitializingShards); return new PlainShardIterator(shardId, ordered);} 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576private ShardIterator preferenceActiveShardIterator(IndexShardRoutingTable indexShard, String localNodeId, DiscoveryNodes nodes, @Nullable String preference) { if (preference == null || preference.isEmpty()) { if (awarenessAttributes.length == 0) { return indexShard.activeInitializingShardsRandomIt(); } else { return indexShard.preferAttributesActiveInitializingShardsIt(awarenessAttributes, nodes); } } if (preference.charAt(0) == '_') { Preference preferenceType = Preference.parse(preference); if (preferenceType == Preference.SHARDS) { // starts with _shards, so execute on specific ones int index = preference.indexOf('|'); String shards; if (index == -1) { shards = preference.substring(Preference.SHARDS.type().length() + 1); } else { shards = preference.substring(Preference.SHARDS.type().length() + 1, index); } String ids = Strings.splitStringByCommaToArray(shards); boolean found = false; for (String id : ids) { if (Integer.parseInt(id) == indexShard.shardId().id()) { found = true; break; } } if (!found) { return null; } // no more preference if (index == -1 || index == preference.length() - 1) { if (awarenessAttributes.length == 0) { return indexShard.activeInitializingShardsRandomIt(); } else { return indexShard.preferAttributesActiveInitializingShardsIt(awarenessAttributes, nodes); } } else { // update the preference and continue preference = preference.substring(index + 1); } } preferenceType = Preference.parse(preference); switch (preferenceType) { case PREFER_NODES: final Set nodesIds = Arrays.stream( preference.substring(Preference.PREFER_NODES.type().length() + 1).split(\",\") ).collect(Collectors.toSet()); return indexShard.preferNodeActiveInitializingShardsIt(nodesIds); case LOCAL: return indexShard.preferNodeActiveInitializingShardsIt(Collections.singleton(localNodeId)); case PRIMARY: return indexShard.primaryActiveInitializingShardIt(); case REPLICA: return indexShard.replicaActiveInitializingShardIt(); case PRIMARY_FIRST: return indexShard.primaryFirstActiveInitializingShardsIt(); case REPLICA_FIRST: return indexShard.replicaFirstActiveInitializingShardsIt(); case ONLY_LOCAL: return indexShard.onlyNodeActiveInitializingShardsIt(localNodeId); case ONLY_NODES: String nodeAttributes = preference.substring(Preference.ONLY_NODES.type().length() + 1); return indexShard.onlyNodeSelectorActiveInitializingShardsIt(nodeAttributes.split(\",\"), nodes); default: throw new IllegalArgumentException(\"unknown preference [\" + preferenceType + \"]\"); } } // if not, then use it as the index if (awarenessAttributes.length == 0) { return indexShard.activeInitializingShardsIt(Murmur3HashFunction.hash(preference)); } else { return indexShard.preferAttributesActiveInitializingShardsIt(awarenessAttributes, nodes, Murmur3HashFunction.hash(preference)); } } ##二，结果震荡问题（Bouncing Results） 搜索同一query，结果ES返回的顺序却不尽相同，这就是请求轮询到不同分片，而未设置排序条件，相同相关性评分情况下，是按照所在segment中​lucene id来排序的，相同数据的不同备份之间该id是不能保证一致的，故造成结果震荡问题。如设置该参数，则有一下9种情况 _primary:发送到集群的相关操作请求只会在主分片上执行。_primary_first:指查询会先在主分片中查询，如果主分片找不到（挂了），就会在副本中查询。_replica:发送到集群的相关操作请求只会在副本上执行。_replica_first：指查询会先在副本中查询，如果副本找不到（挂了），就会在主分片中查询。_local: 指查询操作会优先在本地节点有的分片中查询，没有的话再在其它节点查询。_prefer_nodes:abc,xyz:在提供的节点上优先执行（在这种情况下为’abc’或’xyz’）_shards:2,3：限制操作到指定的分片。 （2和“3”）。这个偏好可以与其他偏好组合，但必须首先出现：_shards：2,3 | _primary_only_nodes:node1,node2:指在指定id的节点里面进行查询，如果该节点只有要查询索引的部分分片，就只在这部分分片中查找，不同节点之间用“，”分隔。 custom(自定义)：注意自定义的preference参数不能以下划线”_”开头。当preference为自定义时，即该参数不为空，且开头不以“下划线”开头时，特别注意：如果以用户query作为自定义preference时，一定要处理以下划线开头的情况，这种情况下如果不属于以上8种情况，则会抛出异常。 三，参考： https://www.elastic.co/guide/en/elasticsearch/reference/current/search-request-preference.html","link":"/2020/03/06/Elasticsearch%20%E6%90%9C%E7%B4%A2%E6%A8%A1%E5%9D%97%E4%B9%8Bpreference%E5%8F%82%E6%95%B0/"},{"title":"Elasticsearch源码编译by Intellij Idea","text":"##一、软件环境Intellij Idea:2017.1版本Elasticsearch源码版本:5.3.1JDK:1.8.0_111Gradle :建议3.3及以上版本。官网：https://gradle.org/##二、下载Elasticsearch源码到github clone源码，https://github.com/elastic/elasticsearch.git，建议选择稳定版本分支。 ##三、导入idea1，##编译执行gradle build.gradle，报错：you must run gradle idea from the root of elasticsearch before importing into intellij解决办法：运行命令：gradle idea。同理如使用eclipse编译器，运行gradle eclipse。该过程会向mvn仓库下载响应的jar包，视网络情况，大概会持续20分钟。 ##2，运行org.elasticsearch.bootstrap.Elasticsearch 方法，报错：“path.home is not configured” when starting ES in transport and client mode“，解决办法：在VM options中加入配置：-Des.path.home=/home/jiangtao/code/elasticsearch/core，即指向相应的core模块的路径。 ##3，报错：org.elasticsearch.bootstrap.BootstrapException: java.nio.file.NoSuchFileException 123456789101112Exception in thread \"main\" org.elasticsearch.bootstrap.BootstrapException: java.nio.file.NoSuchFileException: /home/jiangtao/code/elasticsearch/core/config Likely root cause: java.nio.file.NoSuchFileException: /home/jiangtao/code/elasticsearch/core/config at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86) at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) at sun.nio.fs.UnixFileAttributeViews$Basic.readAttributes(UnixFileAttributeViews.java:55) at sun.nio.fs.UnixFileSystemProvider.readAttributes(UnixFileSystemProvider.java:144) at sun.nio.fs.LinuxFileSystemProvider.readAttributes(LinuxFileSystemProvider.java:99) at java.nio.file.Files.readAttributes(Files.java:1737) at java.nio.file.FileTreeWalker.getAttributes(FileTreeWalker.java:225) at java.nio.file.FileTreeWalker.visit(FileTreeWalker.java:276) at java.nio.file.FileTreeWalker.walk(FileTreeWalker.java:322) at java.nio.file.Files.walkFileTree(Files.java:2662) 解决办法：将distribution模块src路径下的config整个文件copy到core模块中 ##4，报错： ERROR Could not register mbeans java.security.AccessControlException 1234567892017-06-06 09:52:08,007 main ERROR Could not register mbeans java.security.AccessControlException: access denied (\"javax.management.MBeanTrustPermission\" \"register\") at java.security.AccessControlContext.checkPermission(AccessControlContext.java:472) at java.lang.SecurityManager.checkPermission(SecurityManager.java:585) at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.checkMBeanTrustPermission(DefaultMBeanServerInterceptor.java:1848) at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:322) at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522) at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:91) at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:84) 解决办法：禁用jmx,在VM options中继续添加配置： -Dlog4j2.disable.jmx=true。注意：在VM options中多个配置中间用空格分隔。123456789101112131415161718192021##5，报错： java.lang.IllegalStateException: Unsupported transport.type 错误栈如下：```java[2017-06-06T10:04:21,327][WARN ][o.e.b.ElasticsearchUncaughtExceptionHandler] uncaught exception in thread [main]org.elasticsearch.bootstrap.StartupException: java.lang.IllegalStateException: Unsupported transport.type at org.elasticsearch.bootstrap.Elasticsearch.init(Elasticsearch.java:127) ~[main/:?]at org.elasticsearch.bootstrap.Elasticsearch.execute(Elasticsearch.java:114) ~[main/:?]at org.elasticsearch.cli.EnvironmentAwareCommand.execute(EnvironmentAwareCommand.java:58) ~[main/:?]at org.elasticsearch.cli.Command.mainWithoutErrorHandling(Command.java:122) ~[main/:?]at org.elasticsearch.cli.Command.main(Command.java:88) ~[main/:?]at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:91) ~[main/:?]at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:84) ~[main/:?]Caused by: java.lang.IllegalStateException: Unsupported transport.type at org.elasticsearch.common.network.NetworkModule.getTransportSupplier(NetworkModule.java:213) ~[main/:?]at org.elasticsearch.node.Node.(Node.java:421) ~[main/:?]at org.elasticsearch.node.Node.(Node.java:242) ~[main/:?]at org.elasticsearch.bootstrap.Bootstrap$6.(Bootstrap.java:242) ~[main/:?]at org.elasticsearch.bootstrap.Bootstrap.setup(Bootstrap.java:242) ~[main/:?]at org.elasticsearch.bootstrap.Bootstrap.init(Bootstrap.java:360) ~[main/:?]at org.elasticsearch.bootstrap.Elasticsearch.init(Elasticsearch.java:123) ~[main/:?]... 6 more 这个是由于依赖的transport等jar并没有找到，可以在项目根目录找到models模块，然后将下面目录打包，然后copy到distribution/src/main/models目录下，也可以直接去官网（https://www.elastic.co/downloads/elasticsearch）下载zip包，解压后直接copy。我直接去官网下载的zip包：从官网下载完毕zip包后，具体解决办法请看：错误 6。 ##6，copy module版本冲突错误栈如下： 123456789org.elasticsearch.bootstrap.StartupException: java.lang.IllegalArgumentException: Plugin [lang-expression] is incompatible with Elasticsearch [5.3.4]. Was designed for version [5.3.1] at org.elasticsearch.bootstrap.Elasticsearch.init(Elasticsearch.java:127) ~[main/:?] at org.elasticsearch.bootstrap.Elasticsearch.execute(Elasticsearch.java:114) ~[main/:?] at org.elasticsearch.cli.EnvironmentAwareCommand.execute(EnvironmentAwareCommand.java:58) ~[main/:?] at org.elasticsearch.cli.Command.mainWithoutErrorHandling(Command.java:122) ~[main/:?] at org.elasticsearch.cli.Command.main(Command.java:88) ~[main/:?]at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:91) ~[main/:?]at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:84) ~[main/:?]Caused by: java.lang.IllegalArgumentException: Plugin [lang-expression] is incompatible with Elasticsearch [5.3.4]. Was designed for version [5.3.1] 解决办法：修改es当前版本将core模块中的Version.java类由public static final Version CURRENT = V_5_3_4_UNRELEASED;修改为：public static final Version CURRENT = V_5_3_1;","link":"/2020/03/06/Elasticsearch%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91by%20Intellij%20Idea/"},{"title":"Elasticsearch定制化插件开发","text":"一，一般的插件开发方式： 按照官网教程，每次都得打包、替换、重启，这是一个很不方便的过程，固然可以通过testCase来做debug，但是所见即所得的编码习惯，直接上手debug，才是最高效的方式。 介绍插件开发的博客何其多，个人私以为都没有get到G点，其实深入研究下elasticsearch源码，fix 这个问题并不难，下面希望通过这篇文章帮助到大家。二，elasticsearch插件的加载机制①：Node节点启动过程，Elasticsearch.java会调用Bootstrap.java中的init函数。 1234567static void init(...) { ... INSTANCE = new Bootstrap(); INSTANCE.setup(true, environment); ... INSTANCE.start();} ②：Node节点通过setup方法进行实例化。 123456private void setup(boolean addShutdownHook, Environment environment) throws BootstrapException { node = new Node(environment) { ...} ③：Node.java类中会包含各类的service服务，其中包括PluginsService服务。在实例化PluginsService服务时会传参 123456789environment.pluginsFile(),classpathPlugins等参数。而pluginsFile()即是elasticsearch所指定的plugin目录，elasticsearch会扫描该路径下所有的插件，并加载进来。 public Node(Environment environment) { this(environment, Collections.emptyList());} protected Node(final Environment environment, Collection classpathPlugins) { ... this.pluginsService = new PluginsService(tmpSettings, environment.modulesFile(), environment.pluginsFile(), classpathPlugins);} ④：classpathPlugins参数介绍： 123public Node(Environment environment) { this(environment, Collections.emptyList()); } 在elasticsearch源码中，这个参数Collection classpathPlugins一直都是空集合。没有任何地方注入修改该参数。elasticsearch不但会扫描插件所在路径中的插件，同样也会加载classpathPlugins中所指定的插件，只不过问题是elasticsearch没有给我们提供相应的参数！！！！三，如何更优雅的开发开发插件 接上一段小节④，我们只要利用classpathPlugins该参数，就可以在elasticsearch源码环境中进行debug了！！！ 我的实现思路如下，通过继承Node.java，并重写Node类的构造方法，然后在bootstrap中直接实例化该子类，便可以通过elasticsearch直接bug 插件源码了。 下面贴出我的实现代码，供大家参考： 1234567891011121314151617181920212223242526import org.elasticsearch.Version;import org.elasticsearch.env.Environment;import org.elasticsearch.node.Node;import org.elasticsearch.plugins.Plugin;import java.util.Collection;public class EmbeddedNode extends Node { private Version version; private Collection plugins; public EmbeddedNode(Environment environment, Version version, Collection classpathPlugins) { super(environment, classpathPlugins); this.version = version; this.plugins = classpathPlugins; } public Collection getPlugins() { return plugins; } public Version getVersion() { return version; }} 123456789101112131415161718192021private void setup(boolean addShutdownHook, Environment environment) throws BootstrapException { ..... //注释Node初始化源码 /* node = new Node(environment) { @Override protected void validateNodeBeforeAcceptingRequests( final Settings settings, final BoundTransportAddress boundTransportAddress, List checks) throws NodeValidationException { BootstrapChecks.check(settings, boundTransportAddress, checks); } };*/ Collection plugins = new ArrayList(); Collections.addAll(plugins, AnalysisIkPlugin.class, HelloPlugin.class, AnalysisMMsegPlugin.class);//, ,AnalysisMMsegPlugin.class node = new EmbeddedNode(environment, Version.CURRENT, plugins) { @Override protected void validateNodeBeforeAcceptingRequests(final Settings settings, final BoundTransportAddress boundTransportAddress, List checks) throws NodeValidationException { BootstrapChecks.check(settings, boundTransportAddress, checks); } }; } 四，部署插件相关的注意事项： 有关插件开发的详细配置，es插件的种类，在此不再赘述，具体可参考官方文档，更权威，更直接。下面贴个图，本人在elasticsearch中同时整合了多个插件，以供学习研究时用，直接debug，个人感觉十分不错。","link":"/2020/03/27/Elasticsearch%E5%AE%9A%E5%88%B6%E5%8C%96%E6%8F%92%E4%BB%B6%E5%BC%80%E5%8F%91/"},{"title":"Linux系统之用户态、内核态","text":"#什么是内核态、用户态？内核态：cpu可以访问内存的所有数据，包括外围设备，例如硬盘，网卡，cpu也可以将自己从一个程序切换到另一个程序。用户态：只能受限的访问内存，且不允许访问外围设备，占用cpu的能力被剥夺，cpu资源可以被其他程序获取。 #为什么要有用户态和内核态？由于需要限制不同的程序之间的访问能力, 防止他们获取别的程序的内存数据, 或者获取外围设备的数据, 并发送到网络,CPU划分出两个权限等级 – 用户态和内核态。 #用户态与内核态的切换 所有用户程序都是运行在用户态的, 但是有时候程序确实需要做一些内核态的事情, 例如从硬盘读取数据, 或者从键盘获取输入等. 而唯一可以做这些事情的就是操作系统, 所以此时程序就需要先操作系统请求以程序的名义来执行这些操作.这时需要一个这样的机制: 用户态程序切换到内核态, 但是不能控制在内核态中执行的指令这种机制叫系统调用, 在CPU中的实现称之为陷阱指令(Trap Instruction)他们的工作流程如下:用户态程序将一些数据值放在寄存器中, 或者使用参数创建一个堆栈(stack frame), 以此表明需要操作系统提供的服务.用户态程序执行陷阱指令CPU切换到内核态, 并跳到位于内存指定位置的指令, 这些指令是操作系统的一部分, 他们具有内存保护, 不可被用户态程序访问这些指令称之为陷阱(trap)或者系统调用处理器(system call handler). 他们会读取程序放入内存的数据参数, 并执行程序请求的服务系统调用完成后, 操作系统会重置CPU为用户态并返回系统调用的结果当一个任务（进程）执行系统调用而陷入内核代码中执行时，我们就称进程处于内核运行态（或简称为内核态）。此时处理器处于特权级最高的（0级）内核代码中执行。当进程处于内核态时，执行的内核代码会使用当前进程的内核栈。每个进程都有自己的内核栈。当进程在执行用户自己的代码时，则称其处于用户运行态（用户态）。即此时处理器在特权级最低的（3级）用户代码中运行。当正在执行用户程序而突然被中断程序中断时，此时用户程序也可以象征性地称为处于进程的内核态。因为中断处理程序将使用当前进程的内核栈。这与处于内核态的进程的状态有些类似。 内核态与用户态是操作系统的两种运行级别,跟intel cpu没有必然的联系, intel cpu提供Ring0-Ring3三种级别的运行模式，Ring0级别最高，Ring3最低。Linux使用了Ring3级别运行用户态，Ring0作为 内核态，没有使用Ring1和Ring2。Ring3状态不能访问Ring0的地址空间，包括代码和数据。Linux进程的4GB地址空间，3G-4G部 分大家是共享的，是内核态的地址空间，这里存放在整个内核的代码和所有的内核模块，以及内核所维护的数据。用户运行一个程序，该程序所创建的进程开始是运 行在用户态的，如果要执行文件操作，网络数据发送等操作，必须通过write，send等系统调用，这些系统调用会调用内核中的代码来完成操作，这时，必 须切换到Ring0，然后进入3GB-4GB中的内核地址空间去执行这些代码完成操作，完成后，切换回Ring3，回到用户态。这样，用户态的程序就不能 随意操作内核地址空间，具有一定的安全保护作用。至于说保护模式，是说通过内存页表操作等机制，保证进程间的地址空间不会互相冲突，一个进程的操作不会修改另一个进程的地址空间中的数据。","link":"/2020/03/28/Linux%E7%B3%BB%E7%BB%9F%E4%B9%8B%E7%94%A8%E6%88%B7%E6%80%81%E3%80%81%E5%86%85%E6%A0%B8%E6%80%81/"},{"title":"Elasticsearch负载高问题排查","text":"我们Elasticsearch集群近几日负载飙高，排查思路记录如下； 查看日志信息，确定是否存在异常情况 12cd ${ES_HOME}/logstail -100f ES.log 频繁Full GC往往会引起负载飙高，故查看ES集群GC 情况， 使用命令： 1jstat -gcutil 近一个多月，服务共Full GC700余次，平均每次Full GC耗时90ms，符合预期，排除Full GC问题导致负载飙高；4. 找到ES中占用CPU的线程ID 1top -Hp PID 如找到ES进程中2291线程较费CPU 将得到的线程id，转化为16进制 12printf %x 2291输出结果：8f3 使用jstack分析线程状态jstack命令主要用于调试java程序运行过程中的线程堆栈信息 1jstack PID >> pid.txt 8.查看pid.txt文件，分析线程对应的堆栈信息由步骤6得到 16进制线程“8f3” 12vim pid.txt//查找线程“8f3”对应信息 内容如下 123456789101112131415\"elasticsearch[data-es12][write][T#3]\" #94 daemon prio=5 os_prio=0 tid=0x00007f3254017800 nid=0x8f3 waiting for monitor entry [0x00007f2d37a7a000] java.lang.Thread.State: BLOCKED (on object monitor) at org.elasticsearch.index.translog.TranslogWriter.syncUpTo(TranslogWriter.java:342) - waiting to lock (a java.lang.Object) at org.elasticsearch.index.translog.Translog.ensureSynced(Translog.java:797) at org.elasticsearch.index.translog.Translog.ensureSynced(Translog.java:818) at org.elasticsearch.index.engine.InternalEngine.ensureTranslogSynced(InternalEngine.java:489) at org.elasticsearch.index.shard.IndexShard$5.write(IndexShard.java:2782) at org.elasticsearch.common.util.concurrent.AsyncIOProcessor.processList(AsyncIOProcessor.java:107) at org.elasticsearch.common.util.concurrent.AsyncIOProcessor.drainAndProcess(AsyncIOProcessor.java:99) at org.elasticsearch.common.util.concurrent.AsyncIOProcessor.put(AsyncIOProcessor.java:82) at org.elasticsearch.index.shard.IndexShard.sync(IndexShard.java:2804) at org.elasticsearch.action.support.replication.TransportWriteAction$AsyncAfterWriteAction.run(TransportWriteAction.java:355) at org.elasticsearch.action.support.replication.TransportWriteAction$WritePrimaryResult.(TransportWriteAction.java:151) at 该线程正处于堵塞状态。 9，原因分析从ES索引数据创建机制说起写请求首先先写到内存一份数据，然后写translog，默认每1秒进行refresh，将索引写入到文件系统；该ES集群是ELK日志查询服务，特点读多写少，我们TB级数据，上千个索引，refresh_interval参数1s，在日志服务中显然不太合适，是时候调整下该参数配置了。 10，参数调整 123456http://ip:port/logstash*/_settings PUT{ \"settings\": { \"refresh_interval\": \"5m\" }} 11，问题解决","link":"/2020/03/20/Elasticsearch%E8%B4%9F%E8%BD%BD%E9%AB%98%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5/"},{"title":"Git如何回退版本","text":"首先使用git log查看最近几次提交的版本号，如版本号”0250cd”; 在命令行输入 git reset –hard 0250cd，成功后会提示”head is now at 0250cd”； git push -f -u origin you_branch,you_branch需要回退的分支名","link":"/2020/03/20/Git%E5%A6%82%E4%BD%95%E5%9B%9E%E9%80%80%E7%89%88%E6%9C%AC/"},{"title":"Java之Buffer","text":"一，Buffer概念Buffer 类是 java.nio 的构造基础。一个 Buffer 对象是固定数量的数据的容器，其作用是一个存储器，或者分段运输区.每个非布尔原始数据类型都有一个缓冲区类.子类有 1234567ByteBufferCharBufferIntBufferLongBufferDoubleBufferFloatBufferShortBuffer 二，缓存区的四个属性1234private int mark = -1;//一个备忘位置。标记在设定前是未定义的(undefined)。使用场景是，假设缓冲区中有 10 个元素，position 目前的位置为 2(也就是如果get的话是第三个元素)，现在只想发送 6 - 10 之间的缓冲数据，此时我们可以 buffer.mark(buffer.position())，即把当前的 position 记入 mark 中，然后 buffer.postion(6)，此时发送给 channel 的数据就是 6 - 10 的数据。发送完后，我们可以调用 buffer.reset() 使得 position = mark，因此这里的 mark 只是用于临时记录一下位置用的private int position = 0;//下一个要被读或写的元素的索引。位置会自动由相应的 get() 和 put() 函数更新。 这里需要注意的是positon的位置是从0开始的private int limit;//缓冲区的第一个不能被读或写的元素。缓冲创建时，limit 的值等于 capacity 的值。假设 capacity = 1024，我们在程序中设置了 limit = 512，说明，Buffer 的容量为 1024，但是从 512 之后既不能读也不能写，因此可以理解成，Buffer 的实际可用大小为 512private int capacity;//缓冲区能够容纳的数据元素的最大数量。这一容量在缓冲区创建时被设定，并且永远不能被改变。 三，flipflip() :写模式转到读模式clear()或者compact():重新从Buffer中读取数据such as : 123456789101112131415161718192021import java.nio.ByteBuffer;public class CreateBuffer { public static void main(String args[]) { ByteBuffer buffer = ByteBuffer.allocate(1024); buffer.put((byte) 'a'); buffer.put((byte) 'b'); buffer.put((byte) 'c'); //调用flip之后，读写指针指到缓存头部，并且设置了最多只能读出之前写入的数据长度(而不是整个缓存的容量大小) buffer.flip(); System.out.println((char) buffer.get());//a System.out.println((char) buffer.get());//b System.out.println((char) buffer.get());//c //重新从Buffer中读取数据 buffer.compact(); System.out.println((char) buffer.get());//a System.out.println((char) buffer.get());//b System.out.println((char) buffer.get());//c }}","link":"/2020/03/27/Java%E4%B9%8BBuffer/"},{"title":"lambda表达式","text":"一，排序对数组从小到大排序 123public void sortUsingLambda(List indexs) { Collections.sort(indexs, (s1, s2) -> s1.compareTo(s2));} 更简洁的实现方式 123public void sortUsingLambda(List indexs) { Collections.sort(indexs, Integer::compareTo);} 对数组从小到大排序 123public void sortUsingLambda(List indexs) { Collections.sort(indexs, (s1, s2) -> s2.compareTo(s1));} 从小到大简洁实现 123public void sortUsingLambda(List indexs) { Collections.sort(indexs, Comparator.reverseOrder());} 二，list转map①：取list中某2个字段作为Map的K,V 123public Map getIdNameMap(List accounts) { return accounts.stream().collect(Collectors.toMap(Account::getId, Account::getUsername));} ②：将id和实体Bean做为K,V 123public Map getIdAccountMap(List accounts) { return accounts.stream().collect(Collectors.toMap(Account::getId, account -> account));} 或者这样写 123public Map getIdAccountMap(List accounts) { return accounts.stream().collect(Collectors.toMap(Account::getId, Function.identity()));} account -> account是一个返回本身的lambda表达式，后面的使用Function接口中的一个默认方法代替，使整个方法更简洁优雅。③：key存在重复记录时处理 123public Map getNameAccountMap(List accounts) { return accounts.stream().collect(Collectors.toMap(Account::getUsername, Function.identity(), (key1, key2) -> key2));} ④：使用某个具体的Map类来保存，如保存时使用LinkedHashMap 123public Map getNameAccountMap(List accounts) { return accounts.stream().collect(Collectors.toMap(Account::getUsername, Function.identity(), (key1, key2) -> key2, LinkedHashMap::new));} ⑤：List转List 123456789101112public Map getCodeListMap(){ if(CollectionUtils.isEmpty(codeListMap)){ List codeList = this.getCodeList(); Set keySet = codeList.stream().map(code -> code.getCodeKbn()).collect(Collectors.toSet()); Iterator it = keySet.iterator(); while(it.hasNext()) { String key = it.next(); codeListMap.put(key, codeList.stream().filter(code -> code.getCodeKbn().equals(key)).collect(Collectors.toList())); } } return codeListMap;} 三，Map转List 1234567891011121314151617Map map = new HashMap();// Convert all Map keys to a ListList result = new ArrayList(map.keySet());// Convert all Map values to a ListList result2 = new ArrayList(map.values());// Java 8, Convert all Map keys to a ListList result3 = map.keySet().stream() .collect(Collectors.toList());// Java 8, Convert all Map values to a ListList result4 = map.values().stream() .collect(Collectors.toList());// Java 8, seem a bit long, but you can enjoy the Stream features like filter and etc.List result5 = map.values().stream() .filter(x -> !\"apple\".equalsIgnoreCase(x)) .collect(Collectors.toList());// Java 8, split a map into 2 List, it works!// refer example 3 below","link":"/2020/03/06/lambda%E8%A1%A8%E8%BE%BE%E5%BC%8F/"},{"title":"Git如何回退版本","text":"目录 1、什么是垃圾 2、如何定位垃圾 reference count Root Searching 3、常见的垃圾回收算法 Mark-Sweep(标记清除) Copying(拷贝算法） Mark-Compact（标记压缩)​ 4、JVM内存分代模型(用于分代垃圾回收算法） 堆内存逻辑分区 5、垃圾回收器 Serial Parallel Scavenge ParNew SerialOld Parallel Old CMS 6、JVM参数 7、思维导图 1、什么是垃圾 内存分配与回收方式： C语言：malloc、free C++：new、delete Java：new 自动回收内存 自动回收内存系统不容易出错，手动回收内存，容易出现以下的错误： 忘记回收 多次回收 垃圾的定义：没有任何引用指向的一个对象或者多个对象(循环引用）。 当把成员变量设置为空(null)之后，不再指向任何引用对象，那么该对象就被称作垃圾： 还有一种情况，多个对象之间互相引用，但是没有其他的引用指向这个循环的对象。 2、如何定位垃圾 reference count 当引用计数变为0的时候，这个对象就成为垃圾了。但是引用计数不能解决对象循环引用 如下： 每个引用计数都是1，但是它们全部是垃圾，所以用引用计数的方式的话，这些垃圾就找不到了，会发生内存泄漏。 Root Searching 根可达或者根搜索算法。 通过程序找到一些根对象，通过根对象找到它所连接的那些对象不是垃圾，其他的都是垃圾。 Roots：线程栈变量、静态变量、常量池、JNI指针 3、常见的垃圾回收算法 Mark-Sweep(标记清除) 将可回收的对象标记为非垃圾。 缺点：位置不连续，产生内存碎片。 Copying(拷贝算法） 内存一分为二，将存活对象复制到未使用的内存中，原内存全部标记为可使用；新分配内存时先分配存活对象所在的那段内存，垃圾回收时，重复上述操作。 特点：没有碎片，但是内浪费空间。最大的问题：内存浪费。 Mark-Compact（标记压缩) 将存活对象依次复制到垃圾对象和未使用的区域中，结合了标记清除和拷贝的做法，但是效率比copy略低。 三种方法找垃圾的效率是一致的，区别在于找到垃圾后对其进行整理的方式。拷贝算法是内存拷贝，是线性地址的拷贝，速度很快的，效率很高。但是压缩算法却不这么简单，因为任意一个内存进行移动时，如果是多线程， 都要进行线程同步；如果是单线程，那单线程的效率本来就低。 所以任何一块内存挪动都要进行线程同步，所以效率肯定是很低的。 4、JVM内存分代模型(用于分代垃圾回收算法） 目前，生产环境中普遍使用的是JDK1.7或JDK1.8，根据JDK版本不同，分代也不同。 JVM中分代：新生代+老年代+永久代(JDK1.7)/元数据区(JDK1.8)Metaspace。 永久代和元数据区是装载Class的，将硬盘上的Class对象load到内存的时候，装载了永久代或者元数据区域，具体放在哪里区别于使用的JDK版本 永久代必须指定大小限制，而元数据可以设置，也可不设置，无上限(受限于物理内存） 字符串常量在JDK1.7中，是放在永久代区域；而JDK1.8中，是放在堆里 MethodArea是一个逻辑概念，并不是指的一个区域，在JDK1.7中对应的就是永久代，JDK1.8中对应的是元数据 堆内存逻辑分区 新生代中分了两类区域，eden和survivor，而survivor有两块。默认的比例，新生代：老年代=1：3，新生代中eden: survivor：survivor = 8:1:1。 之所以新生代中按照这个比例分配，是因为eden区在GC的时候，90%的对象都会被回收，剩下的存活对象在survivor区是可以放下的。 当创建一个对象时，默认会去找eden区， 如果对象特别大，eden区装不下则直接进入老年代。 新生代 = Eden + 2个survivor区(survivor0、survivor1）： YGC(Young GC)回收后，大多数的对象会被回收，活着的对象进入survivor0 再次YGC，活着的对象eden+s0拷贝到s1，将eden和s0清空 再次YGC，活着的对象eden+s1拷贝到s0，将eden和s1清空 年龄足够->老年代(年龄足够：15，CMS 6) survivor区装不下的时候，装不下的部分直接进入老年代 老年代： 顽固份子 老年代区域满了，就进行Full GC(简称FGC, FGC包括新生代和老年代同时GC) GC Tuning：尽量减少FGC。 5、垃圾回收器 Serial、ParNew、Parallel Scavenge是用于回收Young Generation CMS、Serial Old、Parallel Old是用于回收Old Generation G1、ZGC、Shenandoah不区分老年代和新生代。 Epsilon是一个空的GC，仅仅用于调试JDK。 图中的红色虚线表示可以配合使用。 Serial 垃圾回收的时候，程序是无法执行的。stop-the-world(STW)是停止程序运行，回收线程开始运行，回收结束后程序再接着运行。 Parallel Scavenge 并行回收，多个线程同时进行垃圾回收。 ParNew 配合CMS的年轻代并行回收。 SerialOld 单线程回收算法用于old区域 Parallel Old 多线程回收算法用于old区域 CMS ConcurrentMarkSweep，用于回收老年代，在垃圾回收的同时程序也能运行。(黄色的表示垃圾回收线程，蓝色表示程序执行线程） 调优针对的是Serial、Parallel Scavenge和Serial Old、Parallel New，因为JDK1.8默认的垃圾回收：Parallel Scavenge + Parallel Old。 6、JVM参数 JVM的命令行参数参考：https://docs.oracle.com/javase/8/docs/technotes/tools/unix/java.html JVM参数分类： 标准：-开头，所有的HotSpot都支持。 如：java -version 非标准：-X开头，特定版本HotSpot支持特定命令 不稳定：-XX开头，下个版本可能取消 -XX: +PrintFlagsFinal --- 设置值（最终生效值) -XX:+PrintFlagsInitial --- 默认值 -XX:+PrintCommandLineFlags ---命令行参数 7、思维导图 参考文档： https://blogs.oracle.com/jonthecollector/our-collectors https://blogs.oracle.com/jonthecollector/why-not-a-grand-unified-garbage-collector","link":"/2020/02/26/jvm-GC-and-GC-Tuning/"},{"title":"《可复制的领导力》读后有感","text":"前言 2020年以来，一直想读一本关于管理类的书籍，前中央电视台主持人樊登创办了《樊登读书会》，仅用4年时间，付费会员人数便突破300万，发展势头非常良好。 樊登老师的《可复制的领导力》在京东商城管理类书籍排名第一，抱着高山仰止的心态，选择了这本书，进行拜读学习。 《樊登读书会》火爆带来的思考 在我高中的时候，学校来了一位中国最年轻的演讲家，在学校的大操场慷慨激昂，励志事迹娓娓道来，音响里重复播放着《感恩的心》，最后领着我们宣誓，让我们很多同学，尤其是女同学哭的稀里哗啦，最后很多人买了演讲家100多元的书。 《樊登读书会》能够为那些没有时间阅读、不知道阅读哪些书和阅读效率低下的人，每年吸收50本书的精华。旨在让更多的中国人爱上阅读，通过传播知识不断提升自己，造福社会。我恰好同学在参加了《樊登读书会》，故有了解一些，其大概每年收取365元会费，加入会属于班级以及小组，营造一种共同学习的氛围。读书的重要性不必自说，樊登老师是成功者，也毋庸讳言，不过加入这种每年付费的读书会，我个人感觉是非常不必要的，通过阅读其作品，领悟到其思想中精华就好了。 《可复制的领导力》读后有感一 樊登老师在该书中总结了一些关于管理的观点 1、领导力就是一个工具包，可习得、可复制、可传递。 感悟：大概类似两千多年前秦朝的陈胜吧，在地头里喊出”王侯将相，宁有种乎”。这本书也想向我们说明，管理能力不是某些人具备的一种天赋，也不是不可意会的艺术，而是人人都可以掌握的一种能力，跟学习语文、数学没什么区别。 2、团队是一只球队，而不是家，需要明确彼此的目标，才能更有效的合作； 感悟：建立一个团队目标，大家一起朝着目标努力。 3、管理者的几个关键步骤。 先建立感情，信任；再激发源动力，培养责任感；努力营造好的团队氛围；以身作则，知行合一； 良好的沟通，客观的反馈。 感悟：总结的很好； 《可复制的领导力》读后有感二 管理是一门科学，更是一门艺术。犹如看大豆结出果实。需要有种豆、浇水，施肥，开花，结果等等一系列的过程。管理能力虽说不是天生的，我们需要不断练习即可获得，但是也不要看完樊登老师举的”海底捞、麦当劳”成功小事例，就盲目自信，给自己一种很容易学习到的感觉。 《可复制的执行力》在京东商城管理类书籍排名第一，但在我看来，的确不能算一本好书。跟我看高中时买的演讲家自编的励志故事书味道差不多；一本书，一篇文章到底好不好，大概需要经历岁月的洗涤，历久弥新，给人以启发吧。买书学管理，我个人感觉还是不要看京东上热销的管理学的书了，别抱着太强的功利心了，或许读书更有启发吧；正如：孙子兵法第一句：”兵者，国之大事，死生之地，存亡之道，不可不察也”。孙子兵法流传千年，靠的不是打仗的小诀窍，而是站在民族、国家、军队的一个领导者一个应有的战略高度！","link":"/2020/03/22/%E3%80%8A%E5%8F%AF%E5%A4%8D%E5%88%B6%E7%9A%84%E9%A2%86%E5%AF%BC%E5%8A%9B%E3%80%8B%E8%AF%BB%E5%90%8E%E6%9C%89%E6%84%9F/"},{"title":"Kafka节点平滑迁移步骤","text":"一，查看所有的topic1bin/kafka-topics.sh --zookeeper ip:port --list 二，将topic组装为JSON格式kafka后台脚本只支持如下JSON格式节点迁移 1234567{ \"topics\": [ { \"topic\": \"plat_order_core_dubbo_access_topic\" } ], \"version\": 1} 生成该格式代码，可参考使用如下Java代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849import com.alibaba.fastjson.JSONObject;import com.google.common.collect.Lists;import org.apache.commons.lang3.StringUtils; import java.io.BufferedReader;import java.io.InputStream;import java.io.InputStreamReader;import java.nio.charset.StandardCharsets;import java.util.ArrayList;import java.util.List; public class Topic2JsonUtil { public static void main(String[] args) { List topicList = readFileAsListFromJarPath(\"topic.txt\"); List topicJsonList = Lists.newArrayList(); topicList.forEach(topic -> { JSONObject topicJson = new JSONObject(); topicJson.put(\"topic\", topic); topicJsonList.add(topicJson); }); JSONObject resultJson = new JSONObject(); resultJson.put(\"topics\", topicJsonList); System.out.println(resultJson); } public static List readFileAsListFromJarPath(String fileName) { List result = new ArrayList(); try { InputStream inputStream = Topic2JsonUtil.class.getClassLoader().getResourceAsStream(fileName); BufferedReader reader = new BufferedReader(new InputStreamReader(inputStream, StandardCharsets.UTF_8)); String line; while ((line = reader.readLine()) != null) { if (StringUtils.isNotBlank(line)) { result.add(line); } } reader.close(); } catch (Exception e) { LogUtil.ROOT.error(\"\", e); } StringBuilder builder = new StringBuilder(); if (result.size() != 0) { result.forEach(builder::append); } return result; } } 三，生成迁移计划使用如下命令生成迁移计划如下示例代表将topic所有的节点数据重新路由到4、5、6节点上，并将迁移计划输出到plan-move.json文件中 1./bin/kafka-reassign-partitions.sh --zookeeper ip:port --topics-to-move-json-file topics-to-move.json --broker-list \"4,5,6\" --generate > plan-move.json 生成的计划格式化后如下： 1234567891011121314151617181920Current partition replica assignment{ \"version\": 1, \"partitions\": [{ \"topic\": \"erp_java_topic\", \"partition\": 9, \"replicas\": [12, 11, 13, 1], \"log_dirs\": [\"any\", \"any\", \"any\", \"any\"] }]}Proposed partition reassignment configuration{ \"version\": 1, \"partitions\": [{ \"topic\": \"erp_java_topic\", \"partition\": 9, \"replicas\": [4, 5, 6, 7], \"log_dirs\": [\"any\", \"any\", \"any\", \"any\"] }]} 保留迁移计划JSON，即下面的JSON内容； 四，执行迁移计划执行迁移计划 1./bin/kafka-reassign-partitions.sh --zookeeper ip:port --reassignment-json-file plan-move.json --execute 查看迁移进度 1./bin/kafka-reassign-partitions.sh --zookeeper ip:port --reassignment-json-file plan-move.json --verify","link":"/2020/04/23/Kafka%E8%8A%82%E7%82%B9%E5%B9%B3%E6%BB%91%E8%BF%81%E7%A7%BB%E6%AD%A5%E9%AA%A4/"}],"tags":[{"name":"elasticsearch","slug":"elasticsearch","link":"/tags/elasticsearch/"},{"name":"linux","slug":"linux","link":"/tags/linux/"},{"name":"git","slug":"git","link":"/tags/git/"},{"name":"java","slug":"java","link":"/tags/java/"},{"name":"人文","slug":"人文","link":"/tags/%E4%BA%BA%E6%96%87/"}],"categories":[{"name":"elasticsearch","slug":"elasticsearch","link":"/categories/elasticsearch/"},{"name":"linux","slug":"linux","link":"/categories/linux/"},{"name":"git","slug":"git","link":"/categories/git/"},{"name":"java","slug":"java","link":"/categories/java/"},{"name":"人文","slug":"人文","link":"/categories/%E4%BA%BA%E6%96%87/"}]}